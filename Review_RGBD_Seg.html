<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->
			<section>
				<h5 style="text-transform: capitalize;">Review on Indoor RGB-D Semantic Segmentation with Deep
					Convolutional Neural Networks ( <span style="font-style: unset;">DCNN</span> )</h5>
				<br>
				<br>
				<small><b>Sami BARCHID</b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; José MENNESSON &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					Chaabane DJÉRABA</small>
				<img src="img/Review_RGBD_Seg/logos_cbmi.png">
				<!-- <p><small id="js-current-date"></small></p>
				<script>
					document.getElementById('js-current-date').innerHTML = new Date().toLocaleDateString("en-US")
				</script> -->
			</section>

			<section>
				<h3>Objective</h3>
				<ul>
					<li class="fragment">
						<b>Condensed introduction</b> to the field of RGBD semantic segmentation
					</li>
					<br />
					<li class="fragment">Discusses the <b>challenges</b> encountered in the current state-of-the-art
						(SOTA)</li>
					<br />
					<li class="fragment">Presents the <b>promising perspectives</b> of the field for future research
						works</li>
				</ul>
			</section>

			<section>
				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_1.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_2.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_3.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_4.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_5.png">
				</section>

				<section data-transition="none">
					<h3>
						Formulation
						<!-- <small style="text-transform: none; font-size: 35px;">[Long2015]</small> -->
					</h3>
					<img alt="Segmentation Overview" src="img/Review_RGBD_Seg/seg_overview_6.png">
				</section>
			</section>

			<section>
				<section>
					<h3>Overview of current models</h3>

					<ul>
						<li class="fragment"><b>No established method</b> to perfectly exploit RGB and Depth data together</li>
						<br>
						<li class="fragment"><b>Models vary</b> depending on how the depth features are incorporated into the
							DCNN</li>
						<br>
						<b>
							<li class="fragment">Three strategies found</li>
						</b>
					</ul>
				</section>

				<section>
					<h3>
						Depth as Input ( <span style="font-style: italic; text-transform: none;">DaI</span> )
						<small style="text-transform: none;">[Seichter2020]</small>
					</h3>
					<img src="img/Review_RGBD_Seg/approach_DaI.png" alt="DaI_Approach">
					<ul>
						<li>Most popular</li>
						<li>Duplicated parts</li>
						<li>Increased computational and memory complexity</li>
					</ul>
				</section>

				<section>
					<h3>
						Depth as Operation ( <span style="font-style: italic; text-transform: none;">DaO</span> )
						<small style="text-transform: none;">[Wang2018]</small>
					</h3>
					<img src="img/Review_RGBD_Seg/approach_DaO.png" alt="Approach DaO">
					<ul>
						<li>Operation modified w.r.t. depth map</li>
						<li>No duplicated parts</li>
						<li>Reduced complexity</li>
						<li>Adapted to low-cost indoor devices</li>
					</ul>
				</section>

				<section>
					<h3>
						Depth as Prediction ( <span style="font-style: italic; text-transform: none;">DaP</span> )
						<small style="text-transform: none;">[Jiao2019]</small>
					</h3>
					<img src="img/Review_RGBD_Seg/approach_DaP.png" alt="Approach DaP">
					<ul>
						<li>Depth only during training</li>
						<li>Predicts segmentation AND depth map</li>
						<li>Enable the use of cheaper RGB cameras</li>
					</ul>
				</section>
			</section>

			<!-- <section>
				<h3>Mean Intersection over Union <span style="text-transform: none;">(mIoU)</span></h3>
				<p>The mean value of all the intersections
					between the predicted
					$\mathbf{S}$ and the ground truth over their unions.</p>
				<img src="img/Review_RGBD_Seg/IoU.png" alt="IOU" style="height: 400px;">
			</section> -->
			<section>
				<!-- <section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_init.png" alt="Benchmarks">
				</section> -->

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_0.png" alt="Benchmarks">
				</section>

				<!-- <section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_1.png" alt="Benchmarks">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_2.png" alt="Benchmarks">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_3.png" alt="Benchmarks">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_4.png" alt="Benchmarks">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img src="img/Review_RGBD_Seg/benchmarks_wo_notes_5.png" alt="Benchmarks">
				</section> -->

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_0.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_1.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_1_1.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_1_2.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_1_3.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_2.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_2_1.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_2_2.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_3.png">
				</section>

				<section data-transition="none">
					<h3>Existing Datasets</h3>
					<img alt="Benchmarks" src="img/Review_RGBD_Seg/benchmarks_3_1.png">
				</section>

				<!-- <section data-transition="none">
					<img src="img/Review_RGBD_Seg/depth_examples.png" alt="depth examples">
				</section>
				<section data-transition="none">
					<img src="img/Review_RGBD_Seg/depth_examples_0.png" alt="depth examples">
				</section>
				<section data-transition="none">
					<img src="img/Review_RGBD_Seg/depth_examples_1.png" alt="depth examples">
				</section>
				<section data-transition="none">
					<img src="img/Review_RGBD_Seg/depth_examples_2.png" alt="depth examples">
				</section> -->
			</section>

			<section>
				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_0.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_1.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_2.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_3.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_4.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_5.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_6.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_7.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_8.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_9.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_10.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_11.png" alt="Performance Analysis Table">
				</section>

				<section data-transition="none">
					<h3>Performance Analysis</h3>
					<img src="img/Review_RGBD_Seg/performances_12.png" alt="Performance Analysis Table">
				</section>
			</section>

			<section>
				<h3>Challenges</h3>
				<ul>
					<li class="fragment">SOTA models are <b>not adapted to edge devices</b>.</li>
					<br />
					<li class="fragment">Performance are still evaluated on <b>older and smaller datasets</b> (NYUv2, SUN-RGBD)
					</li>
					<br />
					<li class="fragment"><b>DaI strategy</b> still remains the way-to-go despite its drawbacks</li>
				</ul>
			</section>

			<section>
				<h3>Perspectives</h3>
				<ul>
					<li class="fragment">Future works should evaluate their performance on <b>recent and larger datasets</b>
						<span style="font-style: italic;">(2D-3D-S, Matterport3D)</span>
					</li>
					<br>
					<li class="fragment">Focusing on <b>DaP</b> and <b>DaO</b> strategies to fully exploit their
						advantages </li>
					<br>
					<li class="fragment">Models based on <b>lightweight backbone networks</b> would enable the use of low-cost
						devices for indoor applications</li>
				</ul>
			</section>

			<section>
				<h1>Thanks!</h1>
			</section>

			<section>
				<h5>References</h5>
				<ul>
					<!-- <li><small><b>[Long2015]</b>: <i>Long et al. “Fully convolutional networks	for semantic segmentation,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 3431–3440.</i></small></li> -->
					<li><small><b>[Wang2018]</b>: <i>Wang et al. “Depth-aware cnn for rgb-d segmentation,” in
								Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp.
								135–150.</i></small></li>
					<li><small><b>[Seichter2020]</b>: <i>Seichter et al. “Efficient rgb-d semantic segmentation for
								indoor scene analysis,” arXiv preprint arXiv:2011.06961, 2020.</i></small></li>
					<li><small><b>[Wang2018]</b>: <i>Wang et al. “Depth-aware cnn for rgb-d segmentation,” in
								Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp.
								135–150.</i></small></li>
					<li><small><b>[Jiao2019]</b>: <i>Jiao et al. “Geometry-aware distillation for indoor semantic
								segmentation,” in Proceedings of the IEEE Conference on Computer Vision and Pattern
								Recognition, 2019, pp. 2869–2878.</i></small></li>
					<li><small><b>[Silberman2012]</b>: <i>Silberman et al. “Indoor segmentation
								and support inference from rgbd images,” in European conference on computer vision.
								Springer, 2012, pp. 746–760.</i></small></li>
					<li><small><b>[Song2015]</b>: <i>Song et al. “Sun rgb-d: A rgb-d scene understanding benchmark
								suite,” in Proceedings of the IEEE conference on computer vision and pattern
								recognition, 2015, pp. 567–576.</i></small></li>
					<li><small><b>[Armeni2017]</b>: <i>Armeni et al. “Joint 2d-3d-semantic data for indoor scene
								understanding,” arXiv preprint arXiv:1702.01105, 2017.</i></small></li>
					<li><small><b>[Chang2017]</b>: <i>Chang et al. “Matterport3d: Learning from rgb-d data in indoor
								environments,” arXiv preprint arXiv:1709.06158, 2017.</i></small></li>
					<li><small><b>[McCormac2016]</b>: <i>McCormac et al. “Scenenet rgb-d: 5m photorealistic images of
								synthetic indoor trajectories with ground truth,” arXiv preprint arXiv:1612.05079,
								2016.</i></small></li>
				</ul>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>