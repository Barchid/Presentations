<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks &lpar; DCNN &rpar;</title>
        <style>
</style>
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        
        
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="review-on-indoor-rgb-d-semantic-segmentation-with-deep-convolutional-neural-networks--dcnn-">Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks ( DCNN )</h1>
<p>Hello ! My name is Sami Barchid and in this video, I will present our short paper &quot;Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks&quot; or DCNN for short.</p>
<h2 id="objective">Objective</h2>
<p><strong>FRAGMENT</strong> The main objective in this review paper is to give the reader a condensed introduction to RGB-D semantic segmentation.</p>
<p><strong>FRAGMENT</strong> I will present the current challenges encountered by state-of-the-art approaches and</p>
<p><strong>FRAGMENT</strong> finally, we will talk about promising perspectives that may be interesting for future research works.</p>
<h2 id="formulation">Formulation</h2>
<p>First and foremost, let's formulate the task of RGB-D semantic segmentation.</p>
<p><strong>IMAGE</strong> Given an input RGB image and its related depth map</p>
<p><strong>IMAGE</strong> the objective is to obtain a semantic segmentation map that provides a pixel-wise classification among a defined number of categories.</p>
<p><strong>IMAGE</strong> To do so, the most popular approach currently is to use an encoder-decoder network.</p>
<p><strong>IMAGE</strong> It is composed of the encoder, which is a standard deep backbone network such as ResNet. An encoder extracts feature maps but progressively lose spatial information during the process.</p>
<p><strong>IMAGE</strong> To solve this problem, the decoder recovers low-level features information by merging the encoder's feature maps <strong>IMAGE</strong> using skip connections.</p>
<h2 id="overview-of-current-models">Overview of Current Models</h2>
<p>It has been shown in many works that depth provides a complementary geometric information that can benefit a standard RGB segmentation model.</p>
<p><strong>FRAGMENT</strong> However, there is no established method to perfectly merge depth and RGB features together.</p>
<p><strong>FRAGMENT</strong> State-of-the-art models vary depending on how depth features are incorporated.</p>
<p><strong>FRAGMENT</strong> We identify three main strategies used in previous works.</p>
<h2 id="depth-as-input">Depth as Input</h2>
<p>The most popular one is Depth as Input. It basically uses the depth map as an additional input, and processes both modalities in separated parts before a fusion step. Consequently this strategy requires to duplicate several parts of the DCNN, leading to an increased computational and memory costs.</p>
<h2 id="depth-as-operation">Depth as Operation</h2>
<p>The &quot;Depth as Operation&quot; strategy directly modifies the operations performed in the CNN with respect to the depth. Without duplicated parts, this strategy reduces the computational complexity. Therefore it is quite intersting when the designed model has to run on low-cost devices.</p>
<h2 id="depth-as-prediction">Depth as Prediction</h2>
<p>&quot;Depth as Prediction&quot; only uses depth during training, because the objective of this strategy is to predict both segmentation AND depth maps. In this way, the model implicitly learns the geometric information from depth data. Consequently, &quot;Depth as Prediction&quot; can run on cheaper RGB cameras.</p>
<h2 id="existing-datasets">Existing Datasets</h2>
<p>Now let's see the major datasets used in the field.</p>
<p><strong>IMAGE</strong> We can divide the existing datasets on three different categories.</p>
<p><strong>IMAGE</strong> The first one consists of NYUv2 and SUN RGBD.
<strong>IMAGE</strong> They are the oldest datasets in the list and are not perfectly suitable for data-hungry algorithms like deep learning.
<strong>IMAGE</strong> Indeed, NYUv2 and SUN-RGBD have a very small number of samples and
<strong>IMAGE</strong> the images have a low resolution.</p>
<p><strong>IMAGE</strong> The problems of this first category have been solved in
<strong>IMAGE</strong> 2017 with the release of two more recent benchmarks, namely 2D-3D-S and Matterport3D.
<strong>IMAGE</strong> They are composed of a higher number of high resolution images, making them more adapted to current deep learning models.</p>
<p><strong>IMAGE</strong> The last category focus on synthetic data.</p>
<p><strong>IMAGE</strong> In SceneNet RGB-D, 3D indoor scenes are generated automatically to create a huge quantity of annotated data. Using a synthetic dataset is a good option for pretraining in order to boost the performance. It is a good choice to pretrain a model on SceneNet instead of the usual ImageNet.</p>
<!-- ## Depth Map Examples
On the other hand, the quality of depth sensors is another important feature to take into account.

**IMAGE** as you can see here, in old datasets like NYUv2, we observe many artifacts in non-smooth depth. These problems may lead to poor feature extraction by a deep learning model. 

**IMAGE** On the other hand, more recent datasets like 2D-3D-S were captured by recent depth sensors with better accuracy.

**IMAGE** However, the perfectly-annotated example of SceneNet RGB-D is unreachable in practice because of the synthetic nature of the data. -->
<h2 id="performance-analysis">Performance analysis</h2>
<p>Now let's analyze the state-of-the-art models. Here, I will mainly focus on complexity comparison because it leads to the main challenges for future works but feel free to read our paper to have the full analysis.</p>
<p>We evaluate the models using
<strong>IMAGE</strong> the mean intersection over union on NYUv2 and SUN-RGBD datasets,
<strong>IMAGE</strong> a frame per second metric,
<strong>IMAGE</strong> the backbone network used
<strong>IMAGE</strong> and we sort them by the adopted strategy.
<strong>IMAGE</strong>
<strong>IMAGE</strong> DaI strategy is by far the most popular strategy,
<strong>IMAGE</strong> but is a heavy approach due to duplicated parts of the model, notably the encoder part.</p>
<p><strong>IMAGE</strong>
<strong>IMAGE</strong> In comparison, depth as Operation models are much lighter, only needing one encoder part and still achieves competitive results.</p>
<p><strong>IMAGE</strong> the least popular approach is depth as prediction, but is promising according to the accuracy results.
<strong>IMAGE</strong> However, this approach usually comes with the same drawbacks of heavy duplicated parts in the neural network's design.</p>
<p><strong>IMAGE</strong> An important observation here is that the backbone networks used are all deep ResNets, which leads to heavy models that require expensive hardware.</p>
<h2 id="challenges">Challenges</h2>
<p>So let's summarize the main challenges of the field</p>
<p><strong>FRAGMENT</strong> firstly, we noticed the heaviness of the current models in State-of-the-art. These models use large and deep backbone encoders which make them unsuitable for use in edge devices.</p>
<p><strong>FRAGMENT</strong> Despite the release of larger indoor RGBD datasets, current models are still evaluated on NYUv2 and SUN RGBD. We argue that these datasets limit the performance of modern RGBD semantic segmentation models due to the small number of samples.</p>
<p><strong>FRAGMENT</strong> Nowadays, new models still adopt the Depth as Input strategy even if it comes with a high computational cost.</p>
<h2 id="perspectives">Perspectives</h2>
<p>These challenges create some interesting perspectives for future works.</p>
<p><strong>FRAGMENT</strong> starting to evaluate future models on recent datasets can increase the performance of future models, due to the higher number of samples.</p>
<p><strong>FRAGMENT</strong> Working on DaP and DaO strategies is an interesting direction to exploit the advantages of such strategies like reduced complexity.</p>
<p><strong>FRAGMENT</strong> Finally, focusing on lightweight backbone networks would enable the creation of applications running on low-cost devices since existing models are still heavy.</p>
<h2 id="thanks">Thanks</h2>
<p>This concludes my presentation. I hope it was interesting for you and I'll be glad to answer your questions. Thank your for listening.</p>

    </body>
    </html>