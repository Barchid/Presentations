<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Avancées en Vision Neuromorphique : Représentation Événementielle, Réseaux de Neurones Impulsionnels
		Supervisés et Pré-entraînement Auto-supervisé</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="css/w3.css">

	<style>
		.ita {
			font-style: italic;
		}

		h1,
		h2,
		h3 {
			text-transform: none !important;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->

			<section>
				<img src="these/entree.png" alt="ent">
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>

				<section>
					<h3> 👁️‍🗨️ &nbsp; Vision Artificielle</h3>
					<p>
						📖 &nbsp; Extraire automatiquement des <b>informations</b> à partir de <b>données visuelles</b>
					</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img src="these/detection_exemple.png" alt="detection">
							<!-- <figcaption>Détection d'objets</figcaption> -->
						</figure>

						<figure class="fragment fade-in-then-out" data-fragment-index="2">
							<img src="these/vslam.gif" alt="detection">
							<figcaption><small>[Bokovoy2019]</small></figcaption>
						</figure>

						<ul class="fragment fade-in-then-out" data-fragment-index="3">
							<li><b>Applications nombreuses :</b> médical, industriel, sécurité, robotique, ...</li>
							<br>
							<li><b>Comment ?</b> Réseaux de Neurones Artificiels ( <b><span class="ita">ANN</span>s</b>
								) par l'apprentissage profond </li>
						</ul>
					</div>
				</section>

				<section>
					<h3>🔋&nbsp; Consommation Énergétique</h3>
					<p>Estimation d'énergie consommée lors d'une inférence des modèles de l'état de l'art par
						année<small>[Desislavov2023]</small></p>
					<div class="r-stack">
						<img src="these/consommation_energie_0.png" alt="Consommation énergétique">
						<img src="these/consommation_energie_1.png" alt="Consommation énergétique" class="fragment">
						<img src="these/consommation_energie_2.png" alt="Consommation énergétique" class="fragment">
						<img src="these/consommation_energie_3.png" alt="Consommation énergétique" class="fragment">
						<img src="these/consommation_energie_4.png" alt="Consommation énergétique" class="fragment">
					</div>
				</section>

				<section>
					<h3>🔋&nbsp; Consommation Énergétique</h3>
					<ul>
						<li><b>Évolution des modèles</b></li>
						<ul style="list-style-type: '📈'">
							<li class="fragment" data-fragment-index="1"> &nbsp; Complexité <span
									class="ita">(profondeur, paramètres, ...)</span></li>
							<li class="fragment" data-fragment-index="2"> &nbsp; Puissance de calculs requise</li>
							<li class="fragment" data-fragment-index="3"> &nbsp; Consommation énergétique</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="4"><b>Enjeux majeurs</b></li>
						<ul data-fragment-index="4" class="fragment">
							<li>Environnement</li>
							<li>Applications</li>
						</ul>
					</ul>
					<br>
					<br>
					<p class="fragment" data-fragment-index="5" style="color: red;">
						➡️ &nbsp; <b>Problématique principale</b>
					</p>
				</section>

				<section>
					<h3>💻 &nbsp; Technologie Neuromorphique</h3>
					<p>📖 &nbsp; Technologie inspirée par le fonctionnement des neurones biologiques.</p>
					<br>
					<ul class="fragment">
						<li>📷 &nbsp;<b>Capteur :</b> Caméra événementielle</li>
						<li>🧠 &nbsp;<b>Traitement :</b> Réseaux de neurones impulsionnels (<b><span
									class="ita">SNN</span></b>)</li>
						<br>
						<li class="fragment">Systèmes de vision économes en énergie <br> &nbsp;&nbsp;&nbsp;➡️ &nbsp; <b
								style="color:green">Solution prometteuse</b></li>
					</ul>
				</section>

				<section>
					<h3>📷 &nbsp; Caméra Événementielle</h3>
					<ul>
						<li>Inspirée de la biologie</li>
						<li>Événements <b>asynchrones</b> lors d'un changement d'intensité du pixel</li>
						<!-- <br> -->
						<ul style="list-style-type: none;">
							<li class="fragment">➡️ <b>Mouvement</b></li>
						</ul>
					</ul>
					<video src="img/Bina_rep/dvscamvisu.mp4" height="300px" muted autoplay controls></video>
					<p><small>Source : <a
								href="https://www.youtube.com/watch?v=LauQ6LWTkxM">https://www.youtube.com/watch?v=LauQ6LWTkxM</a></small>
					</p>
				</section>

				<section>
					<h3>🧠 &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<ul>
						<li>Bio-inspirés <span class="ita">(neurones impulsionnels)</span></li>
						<li>Neurones communiquent par <b>impulsions asynchrones</b></li>
					</ul>
					<div class="fragment" data-fragment-index="1"><video src="img/Bina_rep/snn_visu.mp4" muted
							height="300px" controls /></div>
					<p class="fragment" data-fragment-index="1"><small>Source : <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
				</section>

				<section>
					<h3>Vision Neuromorphique</h3>
					<ul>
						<li>📖 &nbsp; Intégrant une caméra événementielle et/ou un SNN</li>
						<br>
						<li>🤝 &nbsp; <b>Traitement asynchrone en commun</b></li>
					</ul>
				</section>

				<section>
					<h3>⛰️ &nbsp; Défis du Neuromorphique</h3>
					<ul>
						<li><b>Par rapport aux méthodes conventionnelles</b></li>
						<ul>
							<li>Domaine moins étudié</li>
							<li>Technologies moins matures</li>
							<li class="fragment" data-fragment-index="1" style="color:red">➡️ &nbsp; Performances et
								complexité des approches neuromorphiques moins avancées</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2"><b>Besoins du domaine</b></li>
						<ul class="fragment" data-fragment-index="2">
							<li>Développement de <b style="color:green">nouvelles approches en vision neuromorphique</b>
							</li>
							<li><b style="color:green">Analyses approfondies</b> pour leur compréhension</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>🎯 &nbsp; Objectifs</h3>
					<p style="border: solid 4px;"><b>Progrès des technologies neuromorphiques dans les tâches de vision
							artificielle</b></p>
					<br>
					<ul>
						<li class="fragment">🧱 &nbsp; <b>Conception de modèles d'apprentissage profond</b> avec SNNs
							et/ou caméras événementielles
						</li>
						<br>
						<li class="fragment">🔎 &nbsp; <b>Études expérimentales</b> pour approfondir nos connaissances
						</li>
					</ul>
				</section>

				<section>
					<h3>🖼️ &nbsp; Contextes</h3>
					<div class="r-stack">

					</div>
				</section>

				<section>
					<h3>🗓️ &nbsp; Organisation</h3>
					<ol style="font-weight: bold;">
						<li>État de l'art</li>
						<br>
						<li>SNNs pour la localisation d'objet</li>
						<br>
						<li>Pré-entraînement auto-supervisé pour la vision événementielle</li>
						<br>
						<li>Conclusion</li>
					</ol>
				</section>
			</section>

			<section>
				<section>
					<h1>État de l'Art</h1>
				</section>

				<section>
					<h3>📚 &nbsp; Trois Domaines</h3>
					<ul>
						<li>👴 &nbsp; <b>Approches classiques</b> : <span class="ita">ANN + images</span></li>
						<br>
						<li>⚡ &nbsp; <b>Réseaux de neurones impulsionnels</b></li>
						<br>
						<li>📸 &nbsp; <b>Vision événementielle</b> : vision artificielle avec des caméras
							événementielles</li>
					</ul>
				</section>

				<section>
					<h3>👴 &nbsp; Approches Classiques</h3>
					<ul>
						<li><b>👴 &nbsp; Historiquement : </b></li>
						<div class="r-stack">
							<ul class="fragment fade-in-then-out" data-fragment-index="0">
								<li>Coucou</li>
							</ul>
							<p class="fragment fade-in-then-out" data-fragment-index="1"> caca</p>
						</div>
						<li><b>🗼 Apprentissage profond : </b> entraînement d'une architecture ANN profonde </li>
					</ul>
				</section>

				<section>
					<h3>👴 &nbsp; Approches Classiques</h3>
					<p>Évolutions</p>
				</section>

				<section>
					<h3>🗒️ &nbsp; Formulations</h3>
				</section>

				<section>
					<h3>🗒️ &nbsp; Formulations</h3>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Explication du neurone impulsionnel (vs ANN)</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Modèle IF & LIF</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Codage neuronal</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Techniques d'apprentissage</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Surrogate gradient</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Matériel Neuromorphique</p>
				</section>

				<section>
					<h3>⚡ &nbsp; Réseaux de Neurones Impulsionnels</h3>
					<p>Verrous Scientifiques</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Caméra</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Avantages</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Évolution caméras + changement paradigme</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Formulation génération événements</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Représentation événements</p>
					<ul>
						<li>Images événementielles (détails)</li>
						<li>Surfaces temporelles</li>
						<li>Voxels</li>
						<li>Graphes</li>
						<li>Entraînable</li>
						<li>Traitement direct</li>
					</ul>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Contribution Bina-Rep</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Tâches de vision</p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Bases de données (différentiations) </p>
				</section>

				<section>
					<h3>📸 &nbsp; Vision Événementielle</h3>
					<p>Verrous scientifiques</p>
				</section>

				<section>
					<h3>🗒️ &nbsp; Bilan</h3>
					<p>Introduire les problèmes qu'on traite et basta-zer</p>
				</section>
			</section>

			<section>
				<section>
					<h1>SNNs pour la Localisation d'Objet</h1>
				</section>

				<section>
					<h3>Pourquoi ?</h3>
					<p></p>
				</section>

				<section>
					<h3>Preuve de Concept Préliminaire</h3>
					<p>Parler brièvement de DECOLLE</p>
				</section>

				<section>
					<h3>Contexte de l'Étude</h3>
					<ul>
						<li>Dévelo</li>
					</ul>
				</section>

				<section>
					<h3>Formulation - Localisation d'Objet</h3>
				</section>

				<section>
					<h3>Métrique d'Évaluation</h3>
				</section>

				<section>
					<h3>Configuration - Latence Temporelle</h3>
					<p>Expliquer comment on fait</p>
				</section>

				<section>
					<h3></h3>
				</section>

				<section>
					<h3>Modèle SNN</h3>
				</section>

				<section>
					<h3>Modèle ANN</h3>
				</section>

				<section>
					<h3>Images Statiques - Base de Données</h3>
				</section>

				<section>
					<h3>Images Statiques - Codages Neuronaux</h3>
				</section>

				<section>
					<h3>Images Statiques - Codages Neuronaux</h3>
				</section>

				<section>
					<h3>Images Statiques - Latence Temporelle</h3>
				</section>

				<section>
					<h3>Images Statiques - Corruptions</h3>
				</section>

				<section>
					<h3>Baisse de Précision Relative</h3>
				</section>

				<section>
					<h3>Images Statiques - Corruptions</h3>
				</section>

				<section>
					<h3>Événements - Bases de Données</h3>
				</section>

				<section>
					<h3>Événements - Latence Temporelle</h3>
				</section>

				<section>
					<h3>Événements - Latence Temporelle</h3>
				</section>

				<section>
					<h3>Événements - Corruptions</h3>
					<p>Détailler les corruptions</p>
				</section>

				<section>
					<h3>Événements - Corruptions</h3>
					<p>Résultats</p>
				</section>

				<section>
					<h3>Consommation Énergétique</h3>
				</section>

				<section>
					<h3>Consommation Énergétique</h3>
				</section>

				<section>
					<h3>Conclusion de l'Étude</h3>
				</section>

				<section>
					<h3>Spiking-Fer</h3>
				</section>
			</section>

			<section>
				<section>
					<h2>Pré-entraînement Auto-supervisé <br> <span style="font-weight: normal;">pour la Vision
							Événementielle</span></h2>
				</section>

				<section>
					<h3>🖼️ &nbsp; Contexte</h3>
					<ul>
						<li>📈 &nbsp; Modèles profonds pour la vision événementielle</li>
						<li><b>Apprentissage supervisé :</b> nécessite beaucoup de données annotées</li>
						<li style="color:red;" class="fragment" data-fragment-index="0">
							➡️ &nbsp; Complexifie le développement de nouvelles applications
						</li>
						<br>
						<li class="fragment" data-fragment-index="1"><b style="color:green;">Solution Proposée : </b>
							Apprentissage auto-supervisé</li>
						<ul class="fragment" data-fragment-index="1">
							<li>Pré-entraîner un modèle sur des données <b>sans nécessiter d'annotations</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>📚 &nbsp; Solutions Existantes</h3>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0"
							src="these/pretraining_explained_0.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="1"
							src="these/pretraining_explained_1.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="2"
							src="these/pretraining_explained.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="3"
							src="these/pretraining_explained_2.png" alt="pretraining">
						<div class="fragment fade-in-then-out" data-fragment-index="4">
							<img src="these/pretraining_supervised.png" alt="pretraining">
							<ul>
								<li><b>Supervisé :</b> utiliser une grande BDD <span class="ita">générique</span>
									annotée puis affiner</li>
								<ul>
									<li>👎 &nbsp; peu de BDDs événementielles pertinentes</li>
								</ul>
							</ul>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="5">
							<img src="these/pretraining_ssl.png" alt="pretraining">
							<ul>
								<li><b>Apprentissage Auto-supervisé de Représentation <span class="ita">(SSRL)</span> :</b> capturer les propriétés et motifs intrinsèques des données </li>
								<ul>
									<li>👍 &nbsp; pas d'annotations requises</li>
									<li>👍 &nbsp; proche du domaine d'application</li>
								</ul>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>📚 &nbsp; Solutions Existantes - SSRL événementiel</h3>
					<ul>
						<li>Peu de travaux existants</li>
						<br>
						<li>Tâches de bas-niveau (flux optique, ...) <small>[TODO,TODO]</small></li>
						<br>
						<li>Travaux concurrents pour les réseaux profonds <span class="ita">(3)</span><small>[TODO,TODO,TODO]</small></li>
						<ul>
							<li>👎 &nbsp; limités à du <span style="color: red;">comportement statique</span></li>
							<li>👎 &nbsp; concentrés sur <span style="color: red;">un seul type de réseau</span> <span class="ita">(ViT / SNN)</span></li>
						</ul>
					</ul>
				</section>			
				
				<section>
					<h3>📚 &nbsp; Solutions Existantes - SSRL événementiel</h3>
					<p><b>Constat</b></p>
					<ul>
						<li>Domaine <b>très prometteur</b> pour réduire le besoin en annotations...</li>
						<li>... mais <b>très peu étudié</b></li>
					</ul>

					<p></p>
				</section>

				<section>
					<h3>⚙️ &nbsp; Méthode</h3>
					<ul>
						<li><b>🧠 &nbsp; Modèles visés :</b> encodeurs convolutifs légers <span class="ita">(CSNN, 2D-CNN, et 3D-CNN)</span></li>
						<br>
						<li><b>📁 &nbsp; Polyvalence des données :</b> comportements statiques et dynamiques</li>
						<br>
						<li><b>👥 &nbsp; Architecture d'encodage conjoint</b></li>
						<ul>
							<li class="fragment">Architecture en <b>deux branches</b></li>
							<li class="fragment"><b>Deux versions transformées</b> de la même entrée</li>
							<li class="fragment">Augmentations de données événementielle <b><span class="ita">(EDAs)</span></b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>⚙️ &nbsp; Méthode</h3>
					<p><b>Augmentation de Données Événementielle</b> (EDA)</p>
					<div class="r-stack">
						<img src="img/ssl/dataaug_0.png" data-fragment-index="0" alt="data" class="fragment">
						<img src="img/ssl/dataaug_1.png" data-fragment-index="1" alt="data" class="fragment">
						<img src="img/ssl/dataaug.png" data-fragment-index="2" alt="data" class="fragment">
						<img src="img/ssl/dataaug_comp.png" alt="data" class="fragment" data-fragment-index="3">
						<img src="img/ssl/dataaug_comp2.png" alt="data" class="fragment" data-fragment-index="4">
						<img src="img/ssl/dataaug_comp3.png" alt="data" class="fragment" data-fragment-index="5">
					</div>
					<p class="fragment" data-fragment-index="3">Une EDA peut être une <b>composition</b> d'autres EDAs</p>
				</section>

				<section>
					<h3>⚙️ &nbsp; Méthode</h3>
					<p><b>Architecture d'Encodage Conjoint</b><small>[TODOvicreg,TODObarlow]</small></p>
					<div class="r-stack">
						<img src="these/archi_ssl_0.png" alt="archi ssl">
						<img src="these/archi_ssl_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_2.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_5.png" alt="archi ssl" class="fragment">
					</div>
				</section>

				<section>
					<h3>⚙️ &nbsp; Méthode</h3>
					
					<p><b>Encodeurs étudiés</b></p>
					<ul>
						<li><b>2D-CNN : </b>ResNet-18<small>[TODOresnet]</small></li>
						<li><b>3D-CNN : </b>MC3-ResNet-18<small>[TODOresnet3d]</small></li>
						<li><b>CSNN : </b>SEW-ResNet-18<small>[TODOsew]</small></li>
					</ul>
					<br>
					<br>
					<ul style="list-style: none;">
						<li>ℹ️ &nbsp; Même complexité <span class="ita">($\approx$11M paramètres)</span></li>
						<li>ℹ️ &nbsp; Représentations $\mathbf{Y}^d \in \mathbb{R}^{K = 512}$</li>
					</ul>
				</section>

				<section>
					<h3>⚙️ &nbsp; Méthode</h3>
					<p><b>Variantes</b></p>
					<div class="r-stack">
						<img src="these/variants_ssl_0.png" alt="variantes ssl">
						<img src="these/variants_ssl_1.png" alt="variantes ssl" class="fragment" data-fragment-index="1">
						<img src="these/variants_ssl.png" alt="variantes ssl" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>👬 &nbsp; Jumeaux : </b>architecture classique avec poids partagés</li>
						<br>
						<li class="fragment" data-fragment-index="2"><b>👨‍🎓🧑‍🏫 &nbsp; Étudiant-Professeur : </b>CSNN (<span class="ita">étudiant</span>) couplé à 2D-/3D-CNN (<span class="ita">professeur</span>)</li>
					</ul>
				</section>

				<section>
					<h3>🔎 &nbsp; Étude sur les EDAs</h3>
					<p>À chaque inférence, une composition $d_A$ / $d_B$ est échantillonnée d'une distribution $D$</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0" src="these/archi_ssl_6.png" alt="ssl d">
						<img class="fragment fade-in-then-out" data-fragment-index="1" src="these/eda_distrib_0.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="2" src="these/eda_distrib_1.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="3" src="these/eda_distrib_2.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="4" src="these/eda_distrib.png" alt="distrib d">
						<p class="fragment" data-fragment-index="5"><b>⚠️ Définir une distribution $D$ efficace est essentiel ⚠️ </b></p>
					</div>
				</section>

				<section>
					<h3>🪄 &nbsp; EDAs Étudiées</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Exemple</b></p>
						<p style="border: solid 3px  blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="1"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Augmentations Communes</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="5"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10"><b>Augmentations en Découpage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11"><b>Augmentations en Découpage</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="12"><b>Augmentations Géométriques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13"><b>Augmentations Géométriques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="14"><b>Augmentations Géométriques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="15"><b>Augmentations Géométriques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="16"><b>Augmentations Géométriques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="17"><b>Augmentations Géométriques</b></p>
					</div>
					<div class="r-stack">
						<img src="these/eda/normal.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="0">
						<p class="fragment fade-in-then-out" data-fragment-index="1">📖 &nbsp; Transformations couramment utilisées, ne partagent <b>pas de caractéristiques communes</b>.</p>
						<img src="these/eda/background_activity.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/eda/polarity_flip.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/eda/crop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="4">

						<p class="fragment fade-in-then-out" data-fragment-index="5">📖 &nbsp; Transformations impliquant la <b>suppression d'événements</b>.</p>
						<img src="these/eda/cutout.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/eda/drop_by_time.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/eda/random_drop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="8">
						<img src="these/eda/event_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="9">
						<img src="these/eda/event_copy.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="10">
						<img src="these/eda/event_copy_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="11">

						<p class="fragment fade-in-then-out" data-fragment-index="12">📖 &nbsp; Transformations impliquant une <b>distorsion spatiale des événements</b>.</p>
						<img src="these/eda/static_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="13">
						<img src="these/eda/static_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="14">
						<img src="these/eda/dynamic_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="15">
						<img src="these/eda/dynamic_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="16">
						<img src="these/eda/stat_dyn_geo.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="17">

					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2">Bruit d'activité de fond (<code>Noise</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="3">Inversion de polarité (<code>PolFlip</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">Recadrage (<code>Crop</code>)</p>
						<!-- decoupage-->
						<p class="fragment fade-in-then-out" data-fragment-index="5"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6">Découpe par zone (<code>Cutout</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="7">Découpe par durée</p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">Découpe aléatoire</p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><code>EventDrop</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10">🆕 &nbsp; <code>EventCopy</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11">🆕 &nbsp; <code>EventCopyDrop</code></p>
						<!-- geo -->
						<p class="fragment fade-in-then-out" data-fragment-index="12"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13">Translation statique (<code>StatTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="14">Rotation statique (<code>StatRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="15">🆕 &nbsp; Translation dynamique (<code>DynTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="16">🆕 &nbsp; Rotation dynamique (<code>DynRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="17">🆕 &nbsp; <code>StatDynGeo</code></p>
					</div>
				</section>

				<section>
					<h3>⚖️ &nbsp; Évaluation des Performances</h3>
					<p style="border: solid 3px red; margin:10px; color:red;">🚫 &nbsp; Pas de protocole d'évaluation commun en SSRL événementiel</p>
					<br>
					<ul>
						<li class="fragment">✅ &nbsp; <b style="color:green;">Solution :</b> définir des <b>protocoles d'évaluation standard</b> pour les travaux futurs</li>
						<ul>
							<li class="fragment">Bases de données populaires <span class="ita">(classification ➡️ taux de précision)</span></li>
							<li class="fragment">Trois protocoles pour évaluer des aspects spécifiques du SSRL</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Protocole 1️⃣ &nbsp;- Évaluation Linéaire</h3>
					<p>🎯 &nbsp; Est-ce que la méthode de SSRL <b>extrait des caractéristiques pertinentes ?</b></p>
				</section>

				<section>
					<h3>Protocole 2️⃣ &nbsp;- Apprentissage Semi-supervisé</h3>
					<p>🎯 &nbsp; Est-ce que la méthode de SSRL permet de <b>réduire le besoin en annotations ?</b></p>
				</section>

				<section>
					<h3>Protocole 3️⃣ &nbsp;- Transfert d'Apprentissage</h3>
					<p>🎯 &nbsp; Est-ce que les caractéristiques apprises peuvent <b>être transférées à d'autres données ?</b></p>
				</section>

				<section>
					<h3>Étude sur les EDAs</h3>
					<p></p>
				</section>

				<section>
					<h3>Étude sur les EDAs</h3>
					<p>Résultats</p>
				</section>

				<section>
					<h3>Résultat des Évaluations</h3>
				</section>

				<section>
					<h3>Mise en Perspective</h3>
				</section>

				<section>
					<h3>Analyses des Représentations</h3>
				</section>

				<section>
					<h3>Représentation - Uniformité et Tolérance</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>Représentation - Uniformité et Tolérance</h3>
					<p>Résultat + interpretations</p>
				</section>

				<section>
					<h3>Représentation - Similarités</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>Représentation - Similarités</h3>
					<p>Résultat + inteprétation</p>
				</section>

				<section>
					<h3>Bilan</h3>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>

				<section>
					<h3>Bilan des Contributions</h3>
				</section>

				<section>
					<h3>Travaux Futurs</h3>
				</section>
			</section>

			<section>
				<p class="r-fit-text">Merci !</p>
			</section>

			<section>
				<h3>References</h3>
				<ul style="list-style: none;">
					<li><small><b>[NameYEAR]: </b>M. Sajjad, et al. "A comprehensive survey on deep facial expression
							recognition: challenges, applications, and future guidelines"</small></li>
					<li><small><b>[Bokovoy2019]: </b>A. Bokovoy et al. "Real-time Vision-based Depth Reconstruction with
							NVidia Jetson"</small></li>
					<li><small><b>[Desislavov2023]: </b>R. Desislavov et al. "Trends in AI inference energy consumption:
							Beyond the performance-vs-parameter laws of deep learning"</small></li>
				</ul>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
				</section>

				<section>
					<h3>Bina-Rep</h3>
				</section>

				<section>
					<h3>dIoU</h3>
				</section>

				<section>
					<h3>VICReg</h3>
					<img src="these/vicreg_annexe.png" alt="vicreg annexe">
					<ul>
						<li><b>Fonction de coût à trois termes :</b></li>
						<ol>
							<li><b>Invariance : </b>minimiser la distance entre les deux encastrements de la même entrée</li>
							<li><b>Variance : </b>maintenir la variance de chaque variable d'un même vecteur dans un lot au-dessus d'un seuil</li>
							<li><b>Covariance : </b>minimiser la covariance entre les valeurs d'un même vecteur</li>
						</ol>
					</ul>
				</section>

				<section>
					<h3></h3>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>