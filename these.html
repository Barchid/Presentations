<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Avanc√©es en Vision Neuromorphique : Repr√©sentation √âv√©nementielle, R√©seaux de Neurones Impulsionnels
		Supervis√©s et Pr√©-entra√Ænement Auto-supervis√©</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="css/w3.css">

	<style>
		.ita {
			font-style: italic;
		}

		h1,
		h2,
		h3 {
			text-transform: none !important;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->

			<section>
				<img src="these/entree.png" alt="ent">
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>

				<section>
					<h3> üëÅÔ∏è‚Äçüó®Ô∏è &nbsp; Vision Artificielle</h3>
					<p>
						üìñ &nbsp; Extraire automatiquement des <b>informations</b> √† partir de <b>donn√©es visuelles</b>
					</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img src="these/detection_exemple.png" alt="detection">
							<!-- <figcaption>D√©tection d'objets</figcaption> -->
						</figure>

						<figure class="fragment fade-in-then-out" data-fragment-index="2">
							<img src="these/vslam.gif" alt="detection">
							<figcaption><small>[Bokovoy2019]</small></figcaption>
						</figure>

						<ul class="fragment fade-in-then-out" data-fragment-index="3">
							<li><b>Applications nombreuses :</b> m√©dical, industriel, s√©curit√©, robotique, ...</li>
							<br>
							<li><b>Comment ?</b> R√©seaux de Neurones Artificiels ( <b><span class="ita">ANN</span>s</b>
								) par l'apprentissage profond </li>
						</ul>
					</div>
				</section>

				<section>
					<h3>üîã&nbsp; Consommation √ânerg√©tique</h3>
					<p>Estimation d'√©nergie consomm√©e lors d'une inf√©rence des mod√®les de l'√©tat de l'art par
						ann√©e<small>[Desislavov2023]</small></p>
					<div class="r-stack">
						<img src="these/consommation_energie_0.png" alt="Consommation √©nerg√©tique">
						<img src="these/consommation_energie_1.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_2.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_3.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_4.png" alt="Consommation √©nerg√©tique" class="fragment">
					</div>
				</section>

				<section>
					<h3>üîã&nbsp; Consommation √ânerg√©tique</h3>
					<ul>
						<li><b>√âvolution des mod√®les</b></li>
						<ul style="list-style-type: 'üìà'">
							<li class="fragment" data-fragment-index="1"> &nbsp; Complexit√© <span
									class="ita">(profondeur, param√®tres, ...)</span></li>
							<li class="fragment" data-fragment-index="2"> &nbsp; Puissance de calculs requise</li>
							<li class="fragment" data-fragment-index="3"> &nbsp; Consommation √©nerg√©tique</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="4"><b>Enjeux majeurs</b></li>
						<ul data-fragment-index="4" class="fragment">
							<li>Environnement</li>
							<li>Applications</li>
						</ul>
					</ul>
					<br>
					<br>
					<p class="fragment" data-fragment-index="5" style="color: red;">
						‚û°Ô∏è &nbsp; <b>Probl√©matique principale</b>
					</p>
				</section>

				<section>
					<h3>üíª &nbsp; Technologie Neuromorphique</h3>
					<p>üìñ &nbsp; Technologie inspir√©e par le fonctionnement des neurones biologiques.</p>
					<br>
					<ul class="fragment">
						<li>üì∑ &nbsp;<b>Capteur :</b> Cam√©ra √©v√©nementielle</li>
						<li>üß† &nbsp;<b>Traitement :</b> R√©seaux de neurones impulsionnels (<b><span
									class="ita">SNN</span></b>)</li>
						<br>
						<li class="fragment">Syst√®mes de vision √©conomes en √©nergie <br> &nbsp;&nbsp;&nbsp;‚û°Ô∏è &nbsp; <b
								style="color:green">Solution prometteuse</b></li>
					</ul>
				</section>

				<section>
					<h3>üì∑ &nbsp; Cam√©ra √âv√©nementielle</h3>
					<ul>
						<li>Inspir√©e de la biologie</li>
						<li>√âv√©nements <b>asynchrones</b> lors d'un changement d'intensit√© du pixel</li>
						<!-- <br> -->
						<ul style="list-style-type: none;">
							<li class="fragment">‚û°Ô∏è <b>Mouvement</b></li>
						</ul>
					</ul>
					<video src="img/Bina_rep/dvscamvisu.mp4" height="300px" muted autoplay controls></video>
					<p><small>Source : <a
								href="https://www.youtube.com/watch?v=LauQ6LWTkxM">https://www.youtube.com/watch?v=LauQ6LWTkxM</a></small>
					</p>
				</section>

				<section>
					<h3>üß† &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<ul>
						<li>Bio-inspir√©s <span class="ita">(neurones impulsionnels)</span></li>
						<li>Neurones communiquent par <b>impulsions asynchrones</b></li>
					</ul>
					<div class="fragment" data-fragment-index="1"><video src="img/Bina_rep/snn_visu.mp4" muted
							height="300px" controls /></div>
					<p class="fragment" data-fragment-index="1"><small>Source : <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
				</section>

				<section>
					<h3>Vision Neuromorphique</h3>
					<ul>
						<li>üìñ &nbsp; Int√©grant une cam√©ra √©v√©nementielle et/ou un SNN</li>
						<br>
						<li>ü§ù &nbsp; <b>Traitement asynchrone en commun</b></li>
					</ul>
				</section>

				<section>
					<h3>‚õ∞Ô∏è &nbsp; D√©fis du Neuromorphique</h3>
					<ul>
						<li><b>Par rapport aux m√©thodes conventionnelles</b></li>
						<ul>
							<li>Domaine moins √©tudi√©</li>
							<li>Technologies moins matures</li>
							<li class="fragment" data-fragment-index="1" style="color:red">‚û°Ô∏è &nbsp; Performances et
								complexit√© des approches neuromorphiques moins avanc√©es</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2"><b>Besoins du domaine</b></li>
						<ul class="fragment" data-fragment-index="2">
							<li>D√©veloppement de <b style="color:green">nouvelles approches en vision neuromorphique</b>
							</li>
							<li><b style="color:green">Analyses approfondies</b> pour leur compr√©hension</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üéØ &nbsp; Objectifs</h3>
					<p style="border: solid 4px;"><b>Progr√®s des technologies neuromorphiques dans les t√¢ches de vision
							artificielle</b></p>
					<br>
					<ul>
						<li class="fragment">üß± &nbsp; <b>Conception de mod√®les d'apprentissage profond</b> avec SNNs
							et/ou cam√©ras √©v√©nementielles
						</li>
						<br>
						<li class="fragment">üîé &nbsp; <b>√âtudes exp√©rimentales</b> pour approfondir nos connaissances
						</li>
					</ul>
				</section>

				<section>
					<h3>üñºÔ∏è &nbsp; Contextes</h3>
					<div class="r-stack">

					</div>
				</section>

				<section>
					<h3>üóìÔ∏è &nbsp; Organisation</h3>
					<ol style="font-weight: bold;">
						<li>√âtat de l'art</li>
						<br>
						<li>SNNs pour la localisation d'objet</li>
						<br>
						<li>Pr√©-entra√Ænement auto-supervis√© pour la vision √©v√©nementielle</li>
						<br>
						<li>Conclusion</li>
					</ol>
				</section>
			</section>

			<section>
				<section>
					<h1>√âtat de l'Art</h1>
				</section>

				<section>
					<h3>üìö &nbsp; Trois Domaines</h3>
					<ul>
						<li>üë¥ &nbsp; <b>Approches classiques</b> : <span class="ita">ANN + images</span></li>
						<br>
						<li>‚ö° &nbsp; <b>R√©seaux de neurones impulsionnels</b></li>
						<br>
						<li>üì∏ &nbsp; <b>Vision √©v√©nementielle</b> : vision artificielle avec des cam√©ras
							√©v√©nementielles</li>
					</ul>
				</section>

				<section>
					<h3>üë¥ &nbsp; Approches Classiques</h3>
					<ul>
						<li><b>‚ö∞Ô∏è &nbsp; Historiquement :</b> </li>
						<ul>
							<li>Descripteurs <span class="ita">(ORB<small>[TODO]</small>, SIFT<small>[TODO]</small>)</span> en entr√©e d'un mod√®le d'apprentissage classique <span class="ita">(SVM)</span></li>
						</ul>
						<br>
						<li><b>üóº Apprentissage profond : </b> entra√Ænement d'une architecture ANN profonde par la <b>r√©tropropagation du gradient</b></li>
					</ul>
				</section>

				<section>
					<h3>üë¥ &nbsp; Approches Classiques</h3>
					<p><b>√âvolutions marquantes</b></p>

					<div class="r-stack">
						<figure class="fragment fade-in-then-out">
							<figcaption>Neurone artificiel</figcaption>
							<img src="these/sota/artificial_neuron.png" alt="artificial neuron">
						</figure>
						<figure class="fragment fade-in-then-out">
							<figcaption>Multi-layer Perceptron (<span class="ita">MLP</span>)</figcaption>
							<img src="these/sota/mlp.png" height="450px" alt="artificial neuron">
						</figure>

						<figure class="fragment fade-in-then-out">
							<figcaption>Convolution</figcaption>
							<img src="these/sota/convolution.png" height="450px" alt="artificial neuron">
						</figure>

						<ul class="fragment fade-in-then-out">
							<li>Adoption des <b>r√©seaux de neurones convolutifs</b> <span class="ita">(CNNs)</span></li>
							<ul>
								<li><b>AlexNet</b><small>[TODO]</small> (2012) atteint les meilleures performances sur <b>ImageNet</b><small>[TODO]</small></li>
								<li><b>ResNet</b><small>[TODO]</small> introduit la notion de blocs r√©siduels</li>
								<li>...</li>
								<br>
								<li>Convolutions 2D pour les images : <b>2D-CNN</b></li>
								<li>Convolutions 3D pour les vid√©os : <b>3D-CNN</b></li>
							</ul>
						</ul>

						<ul class="fragment fade-in-then-out">
							<li><b>Plus r√©cemment</b> (2020)</li>
							<br>
							<ul>
								<li>Arriv√©e des <b>transformeurs de vision <span class="ita">(ViT)</span></b></li>
								<br>
								<li><span style="color:red;">Besoin en donn√©es annot√©es massif</span> ‚û°Ô∏è apprentissage auto-supervis√© <span class="ita">(SSL)</span></li>
								<br>
								<li><b>Mod√®les de fondations :</b> mod√®les de grande envergure pr√©-entra√Æn√©s</li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Formulations - R√©seau de Neurones</h3>
					<div class="r-stack">
						<div class="fragment fade-out">
							<p>
								$f_{\alpha}(Input) = Output$
							</p>
							<ul>
								<li>$f_{\alpha}$ $\rightarrow$ r√©seau de neurones dont $\alpha$ est l'ensemble des poids entra√Ænables</li>
								<li>$Input$ $\rightarrow$ les donn√©es en entr√©e</li>
								<li>$Output$ $\rightarrow$ les caract√©ristiques en sortie</li>
								<br>
								<li>üÉè &nbsp; <b>Adaptabilit√© :</b> le format de $Input$ et $Output$ est manipulable selon la t√¢che vis√©e </li>
							</ul>
						</div>
						<div class="fragment fade-in-then-out">
							<p><b>Classification</b></p>
							<p>
								$f_{\alpha}(\mathbf{I}) = c$
							</p>
							<br>
							<ul>
								<li> $\mathbf{I} \in \mathbb{R}^{C \times H \times W}$ $\rightarrow$ image statique de r√©solution $(H \times W)$ avec $C$ canaux</li>
								<br>
								<li>$c \in [1,\mathcal{C}]$ $\rightarrow$ pr√©diction de la classe parmi $\mathcal{C}$ cat√©gories</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Formulations - Encodeur Convolutif</h3>
					<p>üìñ &nbsp; Un 2D-CNN <span class="ita">(ou 3D-CNN) est utilis√© pour extraire un <b>vecteur de caract√©ristiques</b> √† partir de <b>donn√©es visuelles</b> <span class="ita">(ex. une image)</span></span></p>
					<br>
					<p class="fragment" data-fragment-index="0">
						$f_{\alpha}(\mathbf{I}) = \mathcal{F}$
					</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li>$\mathcal{F} \in \mathbb{R}^{K}$ $\rightarrow$ le vecteur de caract√©ristiques de $K$ entr√©es</li>
					</ul>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>R√©seaux de neurones compos√©s de <b style="color: orange; border-bottom: solid 3px orange;">neurones impulsionnels</b></p>
					<div class="r-stack">
						<p></p>
						<img src="these/sota/artificial_impulsion_0.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_1.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_2.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_3.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion.png" alt="annvssnn" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Neurone "Integrate-and-Fire" (IF)</b></p>
					
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>Codage neuronal</p>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>Techniques d'apprentissage</p>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>Surrogate gradient</p>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>Mat√©riel Neuromorphique</p>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>Verrous Scientifiques</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Cam√©ra</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Avantages</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>√âvolution cam√©ras + changement paradigme</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Formulation g√©n√©ration √©v√©nements</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Repr√©sentation √©v√©nements</p>
					<ul>
						<li>Images √©v√©nementielles (d√©tails)</li>
						<li>Surfaces temporelles</li>
						<li>Voxels</li>
						<li>Graphes</li>
						<li>Entra√Ænable</li>
						<li>Traitement direct</li>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Contribution Bina-Rep</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>T√¢ches de vision</p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Bases de donn√©es (diff√©rentiations) </p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p>Verrous scientifiques</p>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Bilan</h3>
					<p>Introduire les probl√®mes qu'on traite et basta-zer</p>
				</section>
			</section>

			<section>
				<section>
					<h2>R√©seaux de Neurones Impulsionnels <br> pour la Localisation d'Objet</h2>
				</section>

				<section>
					<h3>üñºÔ∏è &nbsp; Contexte</h3>
					<ul>
						<li>üí™ &nbsp; L'apprentissage profond par SG est efficace...</li>
						<li>üë∂ &nbsp; ... mais est encore r√©cent :</li>
						<ul>
							<li>‚û°Ô∏è &nbsp; Peu de t√¢ches de vision √©tudi√©es</li>
							<li>‚û°Ô∏è &nbsp; Manque d'analyses</li>
						</ul>
						<br>
						<li class="fragment"><b>Dans ce travail :</b></li>
						<ul>
							<li class="fragment"><b>D√©veloppement</b> d'un SNN Convolutif (<span class="ita">CSNN</span>) pour la <b>localisation d'objet</b></li>
							<li class="fragment"><b>Analyses</b> du comportement de ce CSNN selon divers aspects</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üó®Ô∏è &nbsp; Formulation - Localisation d'Objet</h3>
					<div class="r-stack">
						<img src="these/localization/localization_formulation_0.png" alt="local forma">
						<img src="these/localization/localization_formulation_1.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_2.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_3.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_4.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation.png" alt="local forma" class="fragment fade-in-then-out">
						<div class="fragment">
							<p><b>Pourquoi cette t√¢che ?</b></p>
							<ul style="list-style-type: '‚úîÔ∏è&nbsp;  ';">
								<li>Traitement de l'information spatiale</li>
								<li>Plus simple que des t√¢ches similaires (<span class="ita">d√©tection d'objets, ...</span>)</li>
								<li>Sc√®nes complexes</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üïµÔ∏è &nbsp; Preuve de Concept Pr√©liminaire</h3>
					<p style="border: 3px solid red; color:red; margin:10px; font-weight: bold;">‚ùì Est-ce que c'est possible ?</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li style="color:green;"><b>‚úÖ &nbsp; Valid√©</b></li>
						<ul>
							<li>üß± &nbsp; CSNN profond <b>encodeur-d√©codeur</b></li>
							<li>üìü &nbsp; Images statiques avec <b>codage fr√©quentiel</b></li>
							<li>üëç &nbsp; R√©sultats <b>encourageants</b></li>
						</ul>
					</ul>
					<br>
					<br>
					<p style="border: solid 2px; padding: 10px;" class="fragment" data-fragment-index="0"><small>üì∞<span class="ita"><span class="ita"></span> &nbsp; Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning <br><b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></span></small></p>
				</section>

				<section>
					<h3>üîé &nbsp; Aspects √âtudi√©s</h3>
					<ol>
						<li><b>Deux modalit√©s √©tudi√©es : </b>images statiques et flux d'√©v√©nements</li>
						<br>
						<li><b>Latence temporelle</b> ($T$)</li>
						<br>
						<li><b>Robustesse aux corruptions des capteurs</b></li>
						<br>
						<li><b>Estimation du co√ªt √©nerg√©tique</b></li>
						<br>
						<li><b>Codages neuronaux pour les images</b></li>
					</ol>
				</section>

				<section>
					<h3>‚öîÔ∏è &nbsp; √âtude Comparative</h3>
					<p style="border: solid 3px;">‚ùó&nbsp; On compare un encodeur convolutif CSNN avec un <b>ANN d'architecture similaire : un 2D-CNN</b></p>
					<br>
					<ul>
						<li>üéØ &nbsp; identifier les diff√©rences dans le traitement des donn√©es visuelles</li>
						<br>
						<li>üë• &nbsp; architecture et complexit√© similaires</li>
					</ul>
				</section>

				<section>
					<h3>üß† &nbsp; Encodeur Convolutif - ANN</h3>
					<div class="r-stack">
						<img src="these/localization/ann_archi_0.png" alt="ANN">
						<img src="these/localization/ann_archi_1.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_2.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_3.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_4.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi.png" alt="ANN" class="fragment">
					</div>
				</section>

				<section>
					<h3>üß† &nbsp; Encodeur Convolutif - SNN</h3>
					<div class="r-stack">
						<img src="these/localization/snn_archi_0.png" alt="SNN">
						<img src="these/localization/snn_archi_1.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_2.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_3.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_4.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_5.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_6.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_7.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_8.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi.png" alt="SNN" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; Tenseur Impulsionnel</h3>
					<div class="r-stack">
						<img src="these/localization/inputs_0.png" alt="input">
						<img src="these/localization/inputs_1.png" alt="input" class="fragment">
						<img src="these/localization/inputs_2.png" alt="input" class="fragment">
						<img src="these/localization/inputs_3.png" alt="input" class="fragment">
						<img src="these/localization/inputs.png" alt="input" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìÅ &nbsp; Bases de Donn√©es</h3>
					<div class="r-stack">
						<img src="these/localization/datasets_0.png" alt="data">
						<img src="these/localization/datasets_1.png" alt="data" class="fragment">
						<img src="these/localization/datasets.png" alt="data" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìü &nbsp; Images Statiques - Codages Neuronaux</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/nc/original.png" alt="origi" height="375px">
								<p style="text-align: center;">
									Original
								</p>
							</td>
							<td>
								<div class="r-stack">
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/rate.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage fr√©quentiel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/ttfs.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage temporel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/phase.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage par phases</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/saccade.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>üÜï &nbsp; Codage par saccades</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<p style="text-align: center; margin-top: 5px;"><b>Codage entra√Ænable</b></p>
									</div>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Latence Temporelle</h3>
					<div class="r-stack">
						<ul class="fragment fade-out">
							<li><b>Protocole :</b></li>
							<ol>
								<li>D√©finir un nombre $T$ d'√©tapes temporelles</li>
								<li>Mesurer la performance de localisation ($mIoU$)</li>
							</ol>
						</ul>
						<img src="these/localization/latence_images_1.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_2.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_3.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_4.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_5.png" alt="latence image" class="fragment fade-in-then-out">
						<ul class="fragment fade-in-then-out">
							<li>‚ùå &nbsp; Aucune corr√©lation significative entre $T$ et les performances</li>
							<br>
							<li>‚ùó &nbsp; Comparaison des codages neuronaux</li>
							<ul>
								<li>Observations contraires aux r√®gles biologiques (STDP)</li>
							</ul>
							<br>
							<li>ü•à &nbsp; Performances inf√©rieures √† l'ANN mais comp√©titives</li>
						</ul>
						<img src="these/localization/latence_images_best.png" alt="latence image" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Robustesse</h3>
					<div class="r-stack">
						<img src="these/localization/img_corrup/protocol_0.png" alt="corr proto">
						<img src="these/localization/img_corrup/protocol_1.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_2.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_3.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_4.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_5.png" alt="corr proto" class="fragment fade-in-then-out">
					</div>
				</section>


				<section>
					<h3>üì∑ &nbsp; Images Statiques - Corruptions</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/img_corrup/normal.png" alt="normal">
								<p style="text-align: center; font-weight: bold;">Original</p>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/gaussian.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit gaussien
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/sp.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit poivre & sel
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/jpeg.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Compression JPEG
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/flou.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Flou de d√©focalisation
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/frost.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Perturbations du givre
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption et chaque codage neuronal</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_0.png" alt="mrad">
						<img src="these/localization/img_corrup/mrad_1.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_2.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_3.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_4.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_5.png" alt="mrad" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Latence Temporelle</h3>
					<div class="r-stack">
						<img src="these/localization/latence_events_0.png" alt="latence events">
						<img src="these/localization/latence_events.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_1.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_2.png" alt="latence events" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Latence Temporelle</h3>
					<p><b>Trois Avantages d'une faible valeur $T$</b></p>					
					<ol>
						<li>üèÉ SNN est plus <b style="color:green;">rapide</b></li>
						<br>
						<li>ü™´ SNN est <b  style="color:green;">√©conome</b> en √©nergie</li>
						<br>
						<li>üí™ SNN plus <b style="color:green;">performant</b></li>
					</ol>
					<br>
					<br>
					<p class="fragment" style="color:orange;">‚ö†Ô∏è &nbsp; Base de donn√©es √† <b>comportement statique</b></p>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Corruptions</h3>
					<table>
						<tr>
							<td>
								<figure>
									<img src="these/localization/img_corrup/normal.gif" alt="normal">
									<figcaption style="text-align: center; font-weight: bold;">
										
										Original
									</figcaption>
								</figure>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/baa.gif" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit d'activit√© de fond
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/hotpix.gif" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit "hot pixels"
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_events_0.png" alt="mrad_events">
						<img src="these/localization/img_corrup/mrad_events.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_2.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_3.png" alt="mrad_events" class="fragment">
					</div>
				</section>

				<section>
					<h3>üîã &nbsp; Consommation √ânerg√©tique</h3>
					<p style="color: red;">‚ùå &nbsp; Une puce neuromorphique ad√©quate est difficilement accessible</p>
					<br>
					<ul>
						<li>‚û°Ô∏è &nbsp; <b>Estimation de l'√©nergie consomm√©e</b><small>[TODO]</small></li>
						<br>
						<ul>
							<li>Calcul des FLOPs effectu√©s lors de l'inf√©rence</li>
							<li style="list-style: none;">‚ÑπÔ∏è &nbsp; <b><span class="ita">(li√© au nombre d'impulsions √©mises)</span></b></li>
							<br>
							<li>Estimation sur une puce CMOS de 45nm <small>[TODO]</small></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîã &nbsp; Consommation √ânerg√©tique</h3>
					<div class="r-stack">
						<img src="these/localization/conso_0.png" alt="conso">
						<img src="these/localization/conso_1.png" alt="conso" class="fragment">
						<img src="these/localization/conso_2.png" alt="conso" class="fragment">
						<img src="these/localization/conso_3.png" alt="conso" class="fragment">
						<img src="these/localization/conso.png" alt="conso" class="fragment">
						<img src="these/localization/conso_4.png" alt="conso" class="fragment">
						<img src="these/localization/conso_5.png" alt="conso" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìç &nbsp; Bilan de l'√âtude</h3>
					<ul>
						<li class="fragment"><b>Sup√©riorit√© des faibles latences</b></li>
						<li class="fragment"><b>Codages Neuronaux</b></li>
						<div class="r-stack">
							<img src="these/localization/bilan_0.png" alt="coucou">
							<img src="these/localization/bilan_1.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_2.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_3.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_4.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_5.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_6.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_7.png" alt="coucou" class="fragment">
						</div>
						<li  class="fragment"><b>SNN comp√©titif</b></li>
						<ul  class="fragment">
							<li>Efficacit√© √©nerg√©tique ü•á</li>
							<li><b>√âv√©nements :</b> performance - robustesse üëé</li>
							<li><b>Images :</b> Performance ü•à - robustesse üëç</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üòÉ &nbsp; Spiking-FER - Contribution</h3>
					<p><b>Reconnaissance d'Expressions Faciales √âv√©nementielle avec un CSNN</b></p>
					<div class="r-stack">
						<img src="these/localization/spikingfer_0.png" alt="fer">
						<img src="these/localization/spikingfer_1.png" alt="fer" class="fragment">
						<img src="these/localization/spikingfer_2.png" alt="fer" class="fragment">
					</div>
					<p class="fragment"><b>√âtudes exp√©rimentales :</b> augmentations de donn√©es...</p>
					<p style="border: solid 2px; padding: 10px;" class="fragment"><small>üì∞<span class="ita"><span class="ita"></span> &nbsp; Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras <br><b>2023 International Conference on Content-Based Multimedia Indexing (CBMI). ACM, 2023.</b></span></small></p>
				</section>
			</section>

			<section>
				<section>
					<h2>Pr√©-entra√Ænement Auto-supervis√© <br> pour la Vision
							√âv√©nementielle</h2>
				</section>

				<section>
					<h3>üñºÔ∏è &nbsp; Contexte</h3>
					<ul>
						<li>üìà &nbsp; Mod√®les profonds pour la vision √©v√©nementielle</li>
						<li><b>Apprentissage supervis√© :</b> n√©cessite beaucoup de donn√©es annot√©es</li>
						<li style="color:red;" class="fragment" data-fragment-index="0">
							‚û°Ô∏è &nbsp; Complexifie le d√©veloppement de nouvelles applications
						</li>
						<br>
						<li class="fragment" data-fragment-index="1"><b style="color:green;">Solution Propos√©e : </b>
							Apprentissage auto-supervis√©</li>
						<ul class="fragment" data-fragment-index="1">
							<li>Pr√©-entra√Æner un mod√®le sur des donn√©es <b>sans n√©cessiter d'annotations</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üìö &nbsp; Solutions Existantes</h3>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0"
							src="these/pretraining_explained_0.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="1"
							src="these/pretraining_explained_1.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="2"
							src="these/pretraining_explained.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="3"
							src="these/pretraining_explained_2.png" alt="pretraining">
						<div class="fragment fade-in-then-out" data-fragment-index="4">
							<img src="these/pretraining_supervised.png" alt="pretraining">
							<ul>
								<li><b>Supervis√© :</b> utiliser une grande BDD <span class="ita">g√©n√©rique</span>
									annot√©e puis affiner</li>
								<ul>
									<li>üëé &nbsp; peu de BDDs √©v√©nementielles pertinentes</li>
								</ul>
							</ul>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="5">
							<img src="these/pretraining_ssl.png" alt="pretraining">
							<ul>
								<li><b>Apprentissage Auto-supervis√© de Repr√©sentation <span class="ita">(SSRL)</span> :</b> capturer les propri√©t√©s et motifs intrins√®ques des donn√©es </li>
								<ul>
									<li>üëç &nbsp; pas d'annotations requises</li>
									<li>üëç &nbsp; proche du domaine d'application</li>
								</ul>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üìö &nbsp; Solutions Existantes - SSRL √©v√©nementiel</h3>
					<ul>
						<li>Peu de travaux existants</li>
						<br>
						<li>T√¢ches de bas-niveau (flux optique, ...) <small>[TODO,TODO]</small></li>
						<br>
						<li>Travaux concurrents pour les r√©seaux profonds <span class="ita">(3)</span><small>[TODO,TODO,TODO]</small></li>
						<ul>
							<li>üëé &nbsp; limit√©s √† du <span style="color: red;">comportement statique</span></li>
							<li>üëé &nbsp; concentr√©s sur <span style="color: red;">un seul type de r√©seau</span> <span class="ita">(ViT / SNN)</span></li>
						</ul>
					</ul>
				</section>			
				
				<section>
					<h3>üìö &nbsp; Solutions Existantes - SSRL √©v√©nementiel</h3>
					<p><b>Constat</b></p>
					<ul>
						<li>Domaine <b>tr√®s prometteur</b> pour r√©duire le besoin en annotations...</li>
						<li>... mais <b>tr√®s peu √©tudi√©</b></li>
					</ul>

					<p></p>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<ul>
						<li><b>üß† &nbsp; Mod√®les vis√©s :</b> encodeurs convolutifs l√©gers <span class="ita">(CSNN, 2D-CNN, et 3D-CNN)</span></li>
						<br>
						<li><b>üìÅ &nbsp; Polyvalence des donn√©es :</b> comportements statiques et dynamiques</li>
						<br>
						<li><b>üë• &nbsp; Architecture d'encodage conjoint</b></li>
						<ul>
							<li class="fragment">Architecture en <b>deux branches</b></li>
							<li class="fragment"><b>Deux versions transform√©es</b> de la m√™me entr√©e</li>
							<li class="fragment">Augmentations de donn√©es √©v√©nementielle <b><span class="ita">(EDAs)</span></b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Augmentation de Donn√©es √âv√©nementielle</b> (EDA)</p>
					<div class="r-stack">
						<img src="img/ssl/dataaug_0.png" data-fragment-index="0" alt="data" class="fragment">
						<img src="img/ssl/dataaug_1.png" data-fragment-index="1" alt="data" class="fragment">
						<img src="img/ssl/dataaug.png" data-fragment-index="2" alt="data" class="fragment">
						<img src="img/ssl/dataaug_comp.png" alt="data" class="fragment" data-fragment-index="3">
						<img src="img/ssl/dataaug_comp2.png" alt="data" class="fragment" data-fragment-index="4">
						<img src="img/ssl/dataaug_comp3.png" alt="data" class="fragment" data-fragment-index="5">
					</div>
					<p class="fragment" data-fragment-index="3">Une EDA peut √™tre une <b>composition</b> d'autres EDAs</p>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Architecture d'Encodage Conjoint</b><small>[TODOvicreg,TODObarlow]</small></p>
					<div class="r-stack">
						<img src="these/archi_ssl_0.png" alt="archi ssl">
						<img src="these/archi_ssl_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_2.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_5.png" alt="archi ssl" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					
					<p><b>Encodeurs √©tudi√©s</b></p>
					<ul>
						<li><b>2D-CNN : </b>ResNet-18<small>[TODOresnet]</small></li>
						<li><b>3D-CNN : </b>MC3-ResNet-18<small>[TODOresnet3d]</small></li>
						<li><b>CSNN : </b>SEW-ResNet-18<small>[TODOsew]</small></li>
					</ul>
					<br>
					<br>
					<ul style="list-style: none;">
						<li>‚ÑπÔ∏è &nbsp; M√™me complexit√© <span class="ita">($\approx$11M param√®tres)</span></li>
						<li>‚ÑπÔ∏è &nbsp; Repr√©sentations $\mathbf{Y}^d \in \mathbb{R}^{K = 512}$</li>
					</ul>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Variantes</b></p>
					<div class="r-stack">
						<img src="these/variants_ssl_0.png" alt="variantes ssl">
						<img src="these/variants_ssl_1.png" alt="variantes ssl" class="fragment" data-fragment-index="1">
						<img src="these/variants_ssl.png" alt="variantes ssl" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>üë¨ &nbsp; Jumeaux : </b>architecture classique avec poids partag√©s</li>
						<br>
						<li class="fragment" data-fragment-index="2"><b>üë®‚Äçüéìüßë‚Äçüè´ &nbsp; √âtudiant-Professeur : </b>CSNN (<span class="ita">√©tudiant</span>) coupl√© √† 2D-/3D-CNN (<span class="ita">professeur</span>)</li>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; √âtude sur les EDAs</h3>
					<p>√Ä chaque inf√©rence, une composition $d_A$ / $d_B$ est √©chantillonn√©e d'une distribution $D$</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0" src="these/archi_ssl_6.png" alt="ssl d">
						<img class="fragment fade-in-then-out" data-fragment-index="1" src="these/eda_distrib_0.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="2" src="these/eda_distrib_1.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="3" src="these/eda_distrib_2.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="4" src="these/eda_distrib.png" alt="distrib d">
						<p class="fragment" data-fragment-index="5"><b>‚ö†Ô∏è D√©finir une distribution $D$ efficace est essentiel ‚ö†Ô∏è </b></p>
					</div>
				</section>

				<section>
					<h3>ü™Ñ &nbsp; EDAs √âtudi√©es</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Exemple</b></p>
						<p style="border: solid 3px  blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="1"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Augmentations Communes</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="5"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11"><b>Augmentations en D√©coupage</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="12"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="14"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="15"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="16"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="17"><b>Augmentations G√©om√©triques</b></p>
					</div>
					<div class="r-stack">
						<img src="these/eda/normal.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="0">
						<p class="fragment fade-in-then-out" data-fragment-index="1">üìñ &nbsp; Transformations couramment utilis√©es, ne partagent <b>pas de caract√©ristiques communes</b>.</p>
						<img src="these/eda/background_activity.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/eda/polarity_flip.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/eda/crop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="4">

						<p class="fragment fade-in-then-out" data-fragment-index="5">üìñ &nbsp; Transformations impliquant la <b>suppression d'√©v√©nements</b>.</p>
						<img src="these/eda/cutout.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/eda/drop_by_time.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/eda/random_drop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="8">
						<img src="these/eda/event_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="9">
						<img src="these/eda/event_copy.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="10">
						<img src="these/eda/event_copy_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="11">

						<p class="fragment fade-in-then-out" data-fragment-index="12">üìñ &nbsp; Transformations impliquant une <b>distorsion spatiale des √©v√©nements</b>.</p>
						<img src="these/eda/static_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="13">
						<img src="these/eda/static_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="14">
						<img src="these/eda/dynamic_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="15">
						<img src="these/eda/dynamic_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="16">
						<img src="these/eda/stat_dyn_geo.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="17">

					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2">Bruit d'activit√© de fond (<code>Noise</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="3">Inversion de polarit√© (<code>PolFlip</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">Recadrage (<code>Crop</code>)</p>
						<!-- decoupage-->
						<p class="fragment fade-in-then-out" data-fragment-index="5"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6">D√©coupe par zone (<code>Cutout</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="7">D√©coupe par dur√©e</p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">D√©coupe al√©atoire</p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><code>EventDrop</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10">üÜï &nbsp; <code>EventCopy</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11">üÜï &nbsp; <code>EventCopyDrop</code></p>
						<!-- geo -->
						<p class="fragment fade-in-then-out" data-fragment-index="12"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13">Translation statique (<code>StatTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="14">Rotation statique (<code>StatRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="15">üÜï &nbsp; Translation dynamique (<code>DynTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="16">üÜï &nbsp; Rotation dynamique (<code>DynRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="17">üÜï &nbsp; <code>StatDynGeo</code></p>
					</div>
				</section>

				<section>
					<h3>‚öñÔ∏è &nbsp; √âvaluation des Performances</h3>
					<p style="border: solid 3px red; margin:10px; color:red;">üö´ &nbsp; Pas de protocole d'√©valuation commun en SSRL √©v√©nementiel</p>
					<br>
					<ul>
						<li class="fragment">‚úÖ &nbsp; <b style="color:green;">Solution :</b> d√©finir des <b>protocoles d'√©valuation standard</b> pour les travaux futurs</li>
						<ul>
							<li class="fragment">BDDs populaires <span class="ita">(classification &nbsp; ‚û°Ô∏è &nbsp; taux de pr√©cision)</span></li>
							<li class="fragment">Trois protocoles pour √©valuer des aspects sp√©cifiques du SSRL</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üìÅ &nbsp; Bases de Donn√©es</h3>
					<div class="r-stack">
						<img src="these/bdd_ssl_0.png" alt="bdd">
						<img src="these/bdd_ssl_1.png" alt="bdd" class="fragment" data-fragment-index="0">
						<img src="these/bdd_ssl.png" alt="bdd" class="fragment" data-fragment-index="2">
					</div>
				</section>

				<section>
					<h3>Protocole 1Ô∏è‚É£ &nbsp;- √âvaluation Lin√©aire</h3>
					<div class="r-stack">
						<img src="these/linear_0.png" alt="linear">
						<img src="these/linear_1.png" alt="linear" class="fragment">
						<img src="these/linear_2.png" alt="linear" class="fragment">
						<img src="these/linear_3.png" alt="linear" class="fragment">
						<img src="these/linear.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL <b>extrait des caract√©ristiques pertinentes ?</b></p>
				</section>

				<section>
					<h3>Protocole 2Ô∏è‚É£ &nbsp;- Apprentissage Semi-supervis√©</h3>
					<div class="r-stack">
						<img src="these/semisup_0.png" alt="linear">
						<img src="these/semisup_1.png" alt="linear" class="fragment">
						<img src="these/semisup_2.png" alt="linear" class="fragment">
						<img src="these/semisup.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL permet de <b>r√©duire le besoin en annotations ?</b></p>
				</section>

				<section>
					<h3>Protocole 3Ô∏è‚É£ &nbsp;- Transfert d'Apprentissage</h3>
					<div class="r-stack">
						<img src="these/transfer_0.png" alt="linear">
						<img src="these/transfer_1.png" alt="linear" class="fragment">
						<img src="these/transfer_2.png" alt="linear" class="fragment">
						<img src="these/transfer_3.png" alt="linear" class="fragment">
						<img src="these/transfer.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que les caract√©ristiques apprises peuvent <b>√™tre transf√©r√©es √† d'autres donn√©es ?</b></p>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>‚ûï &nbsp; √âtude incr√©mentale</b></p>
					<ul>
						<li><b>Trois √©tapes progressives : </b>une √©tape par cat√©gorie d'EDA</li>
						<br>
						<li>Pour chaque √©tape, on conserve la combinaison d'EDAs <b>la plus performante de l'√©tape pr√©c√©dente</b></li>
						<br>
						<li>Protocole d'<b>√©valuation lin√©aire</b> sur <b>DVSGesture</b></li>
					</ul>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>R√©sultats</b></p>
					<div class="r-stack">
						<img alt="tab result edas" src="these/results_edas/tab_0.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_1.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_2.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_3.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_4.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_5.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_6.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_7.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_8.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_9.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_10.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_11.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_12.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_13.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_14.png">
					</div>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>Interpr√©tations</b></p>
					<ol>
						<li>‚ûï EDAs communes $\rightarrow$ ‚ûï performances </li>
						<br>
						<li>Une EDA g√©om√©trique et une EDA en d√©coupage $\rightarrow$ ‚ûï performances</li>
						<br>
						<li>Relations <code>OneOf</code> üëç &nbsp; <span class="ita">(<code>EventDrop</code>, ...)</span></li>
					</ol>
					<br>
					<br>
					<p class="fragment">$D = \{\texttt{Noise,Crop,PolFlip,StatDynGeo,}$ $\texttt{EventCopyDrop}\}$</p>
				</section>

				<section>
					<h3>‚öñÔ∏è &nbsp; √âvaluation des Performance</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="5"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>

						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Transfert d'Apprentissage</b></p>
					</div>
					<div class="r-stack">
						<img src="these/results_ssl/tab_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/results_ssl/tab_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/results_ssl/tab_2.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/results_ssl/tab_3.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/results_ssl/tab_4.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="4">
						<img src="these/results_ssl/tab_5.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="5">

						<img src="these/results_ssl/transfer_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/results_ssl/transfer_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/results_ssl/transfer.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="8">
					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">2D-/3D-CNNs $>$ CSNN</p>
						<p class="fragment fade-in-then-out" data-fragment-index="5">Int√©r√™t de la variante "√âtudiant-Professeur"</p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">‚úÖ &nbsp; transf√©rabilit√© des repr√©sentations apprises</p>
					</div>
				</section>

				<section>
					<h3>Mise en Perspective</h3>
					<p><b>‚ùì &nbsp; Comment se compare-t-on aux m√©thodes supervis√©es ?</b></p>
					<img class="fragment" src="these/results_ssl/perspective.png" alt="perspective">
					<ul>
						<li class="fragment">üí™ &nbsp; R√©sultats <b>comp√©titifs</b>...</li>
						<li class="fragment">ü™∂ &nbsp; ... avec des mod√®les <b>plus l√©gers</b>...</li>
						<li class="fragment">‚úÇÔ∏è &nbsp;... sans apprentissage supervis√© !</li>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Analyses des Repr√©sentations</h3>
					<ul>
						<li>‚ö†Ô∏è &nbsp; Les taux de pr√©cision sont des <b>mesures indirectes</b></li>
						<li>‚û°Ô∏è &nbsp; Analyser les propri√©t√©s des repr√©sentations</li>
					</ul>

					<br>
					<br>
					<ul class="fragment">
						<li><b>Deux analyses</b></li>
						<ol>
							<li class="fragment semi-fade-out"><b>Qualit√© des repr√©sentations : </b>compromis d'Uniformit√© - Tol√©rance</li>
							<li class="fragment grow"><b>Similarit√© des repr√©sentations : </b>analyse par alignement de noyau centr√© lin√©aire <span class="ita">(CKA lin√©aire)</span></li>
						</ol>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Similarit√© des Repr√©sentations</h3>
					<ul>
						<li><b>CKA Lin√©aire :</b></li>
						<ul>
							<li>Utilis√©e en SSRL pour les images<small>[TODOCKA]</small></li>
							<li>Compare les repr√©sentations de <b>deux encodeurs</b></li>
							<li>Donne une valeur $\in [0,1]$ √©valuant leur similarit√©</li>
						</ul>
						<br>
						<li><b>üéØ &nbsp; Nos objectifs :</b></li>
						<ul>
							<li>Comparer tous les encodeurs entre eux...</li>
							<li>... selon chaque bloc r√©siduel</li>
							<li><b>Base de donn√©es :</b> DVSGesture</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Similarit√© des Repr√©sentations</h3>
					<div class="r-stack">
						<img src="these/results_ssl/cka_0.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_1.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_2.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_3.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_4.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_5.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_6.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_7.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_8.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_9.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_10.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_11.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_12.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_13.png" alt="cka" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìç &nbsp; Bilan</h3>
					<ul>
						<li><b>Contributions</b></li>
						<ul>
							<li>M√©thode de SSRL √©v√©nementielle pour les encodeurs convolutifs</li>
							<li>Protocoles d'√©valuation standardis√©s</li>
							<li>√âtudes exp√©rimentales</li>
						</ul>
						<br>
						<li><b>Observations</b></li>
						<ul>
							<li>üí™ &nbsp; Efficacit√© et polyvalence de la m√©thode</li>
							<li>ü™Ñ &nbsp; D√©finition d'une distribution d'EDAs efficace</li>
							<li>üîé &nbsp; Diff√©rences int√©ressantes dans les repr√©sentations</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîì &nbsp; Am√©liorations Possibles</h3>
					<ul>
						<li><b>Sp√©cialiser la m√©thode</b> selon le type d'encodeur</li>
						<br>
						<li><b>Diversifier</b> les protocoles d'√©valuation <span class="ita">(d√©tection, ...)</span></li>
						<br>
						<li>M√©thode fonctionnant sur <b>une seule √©tape temporelle</b></li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>

				<section>
					<h3>Bilan des Contributions</h3>
				</section>

				<section>
					<h3>Travaux Futurs</h3>
				</section>
			</section>

			<section>
				<p class="r-fit-text">Merci !</p>
			</section>

			<section>
				<h3>References</h3>
				<ul style="list-style: none;">
					<li><small><b>[NameYEAR]: </b>M. Sajjad, et al. "A comprehensive survey on deep facial expression
							recognition: challenges, applications, and future guidelines"</small></li>
					<li><small><b>[Bokovoy2019]: </b>A. Bokovoy et al. "Real-time Vision-based Depth Reconstruction with
							NVidia Jetson"</small></li>
					<li><small><b>[Desislavov2023]: </b>R. Desislavov et al. "Trends in AI inference energy consumption:
							Beyond the performance-vs-parameter laws of deep learning"</small></li>
				</ul>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Bina-Rep</h4>
				</section>

				<section>
					<h3>Bina-Rep</h3>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Localisation</h4>
				</section>

				<section>
					<h3>Images Statiques - Latence</h3>
					<img src="these/localization/latence_full.png" alt="latence full" height="600px">
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>SSRL √âv√©nementiel</h4>
				</section>

				<section>
					<h3>dIoU</h3>
				</section>

				<section>
					<h3>VICReg</h3>
					<img height="230px" src="these/vicreg_annexe.png" alt="vicreg annexe">
					<ol>
						<li><b>Invariance : </b>minimiser la distance entre les deux encastrements de la m√™me entr√©e</li>
						<li><b>Variance : </b>maintenir la variance de chaque variable d'un m√™me vecteur dans un lot au-dessus d'un seuil</li>
						<li><b>Covariance : </b>minimiser la covariance entre les valeurs d'un m√™me vecteur</li>
					</ol>
				</section>

				<section>
					<h3>Distribution EDAs</h3>
					<img src="these/params_edas.png" alt="param edas" height="600px">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>ASL-DVS</b></p>
					<img height="500px" src="these/results_ssl/perspective_asl.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CARS</b></p>
					<img height="500px" src="these/results_ssl/perspective_ncars.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CALTECH101</b></p>
					<img src="these/results_ssl/perspective_ncaltech101.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DVSGesture</b></p>
					<img src="these/results_ssl/perspective_dvsgesture.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DailyAction-DVS</b></p>
					<img src="these/results_ssl/perspective_dailyactiondvs.png" alt="ASL">
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>R√©sultat + interpretations</p>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>