<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>AvancÃ©es en Vision Neuromorphique : ReprÃ©sentation Ã‰vÃ©nementielle, RÃ©seaux de Neurones Impulsionnels
		SupervisÃ©s et PrÃ©-entraÃ®nement Auto-supervisÃ©</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="css/w3.css">

	<style>
		.ita {
			font-style: italic;
		}

		h1,
		h2,
		h3 {
			text-transform: none !important;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->

			<section>
				<img src="these/entree.png" alt="ent">
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>

				<section>
					<h3> ğŸ‘ï¸â€ğŸ—¨ï¸ &nbsp; Vision Artificielle</h3>
					<p>
						ğŸ“– &nbsp; Extraire automatiquement des <b>informations</b> Ã  partir de <b>donnÃ©es visuelles</b>
					</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img src="these/detection_exemple.png" alt="detection">
							<!-- <figcaption>DÃ©tection d'objets</figcaption> -->
						</figure>

						<figure class="fragment fade-in-then-out" data-fragment-index="2">
							<img src="these/vslam.gif" alt="detection">
							<figcaption><small>[Bokovoy2019]</small></figcaption>
						</figure>

						<ul class="fragment fade-in-then-out" data-fragment-index="3">
							<li><b>Applications nombreuses :</b> mÃ©dical, industriel, sÃ©curitÃ©, robotique, ...</li>
							<br>
							<li><b>Comment ?</b> RÃ©seaux de Neurones Artificiels ( <b><span class="ita">ANN</span>s</b>
								) par l'apprentissage profond </li>
						</ul>
					</div>
				</section>

				<section>
					<h3>ğŸ”‹&nbsp; Consommation Ã‰nergÃ©tique</h3>
					<p>Estimation d'Ã©nergie consommÃ©e lors d'une infÃ©rence des modÃ¨les de l'Ã©tat de l'art par
						annÃ©e<small>[Desislavov2023]</small></p>
					<div class="r-stack">
						<img src="these/consommation_energie_0.png" alt="Consommation Ã©nergÃ©tique">
						<img src="these/consommation_energie_1.png" alt="Consommation Ã©nergÃ©tique" class="fragment">
						<img src="these/consommation_energie_2.png" alt="Consommation Ã©nergÃ©tique" class="fragment">
						<img src="these/consommation_energie_3.png" alt="Consommation Ã©nergÃ©tique" class="fragment">
						<img src="these/consommation_energie_4.png" alt="Consommation Ã©nergÃ©tique" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ”‹&nbsp; Consommation Ã‰nergÃ©tique</h3>
					<ul>
						<li><b>Ã‰volution des modÃ¨les</b></li>
						<ul style="list-style-type: 'ğŸ“ˆ'">
							<li class="fragment" data-fragment-index="1"> &nbsp; ComplexitÃ© <span
									class="ita">(profondeur, paramÃ¨tres, ...)</span></li>
							<li class="fragment" data-fragment-index="2"> &nbsp; Puissance de calculs requise</li>
							<li class="fragment" data-fragment-index="3"> &nbsp; Consommation Ã©nergÃ©tique</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="4"><b>Enjeux majeurs</b></li>
						<ul data-fragment-index="4" class="fragment">
							<li>Environnement</li>
							<li>Applications</li>
						</ul>
					</ul>
					<br>
					<br>
					<p class="fragment" data-fragment-index="5" style="color: red;">
						â¡ï¸ &nbsp; <b>ProblÃ©matique principale</b>
					</p>
				</section>

				<section>
					<h3>ğŸ’» &nbsp; Technologie Neuromorphique</h3>
					<p>ğŸ“– &nbsp; Technologie inspirÃ©e par le fonctionnement des neurones biologiques.</p>
					<br>
					<ul class="fragment">
						<li>ğŸ“· &nbsp;<b>Capteur :</b> CamÃ©ra Ã©vÃ©nementielle</li>
						<li>ğŸ§  &nbsp;<b>Traitement :</b> RÃ©seaux de neurones impulsionnels (<b><span
									class="ita">SNN</span></b>)</li>
						<br>
						<li class="fragment">SystÃ¨mes de vision Ã©conomes en Ã©nergie <br> &nbsp;&nbsp;&nbsp;â¡ï¸ &nbsp; <b
								style="color:green">Solution prometteuse</b></li>
					</ul>
				</section>

				<section>
					<h3>ğŸ“· &nbsp; CamÃ©ra Ã‰vÃ©nementielle</h3>
					<ul>
						<li>InspirÃ©e de la biologie</li>
						<li>Ã‰vÃ©nements <b>asynchrones</b> lors d'un changement d'intensitÃ© du pixel</li>
						<!-- <br> -->
						<ul style="list-style-type: none;">
							<li class="fragment">â¡ï¸ <b>Mouvement</b></li>
						</ul>
					</ul>
					<video src="img/Bina_rep/dvscamvisu.mp4" height="300px" muted autoplay controls></video>
					<p><small>Source : <a
								href="https://www.youtube.com/watch?v=LauQ6LWTkxM">https://www.youtube.com/watch?v=LauQ6LWTkxM</a></small>
					</p>
				</section>

				<section>
					<h3>ğŸ§  &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<ul>
						<li>Bio-inspirÃ©s <span class="ita">(neurones impulsionnels)</span></li>
						<li>Neurones communiquent par <b>impulsions asynchrones</b></li>
					</ul>
					<div class="fragment" data-fragment-index="1"><video src="img/Bina_rep/snn_visu.mp4" muted
							height="300px" controls /></div>
					<p class="fragment" data-fragment-index="1"><small>Source : <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
				</section>

				<section>
					<h3>Vision Neuromorphique</h3>
					<ul>
						<li>ğŸ“– &nbsp; IntÃ©grant une camÃ©ra Ã©vÃ©nementielle et/ou un SNN</li>
						<br>
						<li>ğŸ¤ &nbsp; <b>Traitement asynchrone en commun</b></li>
					</ul>
				</section>

				<section>
					<h3>â›°ï¸ &nbsp; DÃ©fis du Neuromorphique</h3>
					<ul>
						<li><b>Par rapport aux mÃ©thodes conventionnelles</b></li>
						<ul>
							<li>Domaine moins Ã©tudiÃ©</li>
							<li>Technologies moins matures</li>
							<li class="fragment" data-fragment-index="1" style="color:red">â¡ï¸ &nbsp; Performances et
								complexitÃ© des approches neuromorphiques moins avancÃ©es</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2"><b>Besoins du domaine</b></li>
						<ul class="fragment" data-fragment-index="2">
							<li>DÃ©veloppement de <b style="color:green">nouvelles approches en vision neuromorphique</b>
							</li>
							<li><b style="color:green">Analyses approfondies</b> pour leur comprÃ©hension</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ¯ &nbsp; Objectifs</h3>
					<p style="border: solid 4px;"><b>ProgrÃ¨s des technologies neuromorphiques dans les tÃ¢ches de vision
							artificielle</b></p>
					<br>
					<ul>
						<li class="fragment">ğŸ§± &nbsp; <b>Conception de modÃ¨les d'apprentissage profond</b> avec SNNs
							et/ou camÃ©ras Ã©vÃ©nementielles
						</li>
						<br>
						<li class="fragment">ğŸ” &nbsp; <b>Ã‰tudes expÃ©rimentales</b> pour approfondir nos connaissances
						</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ–¼ï¸ &nbsp; Contextes</h3>
					<div class="r-stack">

					</div>
				</section>

				<section>
					<h3>ğŸ—“ï¸ &nbsp; Organisation</h3>
					<ol style="font-weight: bold;">
						<li>Ã‰tat de l'art</li>
						<br>
						<li>SNNs pour la localisation d'objet</li>
						<br>
						<li>PrÃ©-entraÃ®nement auto-supervisÃ© pour la vision Ã©vÃ©nementielle</li>
						<br>
						<li>Conclusion</li>
					</ol>
				</section>
			</section>

			<section>
				<section>
					<h1>Ã‰tat de l'Art</h1>
				</section>

				<section>
					<h3>ğŸ“š &nbsp; Trois Domaines</h3>
					<ul>
						<li>ğŸ‘´ &nbsp; <b>Approches classiques</b> : <span class="ita">ANN + images</span></li>
						<br>
						<li>âš¡ &nbsp; <b>RÃ©seaux de neurones impulsionnels</b></li>
						<br>
						<li>ğŸ“¸ &nbsp; <b>Vision Ã©vÃ©nementielle</b> : vision artificielle avec des camÃ©ras
							Ã©vÃ©nementielles</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ‘´ &nbsp; Approches Classiques</h3>
					<ul>
						<li><b>âš°ï¸ &nbsp; Historiquement :</b> </li>
						<ul>
							<li>Descripteurs <span class="ita">(ORB<small>[TODO]</small>, SIFT<small>[TODO]</small>)</span> en entrÃ©e d'un modÃ¨le d'apprentissage classique <span class="ita">(SVM)</span></li>
						</ul>
						<br>
						<li><b>ğŸ—¼ Apprentissage profond : </b> entraÃ®nement d'une architecture ANN profonde par la <b>rÃ©tropropagation du gradient</b></li>
					</ul>
				</section>

				<section>
					<h3>ğŸ‘´ &nbsp; Approches Classiques</h3>
					<p><b>Ã‰volutions marquantes</b></p>

					<div class="r-stack">
						<figure class="fragment fade-in-then-out">
							<figcaption>Neurone artificiel</figcaption>
							<img src="these/sota/artificial_neuron.png" alt="artificial neuron">
						</figure>
						<figure class="fragment fade-in-then-out">
							<figcaption>Multi-layer Perceptron (<span class="ita">MLP</span>)</figcaption>
							<img src="these/sota/mlp.png" height="450px" alt="artificial neuron">
						</figure>

						<figure class="fragment fade-in-then-out">
							<figcaption>Convolution</figcaption>
							<img src="these/sota/convolution.png" height="450px" alt="artificial neuron">
						</figure>

						<ul class="fragment fade-in-then-out">
							<li>Adoption des <b>rÃ©seaux de neurones convolutifs</b> <span class="ita">(CNNs)</span></li>
							<ul>
								<li><b>AlexNet</b><small>[TODO]</small> (2012) atteint les meilleures performances sur <b>ImageNet</b><small>[TODO]</small></li>
								<li><b>ResNet</b><small>[TODO]</small> introduit la notion de blocs rÃ©siduels</li>
								<li>...</li>
								<br>
								<li>Convolutions 2D pour les images : <b>2D-CNN</b></li>
								<li>Convolutions 3D pour les vidÃ©os : <b>3D-CNN</b></li>
							</ul>
						</ul>

						<ul class="fragment fade-in-then-out">
							<li><b>Plus rÃ©cemment</b> (2020)</li>
							<br>
							<ul>
								<li>ArrivÃ©e des <b>transformeurs de vision <span class="ita">(ViT)</span></b></li>
								<br>
								<li><span style="color:red;">Besoin en donnÃ©es annotÃ©es massif</span> â¡ï¸ apprentissage auto-supervisÃ© <span class="ita">(SSL)</span></li>
								<br>
								<li><b>ModÃ¨les de fondations :</b> modÃ¨les de grande envergure prÃ©-entraÃ®nÃ©s</li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>ğŸ—’ï¸ &nbsp; Formulations - RÃ©seau de Neurones</h3>
					<div class="r-stack">
						<div class="fragment fade-out">
							<p>
								$f_{\alpha}(Input) = Output$
							</p>
							<ul>
								<li>$f_{\alpha}$ $\rightarrow$ rÃ©seau de neurones dont $\alpha$ est l'ensemble des poids entraÃ®nables</li>
								<li>$Input$ $\rightarrow$ les donnÃ©es en entrÃ©e</li>
								<li>$Output$ $\rightarrow$ les caractÃ©ristiques en sortie</li>
								<br>
								<li>ğŸƒ &nbsp; <b>AdaptabilitÃ© :</b> le format de $Input$ et $Output$ est manipulable selon la tÃ¢che visÃ©e </li>
							</ul>
						</div>
						<div class="fragment fade-in-then-out">
							<p><b>Classification</b></p>
							<p>
								$f_{\alpha}(\mathbf{I}) = c$
							</p>
							<br>
							<ul>
								<li> $\mathbf{I} \in \mathbb{R}^{C \times H \times W}$ $\rightarrow$ image statique de rÃ©solution $(H \times W)$ avec $C$ canaux</li>
								<br>
								<li>$c \in [1,\mathcal{C}]$ $\rightarrow$ prÃ©diction de la classe parmi $\mathcal{C}$ catÃ©gories</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>ğŸ—’ï¸ &nbsp; Formulations - Encodeur Convolutif</h3>
					<p>ğŸ“– &nbsp; Un 2D-CNN <span class="ita">(ou 3D-CNN) est utilisÃ© pour extraire un <b>vecteur de caractÃ©ristiques</b> Ã  partir de <b>donnÃ©es visuelles</b> <span class="ita">(ex. une image)</span></span></p>
					<br>
					<p class="fragment" data-fragment-index="0">
						$f_{\alpha}(\mathbf{I}) = \mathcal{F}$
					</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li>$\mathcal{F} \in \mathbb{R}^{K}$ $\rightarrow$ le vecteur de caractÃ©ristiques de $K$ entrÃ©es</li>
					</ul>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>RÃ©seaux de neurones composÃ©s de <b style="color: orange; border-bottom: solid 3px orange;">neurones impulsionnels</b></p>
					<div class="r-stack">
						<p></p>
						<img src="these/sota/artificial_impulsion_0.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_1.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_2.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_3.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion.png" alt="annvssnn" class="fragment">
					</div>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p><b>Neurone "Integrate-and-Fire" (IF)</b></p>
					
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>Codage neuronal</p>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>Techniques d'apprentissage</p>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>Surrogate gradient</p>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>MatÃ©riel Neuromorphique</p>
				</section>

				<section>
					<h3>âš¡ &nbsp; RÃ©seaux de Neurones Impulsionnels</h3>
					<p>Verrous Scientifiques</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>CamÃ©ra</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Avantages</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Ã‰volution camÃ©ras + changement paradigme</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Formulation gÃ©nÃ©ration Ã©vÃ©nements</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>ReprÃ©sentation Ã©vÃ©nements</p>
					<ul>
						<li>Images Ã©vÃ©nementielles (dÃ©tails)</li>
						<li>Surfaces temporelles</li>
						<li>Voxels</li>
						<li>Graphes</li>
						<li>EntraÃ®nable</li>
						<li>Traitement direct</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Contribution Bina-Rep</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>TÃ¢ches de vision</p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Bases de donnÃ©es (diffÃ©rentiations) </p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Vision Ã‰vÃ©nementielle</h3>
					<p>Verrous scientifiques</p>
				</section>

				<section>
					<h3>ğŸ—’ï¸ &nbsp; Bilan</h3>
					<p>Introduire les problÃ¨mes qu'on traite et basta-zer</p>
				</section>
			</section>

			<section>
				<section>
					<h2>RÃ©seaux de Neurones Impulsionnels <br> pour la Localisation d'Objet</h2>
				</section>

				<section>
					<h3>ğŸ–¼ï¸ &nbsp; Contexte</h3>
					<ul>
						<li>ğŸ’ª &nbsp; L'apprentissage profond par SG est efficace...</li>
						<li>ğŸ‘¶ &nbsp; ... mais est encore rÃ©cent :</li>
						<ul>
							<li>â¡ï¸ &nbsp; Peu de tÃ¢ches de vision Ã©tudiÃ©es</li>
							<li>â¡ï¸ &nbsp; Manque d'analyses</li>
						</ul>
						<br>
						<li class="fragment"><b>Dans ce travail :</b></li>
						<ul>
							<li class="fragment"><b>DÃ©veloppement</b> d'un SNN Convolutif (<span class="ita">CSNN</span>) pour la <b>localisation d'objet</b></li>
							<li class="fragment"><b>Analyses</b> du comportement de ce CSNN selon divers aspects</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ—¨ï¸ &nbsp; Formulation - Localisation d'Objet</h3>
					<div class="r-stack">
						<img src="these/localization/localization_formulation_0.png" alt="local forma">
						<img src="these/localization/localization_formulation_1.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_2.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_3.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_4.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation.png" alt="local forma" class="fragment fade-in-then-out">
						<div class="fragment">
							<p><b>Pourquoi cette tÃ¢che ?</b></p>
							<ul style="list-style-type: 'âœ”ï¸&nbsp;  ';">
								<li>Traitement de l'information spatiale</li>
								<li>Plus simple que des tÃ¢ches similaires (<span class="ita">dÃ©tection d'objets, ...</span>)</li>
								<li>ScÃ¨nes complexes</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>ğŸ•µï¸ &nbsp; Preuve de Concept PrÃ©liminaire</h3>
					<p style="border: 3px solid red; color:red; margin:10px; font-weight: bold;">â“ Est-ce que c'est possible ?</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li style="color:green;"><b>âœ… &nbsp; ValidÃ©</b></li>
						<ul>
							<li>ğŸ§± &nbsp; CSNN profond <b>encodeur-dÃ©codeur</b></li>
							<li>ğŸ“Ÿ &nbsp; Images statiques avec <b>codage frÃ©quentiel</b></li>
							<li>ğŸ‘ &nbsp; RÃ©sultats <b>encourageants</b></li>
						</ul>
					</ul>
					<br>
					<br>
					<p style="border: solid 2px; padding: 10px;" class="fragment" data-fragment-index="0"><small>ğŸ“°<span class="ita"><span class="ita"></span> &nbsp; Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning <br><b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></span></small></p>
				</section>

				<section>
					<h3>ğŸ” &nbsp; Aspects Ã‰tudiÃ©s</h3>
					<ol>
						<li><b>Deux modalitÃ©s Ã©tudiÃ©es : </b>images statiques et flux d'Ã©vÃ©nements</li>
						<br>
						<li><b>Latence temporelle</b> ($T$)</li>
						<br>
						<li><b>Robustesse aux corruptions des capteurs</b></li>
						<br>
						<li><b>Estimation du coÃ»t Ã©nergÃ©tique</b></li>
						<br>
						<li><b>Codages neuronaux pour les images</b></li>
					</ol>
				</section>

				<section>
					<h3>âš”ï¸ &nbsp; Ã‰tude Comparative</h3>
					<p style="border: solid 3px;">â—&nbsp; On compare un encodeur convolutif CSNN avec un <b>ANN d'architecture similaire : un 2D-CNN</b></p>
					<br>
					<ul>
						<li>ğŸ¯ &nbsp; identifier les diffÃ©rences dans le traitement des donnÃ©es visuelles</li>
						<br>
						<li>ğŸ‘¥ &nbsp; architecture et complexitÃ© similaires</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ§  &nbsp; Encodeur Convolutif - ANN</h3>
					<div class="r-stack">
						<img src="these/localization/ann_archi_0.png" alt="ANN">
						<img src="these/localization/ann_archi_1.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_2.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_3.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_4.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi.png" alt="ANN" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ§  &nbsp; Encodeur Convolutif - SNN</h3>
					<div class="r-stack">
						<img src="these/localization/snn_archi_0.png" alt="SNN">
						<img src="these/localization/snn_archi_1.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_2.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_3.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_4.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_5.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_6.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_7.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_8.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi.png" alt="SNN" class="fragment">
					</div>
				</section>

				<section>
					<h3>âš¡ &nbsp; Tenseur Impulsionnel</h3>
					<div class="r-stack">
						<img src="these/localization/inputs_0.png" alt="input">
						<img src="these/localization/inputs_1.png" alt="input" class="fragment">
						<img src="these/localization/inputs_2.png" alt="input" class="fragment">
						<img src="these/localization/inputs_3.png" alt="input" class="fragment">
						<img src="these/localization/inputs.png" alt="input" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“ &nbsp; Bases de DonnÃ©es</h3>
					<div class="r-stack">
						<img src="these/localization/datasets_0.png" alt="data">
						<img src="these/localization/datasets_1.png" alt="data" class="fragment">
						<img src="these/localization/datasets.png" alt="data" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“Ÿ &nbsp; Images Statiques - Codages Neuronaux</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/nc/original.png" alt="origi" height="375px">
								<p style="text-align: center;">
									Original
								</p>
							</td>
							<td>
								<div class="r-stack">
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/rate.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage frÃ©quentiel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/ttfs.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage temporel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/phase.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage par phases</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/saccade.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>ğŸ†• &nbsp; Codage par saccades</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<p style="text-align: center; margin-top: 5px;"><b>Codage entraÃ®nable</b></p>
									</div>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>ğŸ“· &nbsp; Images Statiques - Latence Temporelle</h3>
					<div class="r-stack">
						<ul class="fragment fade-out">
							<li><b>Protocole :</b></li>
							<ol>
								<li>DÃ©finir un nombre $T$ d'Ã©tapes temporelles</li>
								<li>Mesurer la performance de localisation ($mIoU$)</li>
							</ol>
						</ul>
						<img src="these/localization/latence_images_1.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_2.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_3.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_4.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_5.png" alt="latence image" class="fragment fade-in-then-out">
						<ul class="fragment fade-in-then-out">
							<li>âŒ &nbsp; Aucune corrÃ©lation significative entre $T$ et les performances</li>
							<br>
							<li>â— &nbsp; Comparaison des codages neuronaux</li>
							<ul>
								<li>Observations contraires aux rÃ¨gles biologiques (STDP)</li>
							</ul>
							<br>
							<li>ğŸ¥ˆ &nbsp; Performances infÃ©rieures Ã  l'ANN mais compÃ©titives</li>
						</ul>
						<img src="these/localization/latence_images_best.png" alt="latence image" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“· &nbsp; Images Statiques - Robustesse</h3>
					<div class="r-stack">
						<img src="these/localization/img_corrup/protocol_0.png" alt="corr proto">
						<img src="these/localization/img_corrup/protocol_1.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_2.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_3.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_4.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_5.png" alt="corr proto" class="fragment fade-in-then-out">
					</div>
				</section>


				<section>
					<h3>ğŸ“· &nbsp; Images Statiques - Corruptions</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/img_corrup/normal.png" alt="normal">
								<p style="text-align: center; font-weight: bold;">Original</p>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/gaussian.png" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit gaussien
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/sp.png" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit poivre & sel
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/jpeg.png" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Compression JPEG
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/flou.png" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Flou de dÃ©focalisation
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/frost.png" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Perturbations du givre
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>ğŸ“· &nbsp; Images Statiques - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption et chaque codage neuronal</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_0.png" alt="mrad">
						<img src="these/localization/img_corrup/mrad_1.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_2.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_3.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_4.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_5.png" alt="mrad" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Ã‰vÃ©nements - Latence Temporelle</h3>
					<div class="r-stack">
						<img src="these/localization/latence_events_0.png" alt="latence events">
						<img src="these/localization/latence_events.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_1.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_2.png" alt="latence events" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Ã‰vÃ©nements - Latence Temporelle</h3>
					<p><b>Trois Avantages d'une faible valeur $T$</b></p>					
					<ol>
						<li>ğŸƒ SNN est plus <b style="color:green;">rapide</b></li>
						<br>
						<li>ğŸª« SNN est <b  style="color:green;">Ã©conome</b> en Ã©nergie</li>
						<br>
						<li>ğŸ’ª SNN plus <b style="color:green;">performant</b></li>
					</ol>
					<br>
					<br>
					<p class="fragment" style="color:orange;">âš ï¸ &nbsp; Base de donnÃ©es Ã  <b>comportement statique</b></p>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Ã‰vÃ©nements - Corruptions</h3>
					<table>
						<tr>
							<td>
								<figure>
									<img src="these/localization/img_corrup/normal.gif" alt="normal">
									<figcaption style="text-align: center; font-weight: bold;">
										
										Original
									</figcaption>
								</figure>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/baa.gif" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit d'activitÃ© de fond
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/hotpix.gif" alt="kÃ©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit "hot pixels"
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>ğŸ“¸ &nbsp; Ã‰vÃ©nements - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_events_0.png" alt="mrad_events">
						<img src="these/localization/img_corrup/mrad_events.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_2.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_3.png" alt="mrad_events" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ”‹ &nbsp; Consommation Ã‰nergÃ©tique</h3>
					<p style="color: red;">âŒ &nbsp; Une puce neuromorphique adÃ©quate est difficilement accessible</p>
					<br>
					<ul>
						<li>â¡ï¸ &nbsp; <b>Estimation de l'Ã©nergie consommÃ©e</b><small>[TODO]</small></li>
						<br>
						<ul>
							<li>Calcul des FLOPs effectuÃ©s lors de l'infÃ©rence</li>
							<li style="list-style: none;">â„¹ï¸ &nbsp; <b><span class="ita">(liÃ© au nombre d'impulsions Ã©mises)</span></b></li>
							<br>
							<li>Estimation sur une puce CMOS de 45nm <small>[TODO]</small></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ”‹ &nbsp; Consommation Ã‰nergÃ©tique</h3>
					<div class="r-stack">
						<img src="these/localization/conso_0.png" alt="conso">
						<img src="these/localization/conso_1.png" alt="conso" class="fragment">
						<img src="these/localization/conso_2.png" alt="conso" class="fragment">
						<img src="these/localization/conso_3.png" alt="conso" class="fragment">
						<img src="these/localization/conso.png" alt="conso" class="fragment">
						<img src="these/localization/conso_4.png" alt="conso" class="fragment">
						<img src="these/localization/conso_5.png" alt="conso" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“ &nbsp; Bilan de l'Ã‰tude</h3>
					<ul>
						<li class="fragment"><b>SupÃ©rioritÃ© des faibles latences</b></li>
						<li class="fragment"><b>Codages Neuronaux</b></li>
						<div class="r-stack">
							<img src="these/localization/bilan_0.png" alt="coucou">
							<img src="these/localization/bilan_1.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_2.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_3.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_4.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_5.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_6.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_7.png" alt="coucou" class="fragment">
						</div>
						<li  class="fragment"><b>SNN compÃ©titif</b></li>
						<ul  class="fragment">
							<li>EfficacitÃ© Ã©nergÃ©tique ğŸ¥‡</li>
							<li><b>Ã‰vÃ©nements :</b> performance - robustesse ğŸ‘</li>
							<li><b>Images :</b> Performance ğŸ¥ˆ - robustesse ğŸ‘</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ˜ƒ &nbsp; Spiking-FER - Contribution</h3>
					<p><b>Reconnaissance d'Expressions Faciales Ã‰vÃ©nementielle avec un CSNN</b></p>
					<div class="r-stack">
						<img src="these/localization/spikingfer_0.png" alt="fer">
						<img src="these/localization/spikingfer_1.png" alt="fer" class="fragment">
						<img src="these/localization/spikingfer_2.png" alt="fer" class="fragment">
					</div>
					<p class="fragment"><b>Ã‰tudes expÃ©rimentales :</b> augmentations de donnÃ©es...</p>
					<p style="border: solid 2px; padding: 10px;" class="fragment"><small>ğŸ“°<span class="ita"><span class="ita"></span> &nbsp; Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras <br><b>2023 International Conference on Content-Based Multimedia Indexing (CBMI). ACM, 2023.</b></span></small></p>
				</section>
			</section>

			<section>
				<section>
					<h2>PrÃ©-entraÃ®nement Auto-supervisÃ© <br> pour la Vision
							Ã‰vÃ©nementielle</h2>
				</section>

				<section>
					<h3>ğŸ–¼ï¸ &nbsp; Contexte</h3>
					<ul>
						<li>ğŸ“ˆ &nbsp; ModÃ¨les profonds pour la vision Ã©vÃ©nementielle</li>
						<li><b>Apprentissage supervisÃ© :</b> nÃ©cessite beaucoup de donnÃ©es annotÃ©es</li>
						<li style="color:red;" class="fragment" data-fragment-index="0">
							â¡ï¸ &nbsp; Complexifie le dÃ©veloppement de nouvelles applications
						</li>
						<br>
						<li class="fragment" data-fragment-index="1"><b style="color:green;">Solution ProposÃ©e : </b>
							Apprentissage auto-supervisÃ©</li>
						<ul class="fragment" data-fragment-index="1">
							<li>PrÃ©-entraÃ®ner un modÃ¨le sur des donnÃ©es <b>sans nÃ©cessiter d'annotations</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ“š &nbsp; Solutions Existantes</h3>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0"
							src="these/pretraining_explained_0.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="1"
							src="these/pretraining_explained_1.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="2"
							src="these/pretraining_explained.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="3"
							src="these/pretraining_explained_2.png" alt="pretraining">
						<div class="fragment fade-in-then-out" data-fragment-index="4">
							<img src="these/pretraining_supervised.png" alt="pretraining">
							<ul>
								<li><b>SupervisÃ© :</b> utiliser une grande BDD <span class="ita">gÃ©nÃ©rique</span>
									annotÃ©e puis affiner</li>
								<ul>
									<li>ğŸ‘ &nbsp; peu de BDDs Ã©vÃ©nementielles pertinentes</li>
								</ul>
							</ul>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="5">
							<img src="these/pretraining_ssl.png" alt="pretraining">
							<ul>
								<li><b>Apprentissage Auto-supervisÃ© de ReprÃ©sentation <span class="ita">(SSRL)</span> :</b> capturer les propriÃ©tÃ©s et motifs intrinsÃ¨ques des donnÃ©es </li>
								<ul>
									<li>ğŸ‘ &nbsp; pas d'annotations requises</li>
									<li>ğŸ‘ &nbsp; proche du domaine d'application</li>
								</ul>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>ğŸ“š &nbsp; Solutions Existantes - SSRL Ã©vÃ©nementiel</h3>
					<ul>
						<li>Peu de travaux existants</li>
						<br>
						<li>TÃ¢ches de bas-niveau (flux optique, ...) <small>[TODO,TODO]</small></li>
						<br>
						<li>Travaux concurrents pour les rÃ©seaux profonds <span class="ita">(3)</span><small>[TODO,TODO,TODO]</small></li>
						<ul>
							<li>ğŸ‘ &nbsp; limitÃ©s Ã  du <span style="color: red;">comportement statique</span></li>
							<li>ğŸ‘ &nbsp; concentrÃ©s sur <span style="color: red;">un seul type de rÃ©seau</span> <span class="ita">(ViT / SNN)</span></li>
						</ul>
					</ul>
				</section>			
				
				<section>
					<h3>ğŸ“š &nbsp; Solutions Existantes - SSRL Ã©vÃ©nementiel</h3>
					<p><b>Constat</b></p>
					<ul>
						<li>Domaine <b>trÃ¨s prometteur</b> pour rÃ©duire le besoin en annotations...</li>
						<li>... mais <b>trÃ¨s peu Ã©tudiÃ©</b></li>
					</ul>

					<p></p>
				</section>

				<section>
					<h3>âš™ï¸ &nbsp; MÃ©thode</h3>
					<ul>
						<li><b>ğŸ§  &nbsp; ModÃ¨les visÃ©s :</b> encodeurs convolutifs lÃ©gers <span class="ita">(CSNN, 2D-CNN, et 3D-CNN)</span></li>
						<br>
						<li><b>ğŸ“ &nbsp; Polyvalence des donnÃ©es :</b> comportements statiques et dynamiques</li>
						<br>
						<li><b>ğŸ‘¥ &nbsp; Architecture d'encodage conjoint</b></li>
						<ul>
							<li class="fragment">Architecture en <b>deux branches</b></li>
							<li class="fragment"><b>Deux versions transformÃ©es</b> de la mÃªme entrÃ©e</li>
							<li class="fragment">Augmentations de donnÃ©es Ã©vÃ©nementielle <b><span class="ita">(EDAs)</span></b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>âš™ï¸ &nbsp; MÃ©thode</h3>
					<p><b>Augmentation de DonnÃ©es Ã‰vÃ©nementielle</b> (EDA)</p>
					<div class="r-stack">
						<img src="img/ssl/dataaug_0.png" data-fragment-index="0" alt="data" class="fragment">
						<img src="img/ssl/dataaug_1.png" data-fragment-index="1" alt="data" class="fragment">
						<img src="img/ssl/dataaug.png" data-fragment-index="2" alt="data" class="fragment">
						<img src="img/ssl/dataaug_comp.png" alt="data" class="fragment" data-fragment-index="3">
						<img src="img/ssl/dataaug_comp2.png" alt="data" class="fragment" data-fragment-index="4">
						<img src="img/ssl/dataaug_comp3.png" alt="data" class="fragment" data-fragment-index="5">
					</div>
					<p class="fragment" data-fragment-index="3">Une EDA peut Ãªtre une <b>composition</b> d'autres EDAs</p>
				</section>

				<section>
					<h3>âš™ï¸ &nbsp; MÃ©thode</h3>
					<p><b>Architecture d'Encodage Conjoint</b><small>[TODOvicreg,TODObarlow]</small></p>
					<div class="r-stack">
						<img src="these/archi_ssl_0.png" alt="archi ssl">
						<img src="these/archi_ssl_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_2.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_5.png" alt="archi ssl" class="fragment">
					</div>
				</section>

				<section>
					<h3>âš™ï¸ &nbsp; MÃ©thode</h3>
					
					<p><b>Encodeurs Ã©tudiÃ©s</b></p>
					<ul>
						<li><b>2D-CNN : </b>ResNet-18<small>[TODOresnet]</small></li>
						<li><b>3D-CNN : </b>MC3-ResNet-18<small>[TODOresnet3d]</small></li>
						<li><b>CSNN : </b>SEW-ResNet-18<small>[TODOsew]</small></li>
					</ul>
					<br>
					<br>
					<ul style="list-style: none;">
						<li>â„¹ï¸ &nbsp; MÃªme complexitÃ© <span class="ita">($\approx$11M paramÃ¨tres)</span></li>
						<li>â„¹ï¸ &nbsp; ReprÃ©sentations $\mathbf{Y}^d \in \mathbb{R}^{K = 512}$</li>
					</ul>
				</section>

				<section>
					<h3>âš™ï¸ &nbsp; MÃ©thode</h3>
					<p><b>Variantes</b></p>
					<div class="r-stack">
						<img src="these/variants_ssl_0.png" alt="variantes ssl">
						<img src="these/variants_ssl_1.png" alt="variantes ssl" class="fragment" data-fragment-index="1">
						<img src="these/variants_ssl.png" alt="variantes ssl" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>ğŸ‘¬ &nbsp; Jumeaux : </b>architecture classique avec poids partagÃ©s</li>
						<br>
						<li class="fragment" data-fragment-index="2"><b>ğŸ‘¨â€ğŸ“ğŸ§‘â€ğŸ« &nbsp; Ã‰tudiant-Professeur : </b>CSNN (<span class="ita">Ã©tudiant</span>) couplÃ© Ã  2D-/3D-CNN (<span class="ita">professeur</span>)</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ” &nbsp; Ã‰tude sur les EDAs</h3>
					<p>Ã€ chaque infÃ©rence, une composition $d_A$ / $d_B$ est Ã©chantillonnÃ©e d'une distribution $D$</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0" src="these/archi_ssl_6.png" alt="ssl d">
						<img class="fragment fade-in-then-out" data-fragment-index="1" src="these/eda_distrib_0.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="2" src="these/eda_distrib_1.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="3" src="these/eda_distrib_2.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="4" src="these/eda_distrib.png" alt="distrib d">
						<p class="fragment" data-fragment-index="5"><b>âš ï¸ DÃ©finir une distribution $D$ efficace est essentiel âš ï¸ </b></p>
					</div>
				</section>

				<section>
					<h3>ğŸª„ &nbsp; EDAs Ã‰tudiÃ©es</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Exemple</b></p>
						<p style="border: solid 3px  blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="1"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Augmentations Communes</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="5"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10"><b>Augmentations en DÃ©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11"><b>Augmentations en DÃ©coupage</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="12"><b>Augmentations GÃ©omÃ©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13"><b>Augmentations GÃ©omÃ©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="14"><b>Augmentations GÃ©omÃ©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="15"><b>Augmentations GÃ©omÃ©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="16"><b>Augmentations GÃ©omÃ©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="17"><b>Augmentations GÃ©omÃ©triques</b></p>
					</div>
					<div class="r-stack">
						<img src="these/eda/normal.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="0">
						<p class="fragment fade-in-then-out" data-fragment-index="1">ğŸ“– &nbsp; Transformations couramment utilisÃ©es, ne partagent <b>pas de caractÃ©ristiques communes</b>.</p>
						<img src="these/eda/background_activity.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/eda/polarity_flip.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/eda/crop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="4">

						<p class="fragment fade-in-then-out" data-fragment-index="5">ğŸ“– &nbsp; Transformations impliquant la <b>suppression d'Ã©vÃ©nements</b>.</p>
						<img src="these/eda/cutout.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/eda/drop_by_time.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/eda/random_drop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="8">
						<img src="these/eda/event_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="9">
						<img src="these/eda/event_copy.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="10">
						<img src="these/eda/event_copy_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="11">

						<p class="fragment fade-in-then-out" data-fragment-index="12">ğŸ“– &nbsp; Transformations impliquant une <b>distorsion spatiale des Ã©vÃ©nements</b>.</p>
						<img src="these/eda/static_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="13">
						<img src="these/eda/static_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="14">
						<img src="these/eda/dynamic_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="15">
						<img src="these/eda/dynamic_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="16">
						<img src="these/eda/stat_dyn_geo.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="17">

					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2">Bruit d'activitÃ© de fond (<code>Noise</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="3">Inversion de polaritÃ© (<code>PolFlip</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">Recadrage (<code>Crop</code>)</p>
						<!-- decoupage-->
						<p class="fragment fade-in-then-out" data-fragment-index="5"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6">DÃ©coupe par zone (<code>Cutout</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="7">DÃ©coupe par durÃ©e</p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">DÃ©coupe alÃ©atoire</p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><code>EventDrop</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10">ğŸ†• &nbsp; <code>EventCopy</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11">ğŸ†• &nbsp; <code>EventCopyDrop</code></p>
						<!-- geo -->
						<p class="fragment fade-in-then-out" data-fragment-index="12"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13">Translation statique (<code>StatTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="14">Rotation statique (<code>StatRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="15">ğŸ†• &nbsp; Translation dynamique (<code>DynTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="16">ğŸ†• &nbsp; Rotation dynamique (<code>DynRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="17">ğŸ†• &nbsp; <code>StatDynGeo</code></p>
					</div>
				</section>

				<section>
					<h3>âš–ï¸ &nbsp; Ã‰valuation des Performances</h3>
					<p style="border: solid 3px red; margin:10px; color:red;">ğŸš« &nbsp; Pas de protocole d'Ã©valuation commun en SSRL Ã©vÃ©nementiel</p>
					<br>
					<ul>
						<li class="fragment">âœ… &nbsp; <b style="color:green;">Solution :</b> dÃ©finir des <b>protocoles d'Ã©valuation standard</b> pour les travaux futurs</li>
						<ul>
							<li class="fragment">BDDs populaires <span class="ita">(classification &nbsp; â¡ï¸ &nbsp; taux de prÃ©cision)</span></li>
							<li class="fragment">Trois protocoles pour Ã©valuer des aspects spÃ©cifiques du SSRL</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ“ &nbsp; Bases de DonnÃ©es</h3>
					<div class="r-stack">
						<img src="these/bdd_ssl_0.png" alt="bdd">
						<img src="these/bdd_ssl_1.png" alt="bdd" class="fragment" data-fragment-index="0">
						<img src="these/bdd_ssl.png" alt="bdd" class="fragment" data-fragment-index="2">
					</div>
				</section>

				<section>
					<h3>Protocole 1ï¸âƒ£ &nbsp;- Ã‰valuation LinÃ©aire</h3>
					<div class="r-stack">
						<img src="these/linear_0.png" alt="linear">
						<img src="these/linear_1.png" alt="linear" class="fragment">
						<img src="these/linear_2.png" alt="linear" class="fragment">
						<img src="these/linear_3.png" alt="linear" class="fragment">
						<img src="these/linear.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>ğŸ¯ &nbsp; Est-ce que la mÃ©thode de SSRL <b>extrait des caractÃ©ristiques pertinentes ?</b></p>
				</section>

				<section>
					<h3>Protocole 2ï¸âƒ£ &nbsp;- Apprentissage Semi-supervisÃ©</h3>
					<div class="r-stack">
						<img src="these/semisup_0.png" alt="linear">
						<img src="these/semisup_1.png" alt="linear" class="fragment">
						<img src="these/semisup_2.png" alt="linear" class="fragment">
						<img src="these/semisup.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>ğŸ¯ &nbsp; Est-ce que la mÃ©thode de SSRL permet de <b>rÃ©duire le besoin en annotations ?</b></p>
				</section>

				<section>
					<h3>Protocole 3ï¸âƒ£ &nbsp;- Transfert d'Apprentissage</h3>
					<div class="r-stack">
						<img src="these/transfer_0.png" alt="linear">
						<img src="these/transfer_1.png" alt="linear" class="fragment">
						<img src="these/transfer_2.png" alt="linear" class="fragment">
						<img src="these/transfer_3.png" alt="linear" class="fragment">
						<img src="these/transfer.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>ğŸ¯ &nbsp; Est-ce que les caractÃ©ristiques apprises peuvent <b>Ãªtre transfÃ©rÃ©es Ã  d'autres donnÃ©es ?</b></p>
				</section>

				<section>
					<h3>ğŸ”ğŸª„ &nbsp; Ã‰tude sur les EDAs</h3>
					<p><b>â• &nbsp; Ã‰tude incrÃ©mentale</b></p>
					<ul>
						<li><b>Trois Ã©tapes progressives : </b>une Ã©tape par catÃ©gorie d'EDA</li>
						<br>
						<li>Pour chaque Ã©tape, on conserve la combinaison d'EDAs <b>la plus performante de l'Ã©tape prÃ©cÃ©dente</b></li>
						<br>
						<li>Protocole d'<b>Ã©valuation linÃ©aire</b> sur <b>DVSGesture</b></li>
					</ul>
				</section>

				<section>
					<h3>ğŸ”ğŸª„ &nbsp; Ã‰tude sur les EDAs</h3>
					<p><b>RÃ©sultats</b></p>
					<div class="r-stack">
						<img alt="tab result edas" src="these/results_edas/tab_0.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_1.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_2.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_3.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_4.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_5.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_6.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_7.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_8.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_9.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_10.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_11.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_12.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_13.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_14.png">
					</div>
				</section>

				<section>
					<h3>ğŸ”ğŸª„ &nbsp; Ã‰tude sur les EDAs</h3>
					<p><b>InterprÃ©tations</b></p>
					<ol>
						<li>â• EDAs communes $\rightarrow$ â• performances </li>
						<br>
						<li>Une EDA gÃ©omÃ©trique et une EDA en dÃ©coupage $\rightarrow$ â• performances</li>
						<br>
						<li>Relations <code>OneOf</code> ğŸ‘ &nbsp; <span class="ita">(<code>EventDrop</code>, ...)</span></li>
					</ol>
					<br>
					<br>
					<p class="fragment">$D = \{\texttt{Noise,Crop,PolFlip,StatDynGeo,}$ $\texttt{EventCopyDrop}\}$</p>
				</section>

				<section>
					<h3>âš–ï¸ &nbsp; Ã‰valuation des Performance</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="5"><b>Ã‰valuation LinÃ©aire et Apprentissage Semi-supervisÃ©</b></p>

						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Transfert d'Apprentissage</b></p>
					</div>
					<div class="r-stack">
						<img src="these/results_ssl/tab_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/results_ssl/tab_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/results_ssl/tab_2.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/results_ssl/tab_3.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/results_ssl/tab_4.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="4">
						<img src="these/results_ssl/tab_5.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="5">

						<img src="these/results_ssl/transfer_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/results_ssl/transfer_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/results_ssl/transfer.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="8">
					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">2D-/3D-CNNs $>$ CSNN</p>
						<p class="fragment fade-in-then-out" data-fragment-index="5">IntÃ©rÃªt de la variante "Ã‰tudiant-Professeur"</p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">âœ… &nbsp; transfÃ©rabilitÃ© des reprÃ©sentations apprises</p>
					</div>
				</section>

				<section>
					<h3>Mise en Perspective</h3>
					<p><b>â“ &nbsp; Comment se compare-t-on aux mÃ©thodes supervisÃ©es ?</b></p>
					<img class="fragment" src="these/results_ssl/perspective.png" alt="perspective">
					<ul>
						<li class="fragment">ğŸ’ª &nbsp; RÃ©sultats <b>compÃ©titifs</b>...</li>
						<li class="fragment">ğŸª¶ &nbsp; ... avec des modÃ¨les <b>plus lÃ©gers</b>...</li>
						<li class="fragment">âœ‚ï¸ &nbsp;... sans apprentissage supervisÃ© !</li>
					</ul>
				</section>

				<section>
					<h3>ğŸ” &nbsp; Analyses des ReprÃ©sentations</h3>
					<ul>
						<li>âš ï¸ &nbsp; Les taux de prÃ©cision sont des <b>mesures indirectes</b></li>
						<li>â¡ï¸ &nbsp; Analyser les propriÃ©tÃ©s des reprÃ©sentations</li>
					</ul>

					<br>
					<br>
					<ul class="fragment">
						<li><b>Deux analyses</b></li>
						<ol>
							<li class="fragment semi-fade-out"><b>QualitÃ© des reprÃ©sentations : </b>compromis d'UniformitÃ© - TolÃ©rance</li>
							<li class="fragment grow"><b>SimilaritÃ© des reprÃ©sentations : </b>analyse par alignement de noyau centrÃ© linÃ©aire <span class="ita">(CKA linÃ©aire)</span></li>
						</ol>
					</ul>
				</section>

				<section>
					<h3>ğŸ” &nbsp; SimilaritÃ© des ReprÃ©sentations</h3>
					<ul>
						<li><b>CKA LinÃ©aire :</b></li>
						<ul>
							<li>UtilisÃ©e en SSRL pour les images<small>[TODOCKA]</small></li>
							<li>Compare les reprÃ©sentations de <b>deux encodeurs</b></li>
							<li>Donne une valeur $\in [0,1]$ Ã©valuant leur similaritÃ©</li>
						</ul>
						<br>
						<li><b>ğŸ¯ &nbsp; Nos objectifs :</b></li>
						<ul>
							<li>Comparer tous les encodeurs entre eux...</li>
							<li>... selon chaque bloc rÃ©siduel</li>
							<li><b>Base de donnÃ©es :</b> DVSGesture</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ” &nbsp; SimilaritÃ© des ReprÃ©sentations</h3>
					<div class="r-stack">
						<img src="these/results_ssl/cka_0.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_1.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_2.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_3.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_4.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_5.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_6.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_7.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_8.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_9.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_10.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_11.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_12.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_13.png" alt="cka" class="fragment">
					</div>
				</section>

				<section>
					<h3>ğŸ“ &nbsp; Bilan</h3>
					<ul>
						<li><b>Contributions</b></li>
						<ul>
							<li>MÃ©thode de SSRL Ã©vÃ©nementielle pour les encodeurs convolutifs</li>
							<li>Protocoles d'Ã©valuation standardisÃ©s</li>
							<li>Ã‰tudes expÃ©rimentales</li>
						</ul>
						<br>
						<li><b>Observations</b></li>
						<ul>
							<li>ğŸ’ª &nbsp; EfficacitÃ© et polyvalence de la mÃ©thode</li>
							<li>ğŸª„ &nbsp; DÃ©finition d'une distribution d'EDAs efficace</li>
							<li>ğŸ” &nbsp; DiffÃ©rences intÃ©ressantes dans les reprÃ©sentations</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>ğŸ”“ &nbsp; AmÃ©liorations Possibles</h3>
					<ul>
						<li><b>SpÃ©cialiser la mÃ©thode</b> selon le type d'encodeur</li>
						<br>
						<li><b>Diversifier</b> les protocoles d'Ã©valuation <span class="ita">(dÃ©tection, ...)</span></li>
						<br>
						<li>MÃ©thode fonctionnant sur <b>une seule Ã©tape temporelle</b></li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>

				<section>
					<h3>Bilan des Contributions</h3>
				</section>

				<section>
					<h3>Travaux Futurs</h3>
				</section>
			</section>

			<section>
				<p class="r-fit-text">Merci !</p>
			</section>

			<section>
				<h3>References</h3>
				<ul style="list-style: none;">
					<li><small><b>[NameYEAR]: </b>M. Sajjad, et al. "A comprehensive survey on deep facial expression
							recognition: challenges, applications, and future guidelines"</small></li>
					<li><small><b>[Bokovoy2019]: </b>A. Bokovoy et al. "Real-time Vision-based Depth Reconstruction with
							NVidia Jetson"</small></li>
					<li><small><b>[Desislavov2023]: </b>R. Desislavov et al. "Trends in AI inference energy consumption:
							Beyond the performance-vs-parameter laws of deep learning"</small></li>
				</ul>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Bina-Rep</h4>
				</section>

				<section>
					<h3>Bina-Rep</h3>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Localisation</h4>
				</section>

				<section>
					<h3>Images Statiques - Latence</h3>
					<img src="these/localization/latence_full.png" alt="latence full" height="600px">
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>SSRL Ã‰vÃ©nementiel</h4>
				</section>

				<section>
					<h3>dIoU</h3>
				</section>

				<section>
					<h3>VICReg</h3>
					<img height="230px" src="these/vicreg_annexe.png" alt="vicreg annexe">
					<ol>
						<li><b>Invariance : </b>minimiser la distance entre les deux encastrements de la mÃªme entrÃ©e</li>
						<li><b>Variance : </b>maintenir la variance de chaque variable d'un mÃªme vecteur dans un lot au-dessus d'un seuil</li>
						<li><b>Covariance : </b>minimiser la covariance entre les valeurs d'un mÃªme vecteur</li>
					</ol>
				</section>

				<section>
					<h3>Distribution EDAs</h3>
					<img src="these/params_edas.png" alt="param edas" height="600px">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL Ã©vÃ©nementiel</h3>
					<p><b>ASL-DVS</b></p>
					<img height="500px" src="these/results_ssl/perspective_asl.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL Ã©vÃ©nementiel</h3>
					<p><b>N-CARS</b></p>
					<img height="500px" src="these/results_ssl/perspective_ncars.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL Ã©vÃ©nementiel</h3>
					<p><b>N-CALTECH101</b></p>
					<img src="these/results_ssl/perspective_ncaltech101.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL Ã©vÃ©nementiel</h3>
					<p><b>DVSGesture</b></p>
					<img src="these/results_ssl/perspective_dvsgesture.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL Ã©vÃ©nementiel</h3>
					<p><b>DailyAction-DVS</b></p>
					<img src="these/results_ssl/perspective_dailyactiondvs.png" alt="ASL">
				</section>

				<section>
					<h3>ReprÃ©sentation - UniformitÃ© et TolÃ©rance</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>ReprÃ©sentation - UniformitÃ© et TolÃ©rance</h3>
					<p>RÃ©sultat + interpretations</p>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>