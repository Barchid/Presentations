<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Avanc√©es en Vision Neuromorphique : Repr√©sentation √âv√©nementielle, R√©seaux de Neurones Impulsionnels
		Supervis√©s et Pr√©-entra√Ænement Auto-supervis√©</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="css/w3.css">

	<style>
		.ita {
			font-style: italic;
		}

		h1,
		h2,
		h3 {
			text-transform: none !important;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->

			<section>
				<img src="these/entree.png" alt="ent">
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>

				<section>
					<h3> üëÅÔ∏è‚Äçüó®Ô∏è &nbsp; Vision Artificielle</h3>
					<p>
						üìñ &nbsp; Extraire automatiquement des <b>informations</b> √† partir de <b>donn√©es visuelles</b>
					</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img src="these/detection_exemple.png" alt="detection">
							<!-- <figcaption>D√©tection d'objets</figcaption> -->
						</figure>

						<figure class="fragment fade-in-then-out" data-fragment-index="2">
							<img src="these/vslam.gif" alt="detection">
							<figcaption><small>[Bokovoy2019]</small></figcaption>
						</figure>

						<ul class="fragment fade-in-then-out" data-fragment-index="3">
							<li><b>Applications nombreuses :</b> m√©dical, industriel, s√©curit√©, robotique, ...</li>
							<br>
							<li><b>Comment ?</b> R√©seaux de Neurones Artificiels ( <b><span class="ita">ANN</span>s</b>
								) par l'apprentissage profond </li>
						</ul>
					</div>
				</section>

				<section>
					<h3>üîã&nbsp; Consommation √ânerg√©tique</h3>
					<p>Estimation d'√©nergie consomm√©e lors d'une inf√©rence des mod√®les de l'√©tat de l'art par
						ann√©e<small>[Desislavov2023]</small></p>
					<div class="r-stack">
						<img src="these/consommation_energie_0.png" alt="Consommation √©nerg√©tique">
						<img src="these/consommation_energie_1.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_2.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_3.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_4.png" alt="Consommation √©nerg√©tique" class="fragment">
					</div>
				</section>

				<section>
					<h3>üîã&nbsp; Consommation √ânerg√©tique</h3>
					<ul>
						<li><b>√âvolution des mod√®les</b></li>
						<ul style="list-style-type: 'üìà'">
							<li class="fragment" data-fragment-index="1"> &nbsp; Complexit√© <span
									class="ita">(profondeur, param√®tres, ...)</span></li>
							<li class="fragment" data-fragment-index="2"> &nbsp; Puissance de calculs requise</li>
							<li class="fragment" data-fragment-index="3"> &nbsp; Consommation √©nerg√©tique</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="4"><b>Enjeux majeurs</b></li>
						<ul data-fragment-index="4" class="fragment">
							<li>Environnement</li>
							<li>Applications</li>
						</ul>
					</ul>
					<br>
					<br>
					<p class="fragment" data-fragment-index="5" style="color: red;">
						‚û°Ô∏è &nbsp; <b>Probl√©matique principale</b>
					</p>
				</section>

				<section>
					<h3>üíª &nbsp; Technologie Neuromorphique</h3>
					<p>üìñ &nbsp; Technologie inspir√©e par le fonctionnement des neurones biologiques.</p>
					<br>
					<ul class="fragment">
						<li>üì∑ &nbsp;<b>Capteur :</b> Cam√©ra √©v√©nementielle</li>
						<li>üß† &nbsp;<b>Traitement :</b> R√©seaux de neurones impulsionnels (<b><span
									class="ita">SNN</span></b>)</li>
						<br>
						<li class="fragment">Syst√®mes de vision √©conomes en √©nergie <br> &nbsp;&nbsp;&nbsp;‚û°Ô∏è &nbsp; <b
								style="color:green">Solution prometteuse</b></li>
					</ul>
				</section>

				<section>
					<h3>üì∑ &nbsp; Cam√©ra √âv√©nementielle</h3>
					<ul>
						<li>Inspir√©e de la biologie</li>
						<li>√âv√©nements <b>asynchrones</b> lors d'un changement d'intensit√© du pixel</li>
						<!-- <br> -->
						<ul style="list-style-type: none;">
							<li class="fragment">‚û°Ô∏è <b>Mouvement</b></li>
						</ul>
					</ul>
					<video src="img/Bina_rep/dvscamvisu.mp4" height="300px" muted controls></video>
					<p><small>Source : <a
								href="https://www.youtube.com/watch?v=LauQ6LWTkxM">https://www.youtube.com/watch?v=LauQ6LWTkxM</a></small>
					</p>
				</section>

				<section>
					<h3>üß† &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<ul>
						<li>Bio-inspir√©s <span class="ita">(neurones impulsionnels)</span></li>
						<li>Neurones communiquent par <b>impulsions asynchrones</b></li>
					</ul>
					<div class="fragment" data-fragment-index="1"><video src="img/Bina_rep/snn_visu.mp4" muted
							height="300px" controls /></div>
					<p class="fragment" data-fragment-index="1"><small>Source : <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
				</section>

				<section>
					<h3>Vision Neuromorphique</h3>
					<ul>
						<li>üìñ &nbsp; Int√©grant une cam√©ra √©v√©nementielle et/ou un SNN</li>
						<br>
						<li>ü§ù &nbsp; <b>Traitement asynchrone en commun</b></li>
					</ul>
				</section>

				<section>
					<h3>‚õ∞Ô∏è &nbsp; D√©fis du Neuromorphique</h3>
					<ul>
						<li><b>Par rapport aux m√©thodes conventionnelles</b></li>
						<ul>
							<li>Domaine moins √©tudi√©</li>
							<li>Technologies moins matures</li>
							<li class="fragment" data-fragment-index="1" style="color:red">‚û°Ô∏è &nbsp; Performances et
								complexit√© des approches neuromorphiques moins avanc√©es</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2"><b>Besoins du domaine</b></li>
						<ul class="fragment" data-fragment-index="2">
							<li>D√©veloppement de <b style="color:green">nouvelles approches en vision neuromorphique</b>
							</li>
							<li><b style="color:green">Analyses approfondies</b> pour leur compr√©hension</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üéØ &nbsp; Objectifs</h3>
					<p style="border: solid 4px;"><b>Progr√®s des technologies neuromorphiques dans les t√¢ches de vision
							artificielle</b></p>
					<br>
					<ul>
						<li class="fragment">üß± &nbsp; <b>Conception de mod√®les d'apprentissage profond</b> avec SNNs
							et/ou cam√©ras √©v√©nementielles
						</li>
						<br>
						<li class="fragment">üîé &nbsp; <b>√âtudes exp√©rimentales</b> pour approfondir nos connaissances
						</li>
					</ul>
				</section>

				<!-- <section>
					<h3>üñºÔ∏è &nbsp; Contextes</h3>
					<div class="r-stack">

					</div>
				</section> -->

				<section>
					<h3>üóìÔ∏è &nbsp; Organisation</h3>
					<ol style="font-weight: bold;">
						<li>√âtat de l'Art</li>
						<br>
						<li>R√©seaux de Neurones Impulsionnels  pour la Localisation d'Objet</li>
						<br>
						<li>Pr√©-entra√Ænement Auto-supervis√© pour la Vision √âv√©nementielle</li>
						<br>
						<li>Conclusion</li>
					</ol>
				</section>
			</section>

			<section>
				<section>
					<h1>√âtat de l'Art</h1>
				</section>

				<section>
					<h3>üìö &nbsp; Trois Domaines</h3>
					<ul>
						<li>üë¥ &nbsp; <b>Approches classiques</b> : <span class="ita">ANN + images</span></li>
						<br>
						<li>‚ö° &nbsp; <b>R√©seaux de neurones impulsionnels</b></li>
						<br>
						<li>üì∏ &nbsp; <b>Vision √©v√©nementielle</b> : vision artificielle avec des cam√©ras
							√©v√©nementielles</li>
					</ul>
				</section>

				<section>
					<h3>üë¥ &nbsp; Approches Classiques</h3>
					<ul>
						<li><b>‚ö∞Ô∏è &nbsp; Historiquement :</b> </li>
						<ul>
							<li>Descripteurs <span class="ita">(ORB<small>[TODO]</small>, SIFT<small>[TODO]</small>)</span> en entr√©e d'un mod√®le d'apprentissage classique <span class="ita">(SVM)</span></li>
						</ul>
						<br>
						<li><b>üóº Apprentissage profond : </b> entra√Ænement d'une architecture ANN profonde par la <b>r√©tropropagation du gradient</b></li>
					</ul>
				</section>

				<section>
					<h3>üë¥ &nbsp; Approches Classiques</h3>
					<p><b>√âvolutions marquantes</b></p>

					<div class="r-stack">
						<figure class="fragment fade-in-then-out">
							<figcaption>Neurone artificiel</figcaption>
							<img src="these/sota/artificial_neuron.png" alt="artificial neuron">
						</figure>
						<figure class="fragment fade-in-then-out">
							<figcaption>Multi-layer Perceptron (<span class="ita">MLP</span>)</figcaption>
							<img src="these/sota/mlp.png" height="450px" alt="artificial neuron">
						</figure>

						<figure class="fragment fade-in-then-out">
							<figcaption>Convolution</figcaption>
							<img src="these/sota/convolution.png" height="450px" alt="artificial neuron">
						</figure>

						<ul class="fragment fade-in-then-out">
							<li>Adoption des <b>r√©seaux de neurones convolutifs</b> <span class="ita">(CNNs)</span></li>
							<ul>
								<li><b>AlexNet</b><small>[TODO]</small> (2012) atteint les meilleures performances sur <b>ImageNet</b><small>[TODO]</small></li>
								<li><b>ResNet</b><small>[TODO]</small> introduit la notion de blocs r√©siduels</li>
								<li>...</li>
								<br>
								<li>Convolutions 2D pour les images : <b>2D-CNN</b></li>
								<li>Convolutions 3D pour les vid√©os : <b>3D-CNN</b></li>
							</ul>
						</ul>

						<ul class="fragment fade-in-then-out">
							<li><b>Plus r√©cemment</b> (2020)</li>
							<br>
							<ul>
								<li>Arriv√©e des <b>transformeurs de vision <span class="ita">(ViT)</span></b></li>
								<br>
								<li><span style="color:red;">Besoin en donn√©es annot√©es massif</span> ‚û°Ô∏è apprentissage auto-supervis√© <span class="ita">(SSL)</span></li>
								<br>
								<li><b>Mod√®les de fondations :</b> mod√®les de grande envergure pr√©-entra√Æn√©s</li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Formulations - R√©seau de Neurones</h3>
					<div class="r-stack">
						<div class="fragment fade-out">
							<p>
								$f_{\alpha}(Input) = Output$
							</p>
							<ul>
								<li>$f_{\alpha}$ $\rightarrow$ r√©seau de neurones dont $\alpha$ est l'ensemble des poids entra√Ænables</li>
								<li>$Input$ $\rightarrow$ les donn√©es en entr√©e</li>
								<li>$Output$ $\rightarrow$ les caract√©ristiques en sortie</li>
								<br>
								<li>üÉè &nbsp; <b>Adaptabilit√© :</b> le format de $Input$ et $Output$ est manipulable selon la t√¢che vis√©e </li>
							</ul>
						</div>
						<div class="fragment fade-in-then-out">
							<p><b>Classification</b></p>
							<p>
								$f_{\alpha}(\mathbf{I}) = c$
							</p>
							<br>
							<ul>
								<li> $\mathbf{I} \in \mathbb{R}^{C \times H \times W}$ $\rightarrow$ image statique de r√©solution $(H \times W)$ avec $C$ canaux</li>
								<br>
								<li>$c \in [1,\mathcal{C}]$ $\rightarrow$ pr√©diction de la classe parmi $\mathcal{C}$ cat√©gories</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Formulations - Encodeur Convolutif</h3>
					<p>üìñ &nbsp; Un 2D-CNN <span class="ita">(ou 3D-CNN) est utilis√© pour extraire un <b>vecteur de caract√©ristiques</b> √† partir de <b>donn√©es visuelles</b> <span class="ita">(ex. une image)</span></span></p>
					<br>
					<p class="fragment" data-fragment-index="0">
						$f_{\alpha}(\mathbf{I}) = \mathcal{F}$
					</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li>$\mathcal{F} \in \mathbb{R}^{K}$ $\rightarrow$ le vecteur de caract√©ristiques de $K$ entr√©es</li>
					</ul>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p>R√©seaux de neurones compos√©s de <b style="color: orange; border-bottom: solid 3px orange;">neurones impulsionnels</b></p>
					<div class="r-stack">
						<p></p>
						<img src="these/sota/artificial_impulsion_0.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_1.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_2.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion_3.png" alt="annvssnn" class="fragment">
						<img src="these/sota/artificial_impulsion.png" alt="annvssnn" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Mat√©riel Neuromorphique</b></p>
					<p>üìñ Architecture mat√©rielle adapt√©e le fonctionnement des SNNs</p>
					<ul>
						<li>‚ö° &nbsp; Massivement parall√®le et adapt√© aux impulsions</li>
						<li>üè† &nbsp; Localit√© du traitement de l'information</li>
						<br>
						<li style="color:red;">‚ùå &nbsp; Moins mature</li>
						<ul style="color: red;">
							<li>Taille des SNNs limit√©e</li>
							<li>Apprentissage profond limit√©</li>
							<li>Difficult√© d'acquisition</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Simulation sur CPU/GPU</b></p>
					<p>üìñ &nbsp; Simuler sur du mat√©riel conventionnel les neurones impulsionnels</p>
					<br>
					<ul>
						<li>Simulateurs nombreux selon le cas d'utilisation <span class="ita">(neuroscience, vision, etc)</span></li>
						<br>
						<li><b>Pour les SNNs profonds :</b></li>
						<ul>
							<li>Simulations sur les librairies d'apprentissage profond communes <span class="ita">(PyTorch<small>[TODO]</small>, ...)</span></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Neurone "Integrate-and-Fire" (IF)</b><small>[TODO]</small></p>
					<div class="r-stack">
						<img src="these/sota/if_dyna_0.png" alt="dyna">
						<img src="these/sota/if_dyna_1.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_2.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_3.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_4.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_5.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_6.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_7.png" alt="dyna" class="fragment">
						<img src="these/sota/if_dyna_8.png" alt="dyna" class="fragment">
					</div>
					<br>
					<ol>
						<li class="fragment">üîå &nbsp; Potentiel de membrane</li>
						<li class="fragment">‚ö° &nbsp; G√©n√©ration d'impulsion</li>
						<li class="fragment">üí§ &nbsp; Retour au repos</li>
					</ol>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Dynamique discr√©tis√©e sur une nombre $T$ d'√©tapes temporelles d'une couche $l$ de neurones IF</b></p>
					<div class="r-stack">
						<img src="these/sota/if_eq_0.png" alt="eq">
						<img src="these/sota/if_eq_1.png" alt="eq" class="fragment" data-fragment-index="0">
						<img src="these/sota/if_eq_2.png" alt="eq" class="fragment" data-fragment-index="1">
						<img src="these/sota/if_eq_3.png" alt="eq" class="fragment" data-fragment-index="2">
						<img src="these/sota/if_eq_4.png" alt="eq" class="fragment" data-fragment-index="3">
						<img src="these/sota/if_eq_5.png" alt="eq" class="fragment" data-fragment-index="4">
						<img src="these/sota/if_eq_6.png" alt="eq" class="fragment" data-fragment-index="5">
						<img src="these/sota/if_eq.png" alt="eq" class="fragment" data-fragment-index="6">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="0">$U^l_t$ $\rightarrow$ potentiels de membrane √† l'√©tape $1 \leq t \leq T$</li>
						<li class="fragment" data-fragment-index="3">$\mathcal{W}^l$ $\rightarrow$ poids de la couche $l$</li>
						<li class="fragment" data-fragment-index="3">$X^{l-1}_t$ $\rightarrow$ impulsions en entr√©e <span class="ita">(couche pr√©c√©dente)</span></li>
						<li class="fragment" data-fragment-index="4">$X^{l}_t$ $\rightarrow$ impulsions en sortie</li>
						<li class="fragment" data-fragment-index="4">$\Theta(\cdot)$ $\rightarrow$ fonction de Heaviside</li>
						<li class="fragment" data-fragment-index="4">$\theta = 1$ $\rightarrow$ seuil d'activation</li>
					</ul>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>üßë‚Äçüéì &nbsp; Techniques d'apprentissage</b></p>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li><b>‚ôªÔ∏è &nbsp; Conversion ANN-vers-SNN</b></li>
							<ul>
								<li>üëç &nbsp; SNNs profonds et performants</li>
								<li>üëé &nbsp; Lents et consommateurs</li>
							</ul>
							<br>
							<li><b>üß† &nbsp; R√®gles d'apprentissage biologique</b> <span class="ita">(STDP)</span></li>
							<ul>
								<li>üëç &nbsp; Non-supervis√©, adapt√© au mat√©riel neuromorphique</li>
								<li>üëé &nbsp; R√©seaux peu profonds, performances limit√©es</li>
							</ul>
						</ul>

						<ul class="fragment fade-in" data-fragment-index="0">
							<li><b>üèÖ &nbsp; Adaptation de la r√©tro-propagation</b></li>
							<ul>
								<li>üëç &nbsp; Apprentissage direct du SNN</li>
								<li>üí™ &nbsp; Performance</li>
								<li style="color: orange;">‚ö†Ô∏è &nbsp; La r√©tro-propagation ne peut pas √™tre appliqu√©e telle quelle</li>
								<li class="fragment" style="color: green;"><b>Solution employ√©e : </b> apprentissage par Substitut du Gradient (SG)<small>[TODO]</small></li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Apprentissage par Subtitut du Gradient</b> <span class="ita">(SG)</span></p>
					<div class="r-stack">
						<img src="these/sota/if_eq.png" alt="eq" class="fragment fade-in-then-out">
						<img src="these/sota/if_recursive_0.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_2.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_3.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_4.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_5.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_rnn.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_rnn_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_2.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_3.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_4.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/heaviside.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/heaviside_back.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/surrogate.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/surrogate_back.png" alt="recu" class="fragment fade-in-then-out">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Codage Neuronal</b></p>
					<ul>
						<li style="color:red;">Image statique ($\in \mathbb{R}$) <b>pas compatible</b> avec les SNNs</li>
						<li style="color: green;"><b>Solution :</b> convertir les pixels en trains d'impulsions &nbsp; ‚û°Ô∏è &nbsp; <b>codage neuronal</b></li>
					</ul>
					<div class="r-stack">
						<img src="these/sota/codage_0.png" alt="codage">
						<img src="these/sota/codage_1.png" alt="codage" class="fragment">
						<img src="these/sota/codage_2.png" alt="codage" class="fragment">
						<img src="these/sota/codage_3.png" alt="codage" class="fragment">
					</div>
					
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Codage Neuronal - Exemples</b></p>
					<img src="these/sota/codages_function.png" alt="ex">
					
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Apprentissage Profond en Vision Artificielle</b></p>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li><b>üë¥ &nbsp; Historiquement :</b> Bases de Donn√©es <span class="ita">(BDDs)</span> "jouets" (MNIST<small>[TODO]</small>, CIFAR10<small>[TODO]</small>, ...)</li>
							<br>
							<li>üí™ &nbsp; <b>Gr√¢ce au SG :</b></li>
							<ul>
								<li>SNNs convolutifs <span class="ita">(CSNNs) profonds</span></li>
								<li>BDDs de <b>grande envergure</b> avec des <b>sc√®nes complexes</b></li>
								<li>Diversit√© des t√¢ches</li>
							</ul>
						</ul>
						<img src="these/sota/snn_tasks.png" alt="tasks" class="fragment fade-in" data-fragment-index="0">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Probl√©matique du SG</b></p>
					<ul>
						<li>üÜï &nbsp; Emploi r√©cent</li>
						<br>
						<li>üëü &nbsp; D√©veloppement rapide</li>
						<br>
						<li style="color: red;">‚ùå &nbsp; Peu d'analyses du comportement de ces SNNs</li>
						<ul>
							<li style="color: red;">‚û°Ô∏è &nbsp; Quelles sont les particularit√©s par rapport aux ANNs?</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Cam√©ra √©v√©nementielle</b></p>
					<ul>
						<li>Capteur bio-inspir√©</li>
						<br>
						<li>Pixels <b>ind√©pendants</b> qui r√©agissent <b>de mani√®re asynchrone</b> aux <b>changements d'intensit√©</b></li>
						<br>
						<li>La sortie est un <b>flux d'√©v√©nements</b> qui encodent ces changements d'intensit√©</li>
						<br>
						<li style="color: green;">Int√©r√™t grandissant (recherche et industrielle)</li>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<img src="img/ssl/lift.gif" alt="enothing">
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>üóíÔ∏è &nbsp; Formulation</b></p>
					<div class="r-stack">
						<img src="img/spiking_fer/eventcamintro.png" alt="eventcam">
						<img class="fragment" src="img/spiking_fer/eventcamintro_0.png" alt="eventcam">
						<img class="fragment" src="img/spiking_fer/eventcamintro_1.png" alt="eventcam">
						<img class="fragment" src="img/spiking_fer/eventcamintro_2.png" alt="eventcam">
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Avantages</b></p>
					<ul>
						<li>ü™∂ &nbsp; Repr√©sentation √©parse</li>
						<br>
						<li>üöÄ &nbsp; Faible latence (~1 ¬µs)</li>
						<br>
						<li style="text-decoration: line-through;">Flou cin√©tique</li>
						<br>
						<li>üõ°Ô∏è  &nbsp; Haute plage dynamique</li>
						<br>
						<li>üåç &nbsp; Efficacit√© √©nerg√©tique</li>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Changement de paradigme</b></p>
					<ul>
						<li>Images statiques &nbsp; ‚û°Ô∏è &nbsp; flux d'√©v√©nements</li>
						<br>
						<li style="color: red;" class="fragment grow">Les algorithmes de vision conventionnels ne fonctionnent pas tel quel</li>
						<br>
						<li class="fragment" style="color: green;">SNN &nbsp; ü§ù &nbsp; √âv√©nements</li>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Repr√©sentation d'√©v√©nements</b></p>
					<p>üìñ &nbsp; <b>Pr√©-traitement</b> transformant un flux d'√©v√©nements en une <b>repr√©sentation alternative</b> qui exprime plus efficacement les informations de la sc√®ne</p>
					<ul class="fragment">
						<li><b>Exemples :</b></li>
						<ul>
							<li class="fragment grow">Images √©v√©nementielles</li>
							<li>Surfaces temporelles</li>
							<li>Traitement direct <span class="ita">(ex. : SNNs)</span></li>
							<li>...</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Images √âv√©nementielles Binaires</b></p>
					<p>üìñ &nbsp; Image o√π chaque pixel encode la pr√©sence ou l'absence d'un √©v√©nement dans $\mathcal{E}$</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out">
							<img src="these/sota/binary_frame.png" alt="binary">
							<figcaption>Image √©v√©nementielle $X_t \in \mathbb{B}^{C \times H \times W}$</figcaption>
						</figure>

						<figure class="fragment fade-in-then-out">
							<img src="these/sota/frames_sequence_1.png" alt="seq">
							<figcaption>Si $\mathcal{E}$ est trop grand, l'image <b>sature</b></figcaption>
						</figure>

						<figure class="fragment fade-in-then-out">
							<img src="these/sota/frames_sequence_2.png" alt="seq">
							<figcaption>D√©composer en $T$ sous-ensembles $\{\mathcal{E_t}\}_{t=1}^T$ </figcaption>
						</figure>

						<figure class="fragment fade-in-then-out">
							<img src="these/sota/frames_sequence_3.png" alt="seq">
							<figcaption>Tenseur impulsionnel $\mathbf{X}_T \in \mathbb{B}^{T \times C \times H \times W}$</figcaption>
						</figure>
					</div>
				</section>

				<section>
					<h3>üÜï &nbsp; Contribution - Bina-Rep</h3>
					<p>Une technique de repr√©sentation d'√©v√©nements en images √©v√©nementielles efficace pour exprimer de les informations temporelles</p>
					<img src="these/sota/binarep.png" alt="binarep" height="250px">
					<p style="border: solid 2px; padding: 10px;"><small>üì∞<span class="ita"><span class="ita"></span> &nbsp; Bina-Rep Event Frames: a Simple and Effective Representation for Event-based cameras <br><b>2022 IEEE International Conference on Image Processing (ICIP)</b></span></small></p>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>T√¢ches de vision</b></p>
					<ul>
						<li><b>üìà &nbsp; Nombre croissants de t√¢ches de vision trait√©es</b></li>
						<ul>
							<li>Classification, d√©tection d'objet, segmentation, ...</li>
							<li>Flux optique, am√©lioration d'images, reconstruction vid√©o, ...</li>
							<li>Reconnaissance labiale, d√©tection de drones, ...</li>
						</ul>
						<br>
						<li>‚ö° &nbsp; Adoption des SNNs...</li>
						<li>üë¥ &nbsp; ... mais ANNs restent plus populaires</li>
					</ul>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Cat√©gorisations des Bases de Donn√©es</b></p>
					<div class="r-stack">
						<div class="fragment fade-out" data-fragment-index="0">
							<p><b>Deux cat√©gorisations</b></p>
							<ol>
								<li>Selon la <b>m√©thode d'acquisition</b> des √©v√©nements : <span class="ita" style="color: blue;">simul√©e</span> ou <span class="ita" style="color: magenta;">r√©elle</span></li>
								<br>
								<li>Selon la <b>dynamique</b> des sc√®nes captur√©es : <span class="ita" style="color: blue;">comportement statique</span> ou <span class="ita" style="color: magenta;">comportement dynamique</span></li>
							</ol>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="0">
							<p><b>M√©thode d'acquisition</b></p>
							<table>
								<tr>
									<td>
										<figure>
											<figcaption>Acquisition simul√©e</figcaption>
											<img src="these/sota/nmnist.gif" alt="simu">
										</figure>
									</td>

									<td>
										<figure>
											<figcaption>Acquisition r√©elle</figcaption>
											<img src="img/ssl/lift.gif" alt="enothing">
										</figure>
									</td>
								</tr>
							</table>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="1">
							<p><b>Dynamique de la sc√®ne</b></p>
							<table>
								<tr>
									<td>
										<figure>
											<figcaption>Comportement statique</figcaption>
											<img src="these/sota/ncars.png" alt="simu">
										</figure>
									</td>

									<td>
										<figure>
											<figcaption>Comportement dynamique</figcaption>
											<img src="these/sota/DVSACT16.gif" alt="enothing">
										</figure>
									</td>
								</tr>
							</table>
						</div>
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; Vision √âv√©nementielle</h3>
					<p><b>Verrous scientifiques</b></p>
					<ul>
						<li>üöÄ &nbsp; La vision √©v√©nementielle s'√©tend vers de nouvelles applications</li>
						<br>
						<li class="fragment" data-fragment-index="0" style="color: red;">‚û°Ô∏è &nbsp; cr√©ation de BDDs requise</li>
						<ul class="fragment" data-fragment-index="0" style="color: red;">
							<li>üí∏ &nbsp; Processus co√ªteux (temps et moyens)</li>
							<li>üêå &nbsp; Ralentit la diversification du domaine</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üóíÔ∏è &nbsp; Bilan</h3>
					<ul>
						<li><b>Dans nos travaux :</b></li>
						<ul>
							<li><b>CSNN</b> et <b>2D-/3D-CNN</b> profonds</li>
							<li>Apprentissage par <b>Substitut du Gradient</b> <span class="ita">(SG)</span></li>
							<li><b>Simulation</b> des neurones impulsionnels</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="0"><b>Probl√©matiques abord√©es :</b></li>
						<ol class="fragment" data-fragment-index="0">
							<li class="fragment shrink">Repr√©sentation d'√©v√©nements</li>
							<li class="fragment">D√©veloppement et analyses des SNNs</li>
							<li class="fragment">R√©duction des annotations pour la vision √©v√©nementielle</li>
						</ol>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h2>R√©seaux de Neurones Impulsionnels <br> pour la Localisation d'Objet</h2>
				</section>

				<section>
					<h3>üñºÔ∏è &nbsp; Contexte</h3>
					<ul>
						<li>üí™ &nbsp; L'apprentissage profond par SG est efficace...</li>
						<li>üë∂ &nbsp; ... mais est encore r√©cent :</li>
						<ul>
							<li>‚û°Ô∏è &nbsp; Peu de t√¢ches de vision √©tudi√©es</li>
							<li>‚û°Ô∏è &nbsp; Manque d'analyses</li>
						</ul>
						<br>
						<li class="fragment"><b>Dans ce travail :</b></li>
						<ul>
							<li class="fragment"><b>D√©veloppement</b> d'un SNN Convolutif (<span class="ita">CSNN</span>) pour la <b>localisation d'objet</b></li>
							<li class="fragment"><b>Analyses</b> du comportement de ce CSNN selon divers aspects</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üó®Ô∏è &nbsp; Formulation - Localisation d'Objet</h3>
					<div class="r-stack">
						<img src="these/localization/localization_formulation_0.png" alt="local forma">
						<img src="these/localization/localization_formulation_1.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_2.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_3.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation_4.png" alt="local forma" class="fragment fade-in-then-out">
						<img src="these/localization/localization_formulation.png" alt="local forma" class="fragment fade-in-then-out">
						<div class="fragment">
							<p><b>Pourquoi cette t√¢che ?</b></p>
							<ul style="list-style-type: '‚úîÔ∏è&nbsp;  ';">
								<li>Traitement de l'information spatiale</li>
								<li>Plus simple que des t√¢ches similaires (<span class="ita">d√©tection d'objets, ...</span>)</li>
								<li>Sc√®nes complexes</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üïµÔ∏è &nbsp; Preuve de Concept Pr√©liminaire</h3>
					<p style="border: 3px solid red; color:red; margin:10px; font-weight: bold;">‚ùì Est-ce que c'est possible ?</p>
					<br>
					<ul class="fragment" data-fragment-index="0">
						<li style="color:green;"><b>‚úÖ &nbsp; Valid√©</b></li>
						<ul>
							<li>üß± &nbsp; CSNN profond <b>encodeur-d√©codeur</b></li>
							<li>üìü &nbsp; Images statiques avec <b>codage fr√©quentiel</b></li>
							<li>üëç &nbsp; R√©sultats <b>encourageants</b></li>
						</ul>
					</ul>
					<br>
					<br>
					<p style="border: solid 2px; padding: 10px;" class="fragment" data-fragment-index="0"><small>üì∞<span class="ita"><span class="ita"></span> &nbsp; Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning <br><b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></span></small></p>
				</section>

				<section>
					<h3>üîé &nbsp; Aspects √âtudi√©s</h3>
					<ol>
						<li><b>Deux modalit√©s √©tudi√©es : </b>images statiques et flux d'√©v√©nements</li>
						<br>
						<li><b>Latence temporelle</b> ($T$)</li>
						<br>
						<li><b>Robustesse aux corruptions des capteurs</b></li>
						<br>
						<li><b>Estimation du co√ªt √©nerg√©tique</b></li>
						<br>
						<li><b>Codages neuronaux pour les images</b></li>
					</ol>
				</section>

				<section>
					<h3>‚öîÔ∏è &nbsp; √âtude Comparative</h3>
					<p style="border: solid 3px;">‚ùó&nbsp; On compare un encodeur convolutif CSNN avec un <b>ANN d'architecture similaire : un 2D-CNN</b></p>
					<br>
					<ul>
						<li>üéØ &nbsp; identifier les diff√©rences dans le traitement des donn√©es visuelles</li>
						<br>
						<li>üë• &nbsp; architecture et complexit√© similaires</li>
					</ul>
				</section>

				<section>
					<h3>üß† &nbsp; Encodeur Convolutif - ANN</h3>
					<div class="r-stack">
						<img src="these/localization/ann_archi_0.png" alt="ANN">
						<img src="these/localization/ann_archi_1.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_2.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_3.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi_4.png" alt="ANN" class="fragment">
						<img src="these/localization/ann_archi.png" alt="ANN" class="fragment">
					</div>
				</section>

				<section>
					<h3>üß† &nbsp; Encodeur Convolutif - SNN</h3>
					<div class="r-stack">
						<img src="these/localization/snn_archi_0.png" alt="SNN">
						<img src="these/localization/snn_archi_1.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_2.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_3.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_4.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_5.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_6.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_7.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_8.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi.png" alt="SNN" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚ö° &nbsp; Tenseur Impulsionnel</h3>
					<div class="r-stack">
						<img src="these/localization/inputs_0.png" alt="input">
						<img src="these/localization/inputs_1.png" alt="input" class="fragment">
						<img src="these/localization/inputs_2.png" alt="input" class="fragment">
						<img src="these/localization/inputs_3.png" alt="input" class="fragment">
						<img src="these/localization/inputs.png" alt="input" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìÅ &nbsp; Bases de Donn√©es</h3>
					<div class="r-stack">
						<img src="these/localization/datasets_0.png" alt="data">
						<img src="these/localization/datasets_1.png" alt="data" class="fragment">
						<img src="these/localization/datasets.png" alt="data" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìü &nbsp; Images Statiques - Codages Neuronaux</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/nc/original.png" alt="origi" height="375px">
								<p style="text-align: center;">
									Original
								</p>
							</td>
							<td>
								<div class="r-stack">
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/rate.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage fr√©quentiel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/ttfs.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage temporel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/phase.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage par phases</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/saccade.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>üÜï &nbsp; Codage par saccades</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<p style="text-align: center; margin-top: 5px;"><b>Codage entra√Ænable</b></p>
									</div>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Latence Temporelle</h3>
					<div class="r-stack">
						<ul class="fragment fade-out">
							<li><b>Protocole :</b></li>
							<ol>
								<li>D√©finir un nombre $T$ d'√©tapes temporelles</li>
								<li>Mesurer la performance de localisation ($mIoU$)</li>
							</ol>
						</ul>
						<img src="these/localization/latence_images_1.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_2.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_3.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_4.png" alt="latence image" class="fragment fade-in-then-out">
						<img src="these/localization/latence_images_5.png" alt="latence image" class="fragment fade-in-then-out">
						<ul class="fragment fade-in-then-out">
							<li>‚ùå &nbsp; Aucune corr√©lation significative entre $T$ et les performances</li>
							<br>
							<li>‚ùó &nbsp; Comparaison des codages neuronaux</li>
							<ul>
								<li>Observations contraires aux r√®gles biologiques (STDP)</li>
							</ul>
							<br>
							<li>ü•à &nbsp; Performances inf√©rieures √† l'ANN mais comp√©titives</li>
						</ul>
						<img src="these/localization/latence_images_best.png" alt="latence image" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Robustesse</h3>
					<div class="r-stack">
						<img src="these/localization/img_corrup/protocol_0.png" alt="corr proto">
						<img src="these/localization/img_corrup/protocol_1.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_2.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_3.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_4.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_5.png" alt="corr proto" class="fragment fade-in-then-out">
					</div>
				</section>


				<section>
					<h3>üì∑ &nbsp; Images Statiques - Corruptions</h3>
					<table>
						<tr>
							<td>
								<img src="these/localization/img_corrup/normal.png" alt="normal">
								<p style="text-align: center; font-weight: bold;">Original</p>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/gaussian.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit gaussien
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/sp.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Bruit poivre & sel
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/jpeg.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Compression JPEG
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/flou.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Flou de d√©focalisation
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/frost.png" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											<br>
											Perturbations du givre
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∑ &nbsp; Images Statiques - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption et chaque codage neuronal</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_0.png" alt="mrad">
						<img src="these/localization/img_corrup/mrad_1.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_2.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_3.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_4.png" alt="mrad" class="fragment">
						<img src="these/localization/img_corrup/mrad_5.png" alt="mrad" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Latence Temporelle</h3>
					<div class="r-stack">
						<img src="these/localization/latence_events_0.png" alt="latence events">
						<img src="these/localization/latence_events.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_1.png" alt="latence events" class="fragment">
						<img src="these/localization/latence_events_2.png" alt="latence events" class="fragment">
					</div>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Latence Temporelle</h3>
					<p><b>Trois Avantages d'une faible valeur $T$</b></p>					
					<ol>
						<li>üèÉ SNN est plus <b style="color:green;">rapide</b></li>
						<br>
						<li>ü™´ SNN est <b  style="color:green;">√©conome</b> en √©nergie</li>
						<br>
						<li>üí™ SNN plus <b style="color:green;">performant</b></li>
					</ol>
					<br>
					<br>
					<p class="fragment" style="color:orange;">‚ö†Ô∏è &nbsp; Base de donn√©es √† <b>comportement statique</b></p>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Corruptions</h3>
					<table>
						<tr>
							<td>
								<figure>
									<img src="these/localization/img_corrup/normal.gif" alt="normal">
									<figcaption style="text-align: center; font-weight: bold;">
										
										Original
									</figcaption>
								</figure>
							</td>
							<td>
								<div class="r-stack">
									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/baa.gif" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit d'activit√© de fond
										</figcaption>
									</figure>

									<figure class="fragment fade-in-then-out">
										<img src="these/localization/img_corrup/hotpix.gif" alt="k√©">
										<figcaption style="text-align: center; font-weight: bold;">
											Bruit "hot pixels"
										</figcaption>
									</figure>
								</div>
							</td>
						</tr>
					</table>
				</section>

				<section>
					<h3>üì∏ &nbsp; √âv√©nements - Corruptions</h3>
					<p>Valeur de $mRAD^{corr}$ pour chaque corruption</p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/mrad_events_0.png" alt="mrad_events">
						<img src="these/localization/img_corrup/mrad_events.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_2.png" alt="mrad_events" class="fragment">
						<img src="these/localization/img_corrup/mrad_events_3.png" alt="mrad_events" class="fragment">
					</div>
				</section>

				<section>
					<h3>üîã &nbsp; Consommation √ânerg√©tique</h3>
					<p style="color: red;">‚ùå &nbsp; Une puce neuromorphique ad√©quate est difficilement accessible</p>
					<br>
					<ul>
						<li>‚û°Ô∏è &nbsp; <b>Estimation de l'√©nergie consomm√©e</b><small>[TODO]</small></li>
						<br>
						<ul>
							<li>Calcul des FLOPs effectu√©s lors de l'inf√©rence</li>
							<li style="list-style: none;">‚ÑπÔ∏è &nbsp; <b><span class="ita">(li√© au nombre d'impulsions √©mises)</span></b></li>
							<br>
							<li>Estimation sur une puce CMOS de 45nm <small>[TODO]</small></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîã &nbsp; Consommation √ânerg√©tique</h3>
					<div class="r-stack">
						<img src="these/localization/conso_0.png" alt="conso">
						<img src="these/localization/conso_1.png" alt="conso" class="fragment">
						<img src="these/localization/conso_2.png" alt="conso" class="fragment">
						<img src="these/localization/conso_3.png" alt="conso" class="fragment">
						<img src="these/localization/conso.png" alt="conso" class="fragment">
						<img src="these/localization/conso_4.png" alt="conso" class="fragment">
						<img src="these/localization/conso_5.png" alt="conso" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìç &nbsp; Bilan de l'√âtude</h3>
					<ul>
						<li class="fragment"><b>Sup√©riorit√© des faibles latences</b></li>
						<li class="fragment"><b>Codages Neuronaux</b></li>
						<div class="r-stack">
							<img src="these/localization/bilan_0.png" alt="coucou">
							<img src="these/localization/bilan_1.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_2.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_3.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_4.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_5.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_6.png" alt="coucou" class="fragment">
							<img src="these/localization/bilan_7.png" alt="coucou" class="fragment">
						</div>
						<li  class="fragment"><b>SNN comp√©titif</b></li>
						<ul  class="fragment">
							<li>Efficacit√© √©nerg√©tique ü•á</li>
							<li><b>√âv√©nements :</b> performance - robustesse üëé</li>
							<li><b>Images :</b> Performance ü•à - robustesse üëç</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üòÉ &nbsp; Spiking-FER - Contribution</h3>
					<p><b>Reconnaissance d'Expressions Faciales √âv√©nementielle avec un CSNN</b></p>
					<div class="r-stack">
						<img src="these/localization/spikingfer_0.png" alt="fer">
						<img src="these/localization/spikingfer_1.png" alt="fer" class="fragment">
						<img src="these/localization/spikingfer_2.png" alt="fer" class="fragment">
					</div>
					<p class="fragment"><b>√âtudes exp√©rimentales :</b> augmentations de donn√©es...</p>
					<p style="border: solid 2px; padding: 10px;" class="fragment"><small>üì∞<span class="ita"><span class="ita"></span> &nbsp; Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras <br><b>2023 International Conference on Content-Based Multimedia Indexing (CBMI). ACM, 2023.</b></span></small></p>
				</section>
			</section>

			<section>
				<section>
					<h2>Pr√©-entra√Ænement Auto-supervis√© <br> pour la Vision
							√âv√©nementielle</h2>
				</section>

				<section>
					<h3>üñºÔ∏è &nbsp; Contexte</h3>
					<ul>
						<li>üìà &nbsp; Mod√®les profonds pour la vision √©v√©nementielle</li>
						<li><b>Apprentissage supervis√© :</b> n√©cessite beaucoup de donn√©es annot√©es</li>
						<li style="color:red;" class="fragment" data-fragment-index="0">
							‚û°Ô∏è &nbsp; Complexifie le d√©veloppement de nouvelles applications
						</li>
						<br>
						<li class="fragment" data-fragment-index="1"><b style="color:green;">Solution Propos√©e : </b>
							Apprentissage auto-supervis√©</li>
						<ul class="fragment" data-fragment-index="1">
							<li>Pr√©-entra√Æner un mod√®le sur des donn√©es <b>sans n√©cessiter d'annotations</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üìö &nbsp; Solutions Existantes</h3>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0"
							src="these/pretraining_explained_0.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="1"
							src="these/pretraining_explained_1.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="2"
							src="these/pretraining_explained.png" alt="pretraining">
						<img class="fragment fade-in-then-out" data-fragment-index="3"
							src="these/pretraining_explained_2.png" alt="pretraining">
						<div class="fragment fade-in-then-out" data-fragment-index="4">
							<img src="these/pretraining_supervised.png" alt="pretraining">
							<ul>
								<li><b>Supervis√© :</b> utiliser une grande BDD <span class="ita">g√©n√©rique</span>
									annot√©e puis affiner</li>
								<ul>
									<li>üëé &nbsp; peu de BDDs √©v√©nementielles pertinentes</li>
								</ul>
							</ul>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="5">
							<img src="these/pretraining_ssl.png" alt="pretraining">
							<ul>
								<li><b>Apprentissage Auto-supervis√© de Repr√©sentation <span class="ita">(SSRL)</span> :</b> capturer les propri√©t√©s et motifs intrins√®ques des donn√©es </li>
								<ul>
									<li>üëç &nbsp; pas d'annotations requises</li>
									<li>üëç &nbsp; proche du domaine d'application</li>
								</ul>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>üìö &nbsp; Solutions Existantes - SSRL √©v√©nementiel</h3>
					<ul>
						<li>Peu de travaux existants</li>
						<br>
						<li>T√¢ches de bas-niveau (flux optique, ...) <small>[TODO,TODO]</small></li>
						<br>
						<li>Travaux concurrents pour les r√©seaux profonds <span class="ita">(3)</span><small>[TODO,TODO,TODO]</small></li>
						<ul>
							<li>üëé &nbsp; limit√©s √† du <span style="color: red;">comportement statique</span></li>
							<li>üëé &nbsp; concentr√©s sur <span style="color: red;">un seul type de r√©seau</span> <span class="ita">(ViT / SNN)</span></li>
						</ul>
					</ul>
				</section>			
				
				<section>
					<h3>üìö &nbsp; Solutions Existantes - SSRL √©v√©nementiel</h3>
					<p><b>Constat</b></p>
					<ul>
						<li>Domaine <b>tr√®s prometteur</b> pour r√©duire le besoin en annotations...</li>
						<li>... mais <b>tr√®s peu √©tudi√©</b></li>
					</ul>

					<p></p>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<ul>
						<li><b>üß† &nbsp; Mod√®les vis√©s :</b> encodeurs convolutifs l√©gers <span class="ita">(CSNN, 2D-CNN, et 3D-CNN)</span></li>
						<br>
						<li><b>üìÅ &nbsp; Polyvalence des donn√©es :</b> comportements statiques et dynamiques</li>
						<br>
						<li><b>üë• &nbsp; Architecture d'encodage conjoint</b></li>
						<ul>
							<li class="fragment">Architecture en <b>deux branches</b></li>
							<li class="fragment"><b>Deux versions transform√©es</b> de la m√™me entr√©e</li>
							<li class="fragment">Augmentations de donn√©es √©v√©nementielle <b><span class="ita">(EDAs)</span></b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Augmentation de Donn√©es √âv√©nementielle</b> (EDA)</p>
					<div class="r-stack">
						<img src="img/ssl/dataaug_0.png" data-fragment-index="0" alt="data" class="fragment">
						<img src="img/ssl/dataaug_1.png" data-fragment-index="1" alt="data" class="fragment">
						<img src="img/ssl/dataaug.png" data-fragment-index="2" alt="data" class="fragment">
						<img src="img/ssl/dataaug_comp.png" alt="data" class="fragment" data-fragment-index="3">
						<img src="img/ssl/dataaug_comp2.png" alt="data" class="fragment" data-fragment-index="4">
						<img src="img/ssl/dataaug_comp3.png" alt="data" class="fragment" data-fragment-index="5">
					</div>
					<p class="fragment" data-fragment-index="3">Une EDA peut √™tre une <b>composition</b> d'autres EDAs</p>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Architecture d'Encodage Conjoint</b><small>[TODOvicreg,TODObarlow]</small></p>
					<div class="r-stack">
						<img src="these/archi_ssl_0.png" alt="archi ssl">
						<img src="these/archi_ssl_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_2.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_5.png" alt="archi ssl" class="fragment">
					</div>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					
					<p><b>Encodeurs √©tudi√©s</b></p>
					<ul>
						<li><b>2D-CNN : </b>ResNet-18<small>[TODOresnet]</small></li>
						<li><b>3D-CNN : </b>MC3-ResNet-18<small>[TODOresnet3d]</small></li>
						<li><b>CSNN : </b>SEW-ResNet-18<small>[TODOsew]</small></li>
					</ul>
					<br>
					<br>
					<ul style="list-style: none;">
						<li>‚ÑπÔ∏è &nbsp; M√™me complexit√© <span class="ita">($\approx$11M param√®tres)</span></li>
						<li>‚ÑπÔ∏è &nbsp; Repr√©sentations $\mathbf{Y}^d \in \mathbb{R}^{K = 512}$</li>
					</ul>
				</section>

				<section>
					<h3>‚öôÔ∏è &nbsp; M√©thode</h3>
					<p><b>Variantes</b></p>
					<div class="r-stack">
						<img src="these/variants_ssl_0.png" alt="variantes ssl">
						<img src="these/variants_ssl_1.png" alt="variantes ssl" class="fragment" data-fragment-index="1">
						<img src="these/variants_ssl.png" alt="variantes ssl" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>üë¨ &nbsp; Jumeaux : </b>architecture classique avec poids partag√©s</li>
						<br>
						<li class="fragment" data-fragment-index="2"><b>üë®‚Äçüéìüßë‚Äçüè´ &nbsp; √âtudiant-Professeur : </b>CSNN (<span class="ita">√©tudiant</span>) coupl√© √† 2D-/3D-CNN (<span class="ita">professeur</span>)</li>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; √âtude sur les EDAs</h3>
					<p>√Ä chaque inf√©rence, une composition $d_A$ / $d_B$ est √©chantillonn√©e d'une distribution $D$</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0" src="these/archi_ssl_6.png" alt="ssl d">
						<img class="fragment fade-in-then-out" data-fragment-index="1" src="these/eda_distrib_0.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="2" src="these/eda_distrib_1.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="3" src="these/eda_distrib_2.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="4" src="these/eda_distrib.png" alt="distrib d">
						<p class="fragment" data-fragment-index="5"><b>‚ö†Ô∏è D√©finir une distribution $D$ efficace est essentiel ‚ö†Ô∏è </b></p>
					</div>
				</section>

				<section>
					<h3>ü™Ñ &nbsp; EDAs √âtudi√©es</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Exemple</b></p>
						<p style="border: solid 3px  blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="1"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Augmentations Communes</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="5"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11"><b>Augmentations en D√©coupage</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="12"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="14"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="15"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="16"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="17"><b>Augmentations G√©om√©triques</b></p>
					</div>
					<div class="r-stack">
						<img src="these/eda/normal.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="0">
						<p class="fragment fade-in-then-out" data-fragment-index="1">üìñ &nbsp; Transformations couramment utilis√©es, ne partagent <b>pas de caract√©ristiques communes</b>.</p>
						<img src="these/eda/background_activity.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/eda/polarity_flip.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/eda/crop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="4">

						<p class="fragment fade-in-then-out" data-fragment-index="5">üìñ &nbsp; Transformations impliquant la <b>suppression d'√©v√©nements</b>.</p>
						<img src="these/eda/cutout.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/eda/drop_by_time.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/eda/random_drop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="8">
						<img src="these/eda/event_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="9">
						<img src="these/eda/event_copy.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="10">
						<img src="these/eda/event_copy_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="11">

						<p class="fragment fade-in-then-out" data-fragment-index="12">üìñ &nbsp; Transformations impliquant une <b>distorsion spatiale des √©v√©nements</b>.</p>
						<img src="these/eda/static_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="13">
						<img src="these/eda/static_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="14">
						<img src="these/eda/dynamic_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="15">
						<img src="these/eda/dynamic_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="16">
						<img src="these/eda/stat_dyn_geo.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="17">

					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2">Bruit d'activit√© de fond (<code>Noise</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="3">Inversion de polarit√© (<code>PolFlip</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">Recadrage (<code>Crop</code>)</p>
						<!-- decoupage-->
						<p class="fragment fade-in-then-out" data-fragment-index="5"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6">D√©coupe par zone (<code>Cutout</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="7">D√©coupe par dur√©e</p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">D√©coupe al√©atoire</p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><code>EventDrop</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10">üÜï &nbsp; <code>EventCopy</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11">üÜï &nbsp; <code>EventCopyDrop</code></p>
						<!-- geo -->
						<p class="fragment fade-in-then-out" data-fragment-index="12"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13">Translation statique (<code>StatTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="14">Rotation statique (<code>StatRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="15">üÜï &nbsp; Translation dynamique (<code>DynTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="16">üÜï &nbsp; Rotation dynamique (<code>DynRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="17">üÜï &nbsp; <code>StatDynGeo</code></p>
					</div>
				</section>

				<section>
					<h3>‚öñÔ∏è &nbsp; √âvaluation des Performances</h3>
					<p style="border: solid 3px red; margin:10px; color:red;">üö´ &nbsp; Pas de protocole d'√©valuation commun en SSRL √©v√©nementiel</p>
					<br>
					<ul>
						<li class="fragment">‚úÖ &nbsp; <b style="color:green;">Solution :</b> d√©finir des <b>protocoles d'√©valuation standard</b> pour les travaux futurs</li>
						<ul>
							<li class="fragment">BDDs populaires <span class="ita">(classification &nbsp; ‚û°Ô∏è &nbsp; taux de pr√©cision)</span></li>
							<li class="fragment">Trois protocoles pour √©valuer des aspects sp√©cifiques du SSRL</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üìÅ &nbsp; Bases de Donn√©es</h3>
					<div class="r-stack">
						<img src="these/bdd_ssl_0.png" alt="bdd">
						<img src="these/bdd_ssl_1.png" alt="bdd" class="fragment" data-fragment-index="0">
						<img src="these/bdd_ssl.png" alt="bdd" class="fragment" data-fragment-index="2">
					</div>
				</section>

				<section>
					<h3>Protocole 1Ô∏è‚É£ &nbsp;- √âvaluation Lin√©aire</h3>
					<div class="r-stack">
						<img src="these/linear_0.png" alt="linear">
						<img src="these/linear_1.png" alt="linear" class="fragment">
						<img src="these/linear_2.png" alt="linear" class="fragment">
						<img src="these/linear_3.png" alt="linear" class="fragment">
						<img src="these/linear.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL <b>extrait des caract√©ristiques pertinentes ?</b></p>
				</section>

				<section>
					<h3>Protocole 2Ô∏è‚É£ &nbsp;- Apprentissage Semi-supervis√©</h3>
					<div class="r-stack">
						<img src="these/semisup_0.png" alt="linear">
						<img src="these/semisup_1.png" alt="linear" class="fragment">
						<img src="these/semisup_2.png" alt="linear" class="fragment">
						<img src="these/semisup.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL permet de <b>r√©duire le besoin en annotations ?</b></p>
				</section>

				<section>
					<h3>Protocole 3Ô∏è‚É£ &nbsp;- Transfert d'Apprentissage</h3>
					<div class="r-stack">
						<img src="these/transfer_0.png" alt="linear">
						<img src="these/transfer_1.png" alt="linear" class="fragment">
						<img src="these/transfer_2.png" alt="linear" class="fragment">
						<img src="these/transfer_3.png" alt="linear" class="fragment">
						<img src="these/transfer.png" alt="linear" class="fragment">
					</div>
					<br>
					<p>üéØ &nbsp; Est-ce que les caract√©ristiques apprises peuvent <b>√™tre transf√©r√©es √† d'autres donn√©es ?</b></p>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>‚ûï &nbsp; √âtude incr√©mentale</b></p>
					<ul>
						<li><b>Trois √©tapes progressives : </b>une √©tape par cat√©gorie d'EDA</li>
						<br>
						<li>Pour chaque √©tape, on conserve la combinaison d'EDAs <b>la plus performante de l'√©tape pr√©c√©dente</b></li>
						<br>
						<li>Protocole d'<b>√©valuation lin√©aire</b> sur <b>DVSGesture</b></li>
					</ul>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>R√©sultats</b></p>
					<div class="r-stack">
						<img alt="tab result edas" src="these/results_edas/tab_0.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_1.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_2.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_3.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_4.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_5.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_6.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_7.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_8.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_9.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_10.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_11.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_12.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_13.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_14.png">
					</div>
				</section>

				<section>
					<h3>üîéü™Ñ &nbsp; √âtude sur les EDAs</h3>
					<p><b>Interpr√©tations</b></p>
					<ol>
						<li>‚ûï EDAs communes $\rightarrow$ ‚ûï performances </li>
						<br>
						<li>Une EDA g√©om√©trique et une EDA en d√©coupage $\rightarrow$ ‚ûï performances</li>
						<br>
						<li>Relations <code>OneOf</code> üëç &nbsp; <span class="ita">(<code>EventDrop</code>, ...)</span></li>
					</ol>
					<br>
					<br>
					<p class="fragment">$D = \{\texttt{Noise,Crop,PolFlip,StatDynGeo,}$ $\texttt{EventCopyDrop}\}$</p>
				</section>

				<section>
					<h3>‚öñÔ∏è &nbsp; √âvaluation des Performances</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="5"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>

						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Transfert d'Apprentissage</b></p>
					</div>
					<div class="r-stack">
						<img src="these/results_ssl/tab_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/results_ssl/tab_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/results_ssl/tab_2.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/results_ssl/tab_3.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/results_ssl/tab_4.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="4">
						<img src="these/results_ssl/tab_5.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="5">

						<img src="these/results_ssl/transfer_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/results_ssl/transfer_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/results_ssl/transfer.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="8">
					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">2D-/3D-CNNs $>$ CSNN</p>
						<p class="fragment fade-in-then-out" data-fragment-index="5">Int√©r√™t de la variante "√âtudiant-Professeur"</p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">‚úÖ &nbsp; transf√©rabilit√© des repr√©sentations apprises</p>
					</div>
				</section>

				<section>
					<h3>Mise en Perspective</h3>
					<p><b>‚ùì &nbsp; Comment se compare-t-on aux m√©thodes supervis√©es ?</b></p>
					<img class="fragment" src="these/results_ssl/perspective.png" alt="perspective">
					<ul>
						<li class="fragment">üí™ &nbsp; R√©sultats <b>comp√©titifs</b>...</li>
						<li class="fragment">ü™∂ &nbsp; ... avec des mod√®les <b>plus l√©gers</b>...</li>
						<li class="fragment">‚úÇÔ∏è &nbsp;... sans apprentissage supervis√© !</li>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Analyses des Repr√©sentations</h3>
					<ul>
						<li>‚ö†Ô∏è &nbsp; Les taux de pr√©cision sont des <b>mesures indirectes</b></li>
						<li>‚û°Ô∏è &nbsp; Analyser les propri√©t√©s des repr√©sentations</li>
					</ul>

					<br>
					<br>
					<ul class="fragment">
						<li><b>Deux analyses</b></li>
						<ol>
							<li class="fragment semi-fade-out"><b>Qualit√© des repr√©sentations : </b>compromis d'Uniformit√© - Tol√©rance</li>
							<li class="fragment grow"><b>Similarit√© des repr√©sentations : </b>analyse par alignement de noyau centr√© lin√©aire <span class="ita">(CKA lin√©aire)</span></li>
						</ol>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Similarit√© des Repr√©sentations</h3>
					<ul>
						<li><b>CKA Lin√©aire :</b></li>
						<ul>
							<li>Utilis√©e en SSRL pour les images<small>[TODOCKA]</small></li>
							<li>Compare les repr√©sentations de <b>deux encodeurs</b></li>
							<li>Donne une valeur $\in [0,1]$ √©valuant leur similarit√©</li>
						</ul>
						<br>
						<li><b>üéØ &nbsp; Nos objectifs :</b></li>
						<ul>
							<li>Comparer tous les encodeurs entre eux...</li>
							<li>... selon chaque bloc r√©siduel</li>
							<li><b>Base de donn√©es :</b> DVSGesture</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîé &nbsp; Similarit√© des Repr√©sentations</h3>
					<div class="r-stack">
						<img src="these/results_ssl/cka_0.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_1.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_2.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_3.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_4.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_5.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_6.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_7.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_8.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_9.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_10.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_11.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_12.png" alt="cka" class="fragment">
						<img src="these/results_ssl/cka_13.png" alt="cka" class="fragment">
					</div>
				</section>

				<section>
					<h3>üìç &nbsp; Bilan</h3>
					<ul>
						<li><b>Contributions</b></li>
						<ul>
							<li>M√©thode de SSRL √©v√©nementielle pour les encodeurs convolutifs</li>
							<li>Protocoles d'√©valuation standardis√©s</li>
							<li>√âtudes exp√©rimentales</li>
						</ul>
						<br>
						<li><b>Observations</b></li>
						<ul>
							<li>üí™ &nbsp; Efficacit√© et polyvalence de la m√©thode</li>
							<li>ü™Ñ &nbsp; D√©finition d'une distribution d'EDAs efficace</li>
							<li>üîé &nbsp; Diff√©rences int√©ressantes dans les repr√©sentations</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>üîì &nbsp; Am√©liorations Possibles</h3>
					<ul>
						<li><b>Sp√©cialiser la m√©thode</b> selon le type d'encodeur</li>
						<br>
						<li><b>Diversifier</b> les protocoles d'√©valuation <span class="ita">(d√©tection, ...)</span></li>
						<br>
						<li>M√©thode fonctionnant sur <b>une seule √©tape temporelle</b></li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>

				<section>
					<h3>Bilan des Contributions</h3>
					<ul>
						<li>üß† &nbsp; D√©veloppement et l'analyse de SNNs profonds &nbsp; ‚û°Ô∏è &nbsp; <b>localisation d'objet</b></li>
						<br>
						<li>üìÅ &nbsp; R√©duction du besoin en annotations pour la vision √©v√©nementielle &nbsp; ‚û°Ô∏è &nbsp; <b>SSRL √©v√©nementiel</b></li>
						<br>
						<li class="fragment shrink">ü™Ñ &nbsp; Repr√©sentation d'√©v√©nements am√©lior√©es</li>
					</ul>
				</section>

				<section>
					<h3>Travaux Futurs</h3>
					<ul>
						<li><b>üöÄ &nbsp; D√©ploiement sur mat√©riel neuromorphique</b></li>
						<br>
						<li>üèãÔ∏è &nbsp; Am√©liorations des m√©thodes con√ßues</li>
						<ul>
							<li><b>Meilleure extraction des caract√©ristiques</b> de l'encodeur CSNN</li>
							<li><b>SSRL √©v√©nementiel</b> adapt√© au type de r√©seau</li>
						</ul>
						<br>
						<li><b>Nouveaux contextes applicatifs</b></li>
					</ul>
				</section>
			</section>

			<section>
				<h3>Merci pour votre attention !</h3>
				<p style="text-align: left;"><b>Publications</b> &nbsp; 6Ô∏è‚É£</p>
				<ul>
					<li>Conf√©rences internationales √† comit√© de lecture &nbsp; 5Ô∏è‚É£</li>
					<li>Journal international √† comit√© de lecture &nbsp; 1Ô∏è‚É£</li>
				</ul>
				<br>
				<p style="text-align: left;"><b>Divers</b></p>
				<ul>
					<li>Encadrements de stages et projets Master &nbsp;  5Ô∏è‚É£</li>
					<li>Enseignement &nbsp;  1Ô∏è‚É£</li>
					<li>ü•á &nbsp; Doctoriales</li>
					<li>üì£ &nbsp; M√©diation scientifique</li>
				</ul>
				<p><small><a href="https://scholar.google.com/citations?user=M8sMMssAAAAJ&hl=en">https://scholar.google.com/citations?user=M8sMMssAAAAJ&hl=en</a></small></p>
			</section>

			<section>
				<h3>References</h3>
				<ul style="list-style: none;">
					<li><small><b>[NameYEAR]: </b>M. Sajjad, et al. "A comprehensive survey on deep facial expression
							recognition: challenges, applications, and future guidelines"</small></li>
					<li><small><b>[Bokovoy2019]: </b>A. Bokovoy et al. "Real-time Vision-based Depth Reconstruction with
							NVidia Jetson"</small></li>
					<li><small><b>[Desislavov2023]: </b>R. Desislavov et al. "Trends in AI inference energy consumption:
							Beyond the performance-vs-parameter laws of deep learning"</small></li>
				</ul>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Bina-Rep</h4>
				</section>

				<section>
					<h3>Bina-Rep</h3>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Localisation</h4>
				</section>

				<section>
					<h3>Images Statiques - Latence</h3>
					<img src="these/localization/latence_full.png" alt="latence full" height="600px">
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>SSRL √âv√©nementiel</h4>
				</section>

				<section>
					<h3>dIoU</h3>
				</section>

				<section>
					<h3>VICReg</h3>
					<img height="230px" src="these/vicreg_annexe.png" alt="vicreg annexe">
					<ol>
						<li><b>Invariance : </b>minimiser la distance entre les deux encastrements de la m√™me entr√©e</li>
						<li><b>Variance : </b>maintenir la variance de chaque variable d'un m√™me vecteur dans un lot au-dessus d'un seuil</li>
						<li><b>Covariance : </b>minimiser la covariance entre les valeurs d'un m√™me vecteur</li>
					</ol>
				</section>

				<section>
					<h3>Distribution EDAs</h3>
					<img src="these/params_edas.png" alt="param edas" height="600px">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>ASL-DVS</b></p>
					<img height="500px" src="these/results_ssl/perspective_asl.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CARS</b></p>
					<img height="500px" src="these/results_ssl/perspective_ncars.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CALTECH101</b></p>
					<img src="these/results_ssl/perspective_ncaltech101.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DVSGesture</b></p>
					<img src="these/results_ssl/perspective_dvsgesture.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DailyAction-DVS</b></p>
					<img src="these/results_ssl/perspective_dailyactiondvs.png" alt="ASL">
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>R√©sultat + interpretations</p>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>