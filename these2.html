<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Avanc√©es en Vision Neuromorphique : Repr√©sentation √âv√©nementielle, R√©seaux de Neurones Impulsionnels
		Supervis√©s et Pr√©-entra√Ænement Auto-supervis√©</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="css/w3.css">

	<style>
		.reveal .slide-number {
			font-size: 35px;
		}

		.ita {
			font-style: italic;
		}

		h1,
		h2,
		h3,
		h4,
		h5 {
			text-transform: none !important;
		}

		.grid-container {
			display: grid;
			grid-template-columns: repeat(2, 1fr);
			grid-template-rows: 1fr;
			grid-column-gap: 20px;
			grid-row-gap: 0px;
		}
			
		.div1 { grid-area: 1 / 1 / 2 / 2; }
		.div2 { grid-area: 1 / 2 / 2 / 3; }

		.grid-container3 {
			display: grid;
			grid-template-columns: repeat(2, 1fr);
			grid-template-rows: repeat(2, 1fr);
			grid-column-gap: 20px;
			grid-row-gap: 10px;
		}
		.div1-3 { grid-area: 1 / 1 / 3 / 2; }
		.div3 { grid-area: 2 / 2 / 3 / 3; }

		.container1x3 {
			display: grid;
			grid-template-columns: repeat(3, 1fr);
			grid-template-rows: 1fr;
			grid-column-gap: 0px;
			grid-row-gap: 0px;
			}
			
		.div3-1x3 { grid-area: 1 / 3 / 2 / 4; }

		.container3x3 {
			display: grid;
			grid-template-columns: repeat(3, 1fr);
			grid-template-rows: repeat(2, 1fr);
			grid-column-gap: 0px;
			grid-row-gap: 5px;
		}
			
		.div1-3x3 { grid-area: 1 / 1 / 2 / 2; }
		.div2-3x3 { grid-area: 1 / 2 / 2 / 3; }
		.div3-3x3 { grid-area: 1 / 3 / 2 / 4; }
		.div4-3x3 { grid-area: 2 / 1 / 3 / 2; }
		.div5-3x3 { grid-area: 2 / 2 / 3 / 3; }
		.div6-3x3 { grid-area: 2 / 3 / 3 / 4; }
			
			
					
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->

			<section>
				<img src="these/entree.png" alt="ent">
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>

				<section>
					<h3>Vision Artificielle</h3>
					<p>
						üìñ &nbsp; Extraire automatiquement des <b>informations</b> √† partir de <b>donn√©es visuelles</b>
					</p>
					<div class="r-stack">
						<figure class="fragment fade-in-then-out" data-fragment-index="1">
							<img src="these/detection_exemple.png" alt="detection">
							<!-- <figcaption>D√©tection d'objets</figcaption> -->
						</figure>

						<!-- <figure class="fragment fade-in-then-out" data-fragment-index="2">
							<img src="these/vslam.gif" alt="detection">
							<figcaption><small>[Bokovoy2019]</small></figcaption>
						</figure> -->

						<ul class="fragment fade-in-then-out" data-fragment-index="2">
							<li><b>Applications nombreuses :</b> m√©dical, industriel, s√©curit√©, robotique, ...</li>
							<br>
							<li><b>Comment ?</b> R√©seaux de Neurones Artificiels ( <b><span class="ita">ANN</span>s</b>
								) par l'apprentissage profond </li>
							<br>
							<li>üìà &nbsp; <b>Complexit√© des r√©seaux</b></li>
							<ul>
								<li>üìà &nbsp; Puissance de calculs requise $\Rightarrow$ <b>Consommation √©nerg√©tique</b><small>[Desislavov2023]</small></li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>Technologie Neuromorphique</h3>
					<p>üìñ &nbsp; Technologie inspir√©e par le fonctionnement des neurones biologiques.</p>
					<br>
					<ul class="fragment">
						<li><b>Capteur :</b> Cam√©ra √©v√©nementielle</li>
						<li><b>Traitement :</b> R√©seaux de neurones impulsionnels (<b><span
									class="ita">SNN</span></b>)</li>
						<br>
						<li class="fragment">Syst√®mes de vision √©conomes en √©nergie <br> &nbsp;&nbsp;&nbsp; <b
								style="color:green">$\Rightarrow$ Solution prometteuse</b></li>
					</ul>
				</section>

				<section>
					<h3>Cam√©ra √âv√©nementielle</h3>
					<ul>
						<li>Inspir√©e de la biologie</li>
						<li>√âv√©nements <b>asynchrones</b> lors d'un changement d'intensit√© du pixel</li>
						<!-- <br> -->
						<li><b>Avantages :</b> faible latence, haute plage dynamique, <b style="color: green;">efficacit√© √©nerg√©tique</b>, ... </li>
					</ul>

					<div class="grid-container">
						<div class="div1"><img src="these/dvs.gif" alt="dvs" height="300px"></div>
						<div class="div2"><img src="img/ssl/lift.gif" alt="enothing" height="350px"></div>
					</div>
					<!-- <table>
						<tr>
							<td><video style="display: inline !important;"  height="300px" muted controls></video> <img src="these/dvs.gif" alt=""></td>
							<td><img src="img/ssl/lift.gif" alt="enothing" height="350px" style="margin-bottom: 250px;"></td>
						</tr>
					</table> -->
				</section>

				<section>
					<h3>R√©seaux de Neurones Impulsionnels</h3>
					<ul>
						<li>Bio-inspir√©s <span class="ita">(neurones impulsionnels)</span></li>
						<li>Neurones communiquent par <b>impulsions binaires</b> dans le temps</li>
						<li><b style="color: green;">Tr√®s basse consommation</b></li>
					</ul>
					<br>
					<div><img src="these/snn.gif" alt="snn" height="330px" style="margin: 0;"></div>
					<p><small>Source : <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
				</section>

				<section>
					<h3>Probl√©matiques du Neuromorphique</h3>
					<p style="color: red; border: solid 3px;"><b>Domaine attractif mais moins d√©velopp√© que la vision classique</b></p>
					<ul>
						<li class="fragment" data-fragment-index="0"><b>Vision √©v√©nementielle</b></li>
						<ul class="fragment" data-fragment-index="0">
							<li>ANNs profonds fortement utilis√©s</li>
							<li>Diversification des applications <b style="color: red">$\Rightarrow$ besoins de BDDs d'apprentissage</b></li>
						</ul>
						<li class="fragment" data-fragment-index="1"><b>R√©seaux de neurones impulsionnels</b></li>
						<ul class="fragment" data-fragment-index="1">
							<li>Tr√®s prometteurs</li>
							<li>Moins matures que les ANNs <span class="ita">(2020)</span> <b style="color: red;">$\Rightarrow$ peu de diversit√© des t√¢ches de vision</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Contributions</h3>
					<ul>
						<li><b>Vision √âv√©nementielle</b></li>
						<ul>
							<li>Construire une BDD est un processus co√ªteux <span style="color: red;">$\Rightarrow$ ralentit les progr√®s du domaine</span></li>
							<li class="fragment" style="border: 3px; color:blue;"><b>1√®re contribution :</b> r√©duction du besoins en annotations en vision √©v√©nementielle</li>
						</ul>
						<li><b>SNNs :</b> <span class="ita">(d√©but de th√®se - 2020)</span></li>
						<ul>
							<li>T√¢ches de vision simplistes <span class="ita">(classifications)</span></li>
							<li>√âmergence de SNNs profonds<small>[Neftci2019]</small></li>
							<li class="fragment" style="border: 3px; color:blue;"><b>2√®me contribution :</b> aller vers des t√¢ches de vision plus complexes <b>(+ analyses)</b></li>
						</ul>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Th√©ories</h1>
				</section>

				<!-- <section>
					<h3>Trois Domaines</h3>
					<ul>
						<li><b>Approches classiques</b> : ANN + images</li>
						<br>
						<li><b>Vision √©v√©nementielle</b> : vision artificielle avec des cam√©ras
							√©v√©nementielles</li>
						<br>
						<li><b>R√©seaux de neurones impulsionnels</b></li>
					</ul>
				</section> -->
				<section>
					<h3>Donn√©e - Cam√©ra √âv√©nementielle</h3>
					<div class="r-stack">
						<img src="img/ssl/lift.gif" class="fragment fade-out" data-fragment-index="0" alt="enothing">
						<img src="img/spiking_fer/eventcamintro.png" alt="eventcam" data-fragment-index="0" class="fragment fade-in-then-out">
						<img class="fragment fade-in-then-out" src="img/spiking_fer/eventcamintro_0.png" alt="eventcam" data-fragment-index="1">
						<img class="fragment fade-in-then-out" src="img/spiking_fer/eventcamintro_1.png" alt="eventcam" data-fragment-index="2">
						<img class="fragment fade-in-then-out" src="img/spiking_fer/eventcamintro_2.png" alt="eventcam" data-fragment-index="3">
						<figure class="fragment" data-fragment-index="4">
							<p>Discr√©tisation sur $T$ √©tapes temporelles</p>
							<img src="these/discretisation.png" alt="binary">
							<br>
							<br>
							<figcaption>Tenseur impulsionnel $\mathbf{X}_T \in \mathbb{B}^{T \times C \times H \times W}$</figcaption>
						</figure>
					</div>
				</section>

				<section>
					<h3>Donn√©e - Cam√©ra √âv√©nementielle</h3>
					<p>Deux cat√©gories selon la dynamique de la sc√®ne</p>

					<div class="grid-container">
						<div class="div1">
							<p><b>Comportement <br> statique</b></p>
							<img src="these/sota/nmnist.gif" alt="simu" height="360px">
						</div>
						<div class="div2">
							<p><b>Comportement dynamique</b></p>
							<img src="these/sota/dailyactiondvs.gif" alt="enothing">
						</div>
					</div> 
				</section>

				<section>
					<h3>Donn√©e - Image Statique</h3>
					<div class="r-stack">
						<div class="fragment fade-out" data-fragment-index="0">
							<p style="color: red;">‚ùå &nbsp; Les images statiques ($\in \mathbb{R}$) ne sont pas adapt√©s pour le traitement par des neurones impulsionnels</p>
							<br>
							<img src="these/sota/codage.png" alt="codage">
						</div>

						<div class="container1x3 fragment" data-fragment-index="0">
							<div class="div1">
								<figure style="margin: 0;">
									<figcaption>&nbsp;</figcaption>
									<img src="these/localization/nc/original.png" alt="origi" height="300px" style="margin: 0;">
								</figure>
							</div>
							<div class="div2">
								<figure style="margin: 0;">
									<figcaption>Fr√©quentiel</figcaption>
									<img src="these/localization/nc/rate.gif" alt="nc" height="300px" style="margin: 0;">
								</figure>
							</div>
							<div class="div3-1x3">
								<figure style="margin: 0;">
									<figcaption>Temporel</figcaption>
									<img src="these/localization/nc/ttfs.gif" alt="nc" height="300px" style="margin: 0;">
								</figure>
							</div>
						</div>
					</div>
				</section>

				<section>
					<h3>Apprentissage Profond</h3>
					<ul>
						<li><b>R√©seaux de neurones convolutifs <span class="ita">(CNNs)</span></b></li>
						<ul>
							<li><b>AlexNet</b><small>[Kzh2012]</small> (2012) atteint les meilleures performances sur <b>ImageNet</b><small>[Deng2009]</small></li>
							<li><b>2D-CNN</b> : convolutions 2D pour les images</li>
							<li><b>3D-CNN</b> : convolutions 3D pour les vid√©os</li>
						</ul>
						<br>
						<li><b>Plus r√©cemment</b> (2020)</li>
						<ul>
							<li><b>Transformeur de Vision</b> (ViT) $\Rightarrow$ complexit√© üìà (<span class="ita">ex. ViT-22B <small>[Dehghani2023]</small>)</span></li>
							<li><b>Mod√®les de fondations :</b> mod√®les massifs polyvalents</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Formulation - Encodeur Convolutif</h3>
					<br>
					<p>
						$f_{\alpha}(\mathbf{I}) = \mathcal{F}$
					</p>
					<div class="r-stack">
						<!-- <img src="these/convenc_0.png" alt="convenc">
						<img src="these/convenc_1.png" alt="convenc" class="fragment">
						<img src="these/convenc_2.png" alt="convenc" class="fragment"> -->
						<img src="these/convenc.png" alt="convenc">
					</div>
				</section>

				<section>
					<h3>Apprentissage Profond et √âv√©nements</h3>
					<ul>
						<li><b>ANNs sont tr√®s courants</b> pour traiter les √©v√©nements</li>
						<br>
						<li>üìà &nbsp; <b>T√¢ches de vision</b></li>
						<ul>
							<li>Reconnaissance, d√©tection d'objets, segmentation, tracking, synth√©tisation 3D</li>
						</ul>	
						<li>üìà &nbsp; <b>Contextes</b></li>
						<ul>
							<li>Conduite autonome, robotique, lecture labiale, </li>
						</ul>
						<li>üìà &nbsp; <b>Architectures</b></li>
							<ul>
							<li>2D-/3D-CNNs, ViTs, encodeur-d√©codeur</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>R√©seaux de Neurones Impulsionnels</h3>
					<br>
					<p>R√©seaux de neurones compos√©s de <b style="color: orange; border-bottom: solid 3px orange;">neurones impulsionnels</b></p>
					<br>
					<img src="these/sota/artificial_impulsion.png" alt="annvssnn" class="fragment">
				</section>

				<section>
					<h3>Neurone "Integrate-and-Fire" (IF)</h3>
					<p><small>[Lapicque1907]</small></p>
					<img src="these/sota/if_dyna.png" alt="dyna">
				</section>

				<section>
					<h3>R√®gles d'Apprentissage</h3>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li><b>Conversion ANN-vers-SNN</b></li>
							<ul>
								<li style="list-style: '‚úÖ';"> &nbsp; SNNs profonds et performants</li>
								<li style="list-style: '‚ùå';">&nbsp; Lents et consommateurs</li>
							</ul>
							<br>
							<li><b>R√®gles d'apprentissage biologique</b> <span class="ita">(STDP)</span></li>
							<ul>
								<li style="list-style: '‚úÖ';"> &nbsp; Non-supervis√©, adapt√© au mat√©riel sp√©cialis√©</li>
								<li style="list-style: '‚ùå';">&nbsp; Complexit√© des SNNs limit√©e </li>
							</ul>
						</ul>

						<ul class="fragment fade-in" data-fragment-index="0">
							<li><b>R√©tropropagation</b> <span class="fragment" data-fragment-index="1">&nbsp; üèÖ</span></li>
							<ul>
								<li>SNN $=$ R√©seau de neurones r√©currents</li>
								<li>$\Rightarrow$ R√©tropropagation √† travers le temps</li>
								<br>
								<li class="fragment" data-fragment-index="2" >‚úÖ &nbsp; Apprentissage direct du SNN</li>
								<li class="fragment" data-fragment-index="2" >‚úÖ &nbsp; SNNs profonds et performants</li>
								<br>
								<li class="fragment" data-fragment-index="3" style="color: orange;">‚ö†Ô∏è &nbsp; Non-diff√©rentiabilit√© des impulsions</li>
								<li class="fragment" data-fragment-index="3" style="color: green;"><b>$\Rightarrow$ Apprentissage par Substitut du Gradient</b> (SG)<small>[Neftci2019]</small></li>
							</ul>
						</ul>
					</div>
				</section>

				<section>
					<h3>Apprentissage par Substitut du Gradient</h3>
					<div class="r-stack">
						<div class="fragment fade-out" data-fragment-index="0">
							<p style="color: red;">Probl√®me du neurone mort<small>[Eshraghian2021]</small></p>
							<img src="these/heaviside_simple_0.png" alt="go">
						</div>
						<div class="fragment fade-in-then-out" data-fragment-index="0">
							<p style="color: red;">Probl√®me du neurone mort<small>[Eshraghian2021]</small></p>
							<img src="these/heaviside_simple_1.png" alt="go">
						</div>
						<div class="fragment fade-in-then-out" data-fragment-index="1">
							<p style="color: red;">Probl√®me du neurone mort<small>[Eshraghian2021]</small></p>
							<img src="these/heaviside_simple.png" alt="go">
						</div>
						<div class="fragment fade-in-then-out" data-fragment-index="2">
							<p style="color: green;">Remplacer la d√©riv√©e par un <b>substitut</b></p>
							<img src="these/sg_simple.png" alt="go">
						</div>
					</div>
				</section>

				<section>
					<h3>Revue - SNNs en Vision</h3>
					<ul>
						<li><b>D√©but de th√®se </b>(2020-2021) :</li>
						<ul>
							<li>Hautes performances pour la classification (CIFAR10-DVS<small>[Li2017]</small>, ImageNet <small>[Deng2009]</small>, ...)</li>
						</ul>
						<br>
						<li><b>Diversification des t√¢ches</b> (2021 - ...) : segmentation<small>[Kim2022]</small>, d√©tection<small>[Cordone2022]</small>, profondeur<small>[Rancon2021]</small>, ...</li>
					</ul>
				</section>

				<section>
					<h3>Revue - Vision √âv√©nementielle</h3>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li>Int√©r√™t croissant $\Rightarrow$ d√©veloppement rapide du domaine</li>
							<br>
							<li>Diversification des <b>t√¢ches de vision</b> trait√©es</li>
							<br>
							<li>Diversification des <b>contextes d'applications</b></li>
						</ul>
						<div class="r-stack fragment" data-fragment-index="0">
							<img src="these/sota/tasks_0.png" alt="tasks" height="550px">
							<img src="these/sota/tasks_2.png" alt="tasks" height="550px" class="fragment">
							<img src="these/sota/tasks_3.png" alt="tasks" height="550px" class="fragment">
							<img src="these/sota/tasks_4.png" alt="tasks" height="550px" class="fragment">
							<img src="these/sota/tasks.png" alt="tasks" height="550px" class="fragment">
						</div>
					</div>
				</section>

				<section>
					<h3>Verrous Scientifiques</h3>
					<ul>
						<li><b>SNNs profonds :</b></li>
						<ul>
							<li>Progr√®s rapides</li>
							<li style="color: red;">Retard sur la compr√©hension des aspects de conception</li>
							<li class="fragment" style="color:blue;list-style-type: none;"><b>$\Rightarrow$ √âtudes exp√©rimentales</b></li>
						</ul>
						<br>
						<li><b>Vision √©v√©nementielle :</b></li>
						<ul>
							<li>Diversification des contextes d'utilisation $\Rightarrow$ construction de nouvelles BDDs annot√©es</li>
							<li style="color: red;">Processus co√ªteux</li>
							<li class="fragment" style="color:blue;list-style-type: none;"><b>$\Rightarrow$ R√©duire ce co√ªt</b></li>
						</ul>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<br>
					<br>
					<h2>√âtude des R√©seaux de Neurones Impulsionnels <br> par la Localisation d'Objet</h2>
					<br>
					<br>
					<p style="border-top: solid 2px; padding-top: 5px; text-align: justify;"><small>üìî &nbsp; <span class="ita">"Deep spiking convolutional neural network for single object localization based on deep continuous local learning."</span> <b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></small></p>
					<p style="text-align: justify;"><small>üìî &nbsp; <span class="ita">"Spiking neural networks for frame-based and event-based single object localization."</span> <b>Neurocomputing 559 (2023): 126805.</b></small></p>
				</section>

				<section>
					<h3>Manque d'Analyses</h3>
					<ul>
						<li><b>Historiquement</b> (SNNs peu profonds avec STDP) <b>:</b></li>
						<ul>
							<li><b>Images statiques : </b>Sup√©riorit√© du codage temporel</li>
							<li><b>Latence temporelle</b> ($T$) <b>:</b> une grande valeur $T$ est pr√©f√©rable</li>
							<li><b>Robustesse aux corruptions</b></li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="0" style="color: darkorange;">‚ö†Ô∏è &nbsp; Est-ce que l'apprentissage par SG est diff√©rent ?</li>
						<ul class="fragment" data-fragment-index="0">
							<li style="color: red;">R√©ponse inconnue</li>
							<li style="list-style-type: none;">$\Rightarrow$ <b>√âtudes exp√©rimentales</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Formulation - Localisation d'Objet</h3>
					<div class="r-stack">
						<img src="these/localization/localization_formulation.png" alt="local forma">
						<!-- <div class="fragment">
							<p><b>Pourquoi cette t√¢che ?</b></p>
							<ul style="list-style-type: '‚úîÔ∏è&nbsp;  ';">
								<li>Traitement de l'information spatiale</li>
								<li>Plus simple que des t√¢ches similaires (<span class="ita">d√©tection d'objets, ...</span>)</li>
								<li>Sc√®nes complexes</li>
							</ul>
						</div> -->
					</div>
					<p></p>
				</section>

				<section>
					<h3>Contenu de l'√âtude</h3>
					<ul>
						<li><b>Deux modalit√©s :</b> images statiques et √©v√©nements</li>
						<br>
						<li><b>Influence de trois param√®tres sur les performances</b></li>
						<ol>
							<li><b>Latence temporelle</b></li>
							<li>Corruptions des capteurs $\Rightarrow$ <b>robustesse</b></li>
							<li>Le <b>codage neuronal</b> d'une image statique</li>
						</ol>
						<br>
						<li>Estimation du co√ªt √©nerg√©tique</li>
						<br>
						<li><b>Comparaison syst√©matique avec un ANN</b></li>
					</ul>
				</section>

				<section>
					<h3>Encodeur Convolutif - ANN</h3>
					<div class="r-stack">
						<img src="these/localization/ann_archi.png" alt="ANN">
					</div>
				</section>

				<section>
					<h3>Encodeur Convolutif - SNN</h3>
					<div class="r-stack">
						<img src="these/localization/snn_archi_0.png" alt="SNN">
						<img src="these/localization/snn_archi_1.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_2.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_3.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi_4.png" alt="SNN" class="fragment">
						<img src="these/localization/snn_archi.png" alt="SNN" class="fragment">
					</div>
				</section>

				<section>
					<h3>Bases de Donn√©es</h3>
					<img src="these/localization/bdds_loca.png" alt="bdd loca" height="350px">
					<img style="margin-top: 0;" src="these/localization/datasets.png" alt="data">
				</section>

				<section>
					<h3>Codages Neuronaux √âtudi√©s</h3>
					<div class="container3x3">
						<div class="div1-3x3">
							<figure style="margin: 0;">
								<figcaption>&nbsp;</figcaption>
								<img src="these/localization/nc/original.png" alt="origi" height="250px" style="margin: 0;">
							</figure>
						</div>
						<div class="div2-3x3">
							<figure style="margin: 0;">
								<figcaption>Fr√©quentiel</figcaption>
								<img src="these/localization/nc/rate.gif" alt="origi" height="250px" style="margin: 0;">
							</figure>
						</div>
						<div class="div3-3x3">
							<figure style="margin: 0;">
								<figcaption>Temporel</figcaption>
								<img src="these/localization/nc/ttfs.gif" alt="origi" height="250px" style="margin: 0;">
							</figure>
						</div>
						<div class="div4-3x3">
							<figure style="margin: 0;">
								<img src="these/localization/nc/phase.gif" alt="origi" height="250px" style="margin: 0;">
								<figcaption>par Phases</figcaption>
							</figure>
						</div>
						<div class="div5-3x3">
							<figure style="margin: 0;">
								<img src="these/localization/nc/saccade.gif" alt="origi" height="250px" style="margin: 0;">
								<figcaption style="color: blue;">üÜï par Saccades</figcaption>
							</figure>
						</div>
						<div class="div6-3x3">
							<div style="border: 2px solid; height: 250px; width: 250px; margin-left: 35px;">
								<br>
								<p>Codage entra√Ænable</p>
								<br>
							</div>
						</div>
					</div> 
					<!-- <table>
						<tr>
							<td>
								<img src="these/localization/nc/original.png" alt="origi" height="375px">
								<p style="text-align: center;">
									Original
								</p>
							</td>
							<td>
								<div class="r-stack">
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/rate.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage fr√©quentiel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/ttfs.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage temporel</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/phase.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>Codage par phases</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<img src="these/localization/nc/saccade.gif" alt="nc" height="400px">
										<p style="text-align: center; margin-top: 5px;"><b>üÜï &nbsp; Codage par saccades</b></p>
									</div>
									<div class="fragment fade-in-then-out">
										<p style="text-align: center; margin-top: 5px;"><b>Codage entra√Ænable</b></p>
									</div>
								</div>
							</td>
						</tr>
					</table> -->
				</section>

				<section>
					<h3>√âtude sur la Latence Temporelle</h3>
					<p><b>Protocole</b></p>
						<ol>
							<li>D√©finir un nombre $T$ d'√©tapes temporelles</li>
							<br>
							<li>Effectuer un entra√Ænement</li>
							<br>
							<li>Mesurer la performance de localisation (% $mIoU$) sur l'ensemble de validation</li>
						</ol>
				</section>

				<section>
					<h3>Latence Temporelle - Images Statiques</h3>
					<div class="r-stack">
						<img src="these/localization/images_latences_0.png" alt="latence image" class="fragment fade-out" data-fragment-index="0">
						<img src="these/localization/images_latences_1.png" alt="latence image" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/localization/images_latences_2.png" alt="latence image" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/localization/images_latences_3.png" alt="latence image" class="fragment fade-in-then-out" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="0">Aucune correlation significative</li>
						<li class="fragment" data-fragment-index="1">SNN comp√©titif (au mieux, $\Delta = 2.97$%)</li>
						<li class="fragment" data-fragment-index="2"><b>Contraire au STDP :</b> codage temporel $<<$</li>
					</ul>
				</section>

				<section>
					<h3>Latence Temporelle - √âv√©nements</h3>
					<div class="r-stack">
						<img src="these/localization/latence_events.png" alt="latence events" class="fragment fade-out" data-fragment-index="0">
						<img src="these/localization/latence_events_1.png" alt="latence events" class="fragment" data-fragment-index="0">
						<img src="these/localization/latence_events_2.png" alt="latence events" class="fragment" data-fragment-index="1">
						<img src="these/localization/latence_events_3.png" alt="latence events" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="0"><b>ANN :</b> Les performances restent constantes</li>
						<li class="fragment" data-fragment-index="1"><b>SNN :</b> &nbsp; $T$ üìâ &nbsp; $\rightarrow$ performances &nbsp; üìà</li>
						<li class="fragment" data-fragment-index="2">√Ä partir de $T=8$, le SNN est meilleur</li>
					</ul>
				</section>

				<section>
					<h3>√âtude sur la Robustesse aux Corruptions</h3>
					<p><b>Protocole</b></p>
					<div class="r-stack">
						<img src="these/localization/img_corrup/protocol_0.png" alt="corr proto">
						<img src="these/localization/img_corrup/protocol_1.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_2.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_3.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol.png" alt="corr proto" class="fragment fade-in-then-out">
						<img src="these/localization/img_corrup/protocol_5.png" alt="corr proto" class="fragment fade-in-then-out">
					</div>
				</section>


				<section>
					<h3>Robustesse - Images Statiques</h3>
					<img src="these/localization/corruptions_images.png" alt="corruptions">
				</section>

				<section>
					<h3>Images Statiques - Corruptions</h3>
					<!-- <p>Valeur de $mRAD^{corr}$ pour chaque corruption et chaque codage neuronal</p> -->
					<div class="r-stack">
						<img src="these/localization/corruptions_charts.png" alt="mrad" height="450px" style="margin-top: 0;">
						<img src="these/localization/corruptions_charts_0.png" alt="mrad" height="450px" class="fragment" data-fragment-index="0" style="margin-top: 0;">
						<img src="these/localization/corruptions_charts_1.png" alt="mrad" height="450px" class="fragment" data-fragment-index="1" style="margin-top: 0;">
						<img src="these/localization/corruptions_charts_2.png" alt="mrad" height="450px" class="fragment" data-fragment-index="2" style="margin-top: 0;">
						<img src="these/localization/corruptions_charts_3.png" alt="mrad" height="450px" class="fragment" data-fragment-index="3" style="margin-top: 0;">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>Temporel :</b> tr√®s robuste sauf pour le givre</li>
						<li class="fragment" data-fragment-index="2"><b>Saccades :</b> contraire observ√©</li>
						<li class="fragment" data-fragment-index="3" style="color: green;"><b>Fr√©quentiel :</b> grande robustesse g√©n√©rale</li>
					</ul>
				</section>

				<section>
					<h3>Robustesse - √âv√©nements</h3>
					<div class="grid-container3">
						<div class="div1-3" style="margin-top: 50px;"> 
							<figure style="margin: 0;">
								<figcaption>Original</figcaption>
								<img src="these/localization/img_corrup/normal.gif" alt="normal" height="400px" style="margin: 0;">
							</figure>
							
						</div>
						<div class="div2">
							<figure style="margin: 0;">
								<figcaption style="font-size: 30px;">Bruit d'activit√© de fond</figcaption>
								<img src="these/localization/img_corrup/baa.gif" alt="k√©" height="250px" style="margin: 0;">
							</figure>
						</div>
						<div class="div3">
							<figure style="margin: 0;">
								<img src="these/localization/img_corrup/hotpix.gif" alt="k√©" style="margin: 0;" height="250px">
								<figcaption style="font-size: 30px;">Bruit "hot pixels"</figcaption>
							</figure>
						</div>
					</div> 

				</section>


				<section>
					<h3>Robustesse - √âv√©nements</h3>
					<!-- <p>Valeur de $mRAD^{corr}$ pour chaque corruption</p> -->
					<img src="these/localization/event_chart_corr.png" alt="corruption" height="375px">
					<ul>
						<li>Sensibilit√© au bruit du SNN $\rightarrow$ hypoth√®se des potentiels de membrane</li>
					</ul>
				</section>

				<section>
					<h3>Consommation √ânerg√©tique</h3>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li><b>Estimation de l'√©nergie consomm√©e</b><small>[Kim2022]</small></li>
							<br>
							<ul>
								<li>Calcul des FLOPs effectu√©s lors de l'inf√©rence</li>
								<li style="list-style: none;">‚ÑπÔ∏è &nbsp; <b><span class="ita">(li√© au nombre d'impulsions √©mises)</span></b></li>
								<br>
								<li>Estimation sur une puce CMOS de 45nm <small>[Horowitz2024]</small> :</li>
								<ul>
									<li>$E_{ANN} \rightarrow$ √©nergie consomm√©e par l'ANN <span class="ita">(en mJ)</span></li>
									<li>$E_{SNN} \rightarrow$ √©nergie consomm√©e par le SNN</li>
								</ul>
								<br>
								<li style="list-style: none;">$\Rightarrow$ <b>On reporte le ratio :</b> $\frac{E_{ANN}}{E_{SNN}}$</li>
							</ul>
						</ul>
						<div class="fragment" data-fragment-index="0">
							<img src="these/localization/conso_bars.png" alt="conso bars">
							<ul>
								<li class="fragment" data-fragment-index="1"><b>Net avantage pour les SNNs</b></li>
								<li class="fragment" data-fragment-index="1">Les flux d'√©v√©nements sont comparables aux codages neuronaux intensifs</li>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>Bilan de l'√âtude</h3>
					<ul>
						<li class="fragment" data-fragment-index="0"><b>Sup√©riorit√© des faibles latences</b></li>
						<ul class="fragment" data-fragment-index="0">
							<li>SNN plus rapide, plus √©conome, voire plus performant</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="1"><b>Codages Neuronaux : </b> int√©r√™t du <span style="color: green;"><b>codage fr√©quentiel</b></span></li>
						<br>
						<li  class="fragment" data-fragment-index="2"><b>Contradictions avec les √©tudes pr√©c√©dentes</b> <span class="ita">(STDP)</span><small>[TODO]</small></li>
						<ul  class="fragment" data-fragment-index="2">
							<li>Faiblesse du <span style="color:red;">codage temporel</span></li>
							<li>Influence de la latence temporelle</li>
							<li><b>$\Rightarrow$ Remise en cause des connaissances</b></li>
						</ul>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<br>
					<br>
					<br>
					<h2>Pr√©-entra√Ænement <br> Auto-supervis√© <br> pour la Vision
							√âv√©nementielle</h2>
					<br>
					<br>
					<p style="border-top: solid 2px; padding-top: 5px; text-align: justify;"><small>üìî &nbsp; <span class="ita">"Exploring Joint Embedding Architectures and Data Augmentations for Self-Supervised Representation Learning in Event-Based Vision."</span> <b>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023</b>.</small></p>
				</section>

				<section>
					<h3>Contexte</h3>
					<ul>
						<li>üìà &nbsp; Mod√®les profonds pour la vision √©v√©nementielle</li>
						<br>
						<li><b>Apprentissage supervis√© :</b> n√©cessite beaucoup de donn√©es annot√©es</li>
						<br>
						<li style="color:red;" class="fragment" data-fragment-index="0">
							Complexifie le d√©veloppement de nouvelles applications
						</li>
						<!-- <br>
						<li class="fragment" data-fragment-index="1"><b style="color:green;">Solution : </b>
							Apprentissage auto-supervis√©</li>
						<ul class="fragment" data-fragment-index="1">
							<li>Pr√©-entra√Æner un mod√®le sur des donn√©es <b>sans n√©cessiter d'annotations</b></li>
						</ul> -->
					</ul>
					<br>
					<br>
					<p class="fragment" style="font-weight: bold; border: 3px solid; color: black; padding-top: 5px;">üó®Ô∏è &nbsp; Comment r√©duire le besoin en annotations pour les mod√®les profonds en vision √©v√©nementielle ?</p>
				</section>

				<section>
					<h3>Solutions Existantes</h3>
					<div class="r-stack">
						<div class="fragment fade-in-then-out" data-fragment-index="4">
							<img src="these/pretraining_supervised.png" alt="pretraining">
							<ul>
								<li><b>Supervis√© :</b> utiliser une grande BDD <span class="ita">g√©n√©rique</span>
									annot√©e puis affiner</li>
								<ul>
									<li style="color: red;">‚ùå &nbsp; peu de BDDs √©v√©nementielles pertinentes</li>
								</ul>
							</ul>
						</div>

						<div class="fragment fade-in-then-out" data-fragment-index="5">
							<img src="these/pretraining_ssl.png" alt="pretraining">
							<ul>
								<li><b>Apprentissage Auto-supervis√© de Repr√©sentation <span class="ita">(SSRL)</span> :</b> capturer les propri√©t√©s et motifs intrins√®ques des donn√©es </li>
								<ul style="color: green;">
									<li>‚úÖ &nbsp; Pas d'annotations requises</li>
									<li>‚úÖ &nbsp; Proche du domaine d'application</li>
								</ul>
							</ul>
						</div>
					</div>
				</section>

				<section>
					<h3>SSRL √©v√©nementiel</h3>
					<ul>
						<li><b>Trois travaux similaires</b> <span class="ita">(2022 - 2023)</span><small>[TODO,TODO,TODO]</small></li>
						<ul>
							<li>‚ùå &nbsp; Limit√©s √† du <span style="color: red;">comportement statique</span></li>
							<li>‚ùå &nbsp; Exp√©rimentations : <span style="color: red;">√©valuations diff√©rentes</span></li>
							<li>‚ùå &nbsp; Concentr√©s sur <span style="color: red;">un type de r√©seau</span> <span class="ita">(ViT / SNN)</span></li>
							<li>‚ùå &nbsp; Les mod√®les √©tudi√©s sont <span style="color: red;">lourds</span></li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="0"><b>Constat</b></li>
						<ul class="fragment" data-fragment-index="0">
							<li>Domaine <b style="color: green;">prometteur</b> mais encore <b style="color: red;">sous-exploit√©</b></li>
						</ul>
					</ul>
				</section>			
				
				<section>
					<h3>Travaux</h3>
					<ul>
						<li><b>Nouvelle m√©thode de r√©f√©rence</b> pour des encodeurs convolutifs l√©gers <span class="ita">(CSNN, 2D-CNN, et 3D-CNN)</span></li>
						<br>
						<li><b>Polyvalence des donn√©es :</b> BDDs √† comportement statique et dynamique</li>
						<br>
						<li><b>Protocoles d'√©valuation standardis√©s</b></li>
						<br>
						<li><b>√âtude sur les augmentations de donn√©es</b> dans le cadre du SSRL</li>
					</ul>
				</section>

				<section>
					<h3>M√©thode</h3>
					<p><b>Augmentation de Donn√©es √âv√©nementielle</b> (EDA)</p>
					<div class="r-stack">
						<img src="img/ssl/dataaug.png" alt="data">
						<img src="img/ssl/dataaug_comp2.png" alt="data" class="fragment" data-fragment-index="0">
					</div>
					<p class="fragment" data-fragment-index="0">‚ÑπÔ∏è &nbsp; Une EDA peut √™tre une <b>composition</b> d'autres EDAs</p>
				</section>

				<section>
					<h3>M√©thode</h3>
					<p><b>Architecture d'Encodage Conjoint</b><small>[Bardes2022][Zbontar2021]</small></p>
					<div class="r-stack">
						<!-- <img src="these/archi_ssl_0.png" alt="archi ssl"> -->
						<img src="these/archi_ssl_1.png" alt="archi ssl">
						<img src="these/archi_ssl_2.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_3_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_4_1.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl.png" alt="archi ssl" class="fragment">
						<img src="these/archi_ssl_5.png" alt="archi ssl" class="fragment">
					</div>
				</section>

				<section>
					<h3>M√©thode - Encodeurs √âtudi√©s</h3>
					<br>
					<ul>
						<li><b>2D-CNN : </b>ResNet-18<small>[He2016]</small></li>
						<li><b>CSNN : </b>SEW-ResNet-18<small>[Fang2021]</small></li>
						<li><b>3D-CNN : </b>MC3-ResNet-18<small>[TODOresnet3d]</small></li>
					</ul>
					<br>
					<br>
					<p>‚ÑπÔ∏è &nbsp; <span class="ita">M√™me architecture et m√™me complexit√©</span></p>
				</section>

				<section>
					<h3>M√©thode - Variantes</h3>
					<br>
					<div class="r-stack">
						<img src="these/variants_ssl_0.png" alt="variantes ssl">
						<img src="these/variants_ssl_1.png" alt="variantes ssl" class="fragment" data-fragment-index="1">
						<img src="these/variants_ssl.png" alt="variantes ssl" class="fragment" data-fragment-index="2">
					</div>
					<ul>
						<li class="fragment" data-fragment-index="1"><b>üë¨ &nbsp; Jumeaux : </b>architecture classique avec poids partag√©s</li>
						<br>
						<li class="fragment" data-fragment-index="2"><b>üë®‚Äçüéìüßë‚Äçüè´ &nbsp; √âtudiant-Professeur : </b>CSNN (<span class="ita">√©tudiant</span>) coupl√© √† 2D-/3D-CNN (<span class="ita">professeur</span>)</li>
					</ul>
				</section>

				<section>
					<h3>M√©thode - Augmentations de Donn√©es</h3>
					<p>√Ä chaque inf√©rence, une composition $d_A$ / $d_B$ est √©chantillonn√©e d'une distribution $D$</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" data-fragment-index="0" src="these/archi_ssl_6.png" alt="ssl d">
						<img class="fragment fade-in-then-out" data-fragment-index="1" src="these/eda_distrib_0.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="2" src="these/eda_distrib_1.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="3" src="these/eda_distrib_2.png" alt="distrib d">
						<img class="fragment fade-in-then-out" data-fragment-index="4" src="these/eda_distrib.png" alt="distrib d">
						<p class="fragment" data-fragment-index="5" style="color: darkorange;"><b>‚ö†Ô∏è D√©finir une distribution $D$ efficace est essentiel ‚ö†Ô∏è </b></p>
					</div>
				</section>

				<section>
					<h3>Augmentations √âtudi√©es</h3>
					<img src="these/ssrl/edas_summary.png" alt="eda summary">
				</section>

				<section>
					<h3>√âvaluation des Performances</h3>
					<div class="r-stack">
						<div class="fragment fade-out" data-fragment-index="0">
							<p style="border: solid 3px red; margin:10px; color:red; padding-top: 5px;">‚ùå &nbsp; Pas de protocole d'√©valuation commun en SSRL √©v√©nementiel</p>
							<br>
							<ul>
								<li style="color:green;">D√©finir des <b>protocoles d'√©valuation standards</b> pour les travaux futurs</li>
								<ul>
									<li>Probl√®mes de classification $\rightarrow$ taux de pr√©cision</li>
									<li>Trois protocoles pour √©valuer des aspects sp√©cifiques du SSRL</li>
								</ul>
							</ul>
						</div>
						<div class="fragment fade-in" data-fragment-index="0">
							<img height="500px" src="these/ssrl/bdd_ssrl.png" alt="ssrl bdd">
						</div>
					</div>
				</section>

				<section>
					<h3>Protocole n¬∞1 - √âvaluation Lin√©aire</h3>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL <b>extrait des caract√©ristiques pertinentes ?</b></p>
					<br>
					<div class="r-stack">
						<!-- <img src="these/linear.png" alt="linear"> -->
						<img src="these/ssrl/ssrl_linear.png" alt="linear">
					</div>
					<br>
					<br>
				</section>

				<section>
					<h3>Protocole n¬∞2 - Transfert d'Apprentissage</h3>
					<p>üéØ &nbsp; Est-ce que les caract√©ristiques apprises peuvent <b>√™tre transf√©r√©es √† d'autres donn√©es ?</b></p>
					<br>
					<div class="r-stack">
						<img src="these/ssrl/ssrl_transf.png" alt="linear">
					</div>
					<br>
					<br>
				</section>

				<section>
					<h3 style="font-size: 1.1em;">Protocole n¬∞3 - Apprentissage Semi-supervis√©</h3>
					<p>üéØ &nbsp; Est-ce que la m√©thode de SSRL permet de <b>r√©duire le besoin en annotations ?</b></p>
					<br>
					<div class="r-stack">
						<img src="these/ssrl/ssrl_semi.png" alt="linear">
					</div>
					<br>
					<br>
				</section>

				<section>
					<h3>√âtude sur les EDAs</h3>
					<p style="border: 3px solid; font-weight: bold; padding-top: 5px;">üéØ &nbsp; √âvaluer l'int√©r√™t des EDAs pour le SSRL</p>
					<br>
					<ul>
						<li>Protocole d'<b>√©valuation lin√©aire</b> sur <b>DVSGesture</b></li>
						<br>
						<li><b>Trois √©tapes incr√©mentales : </b>une √©tape par cat√©gorie</li>
						<br>
						<li>Pour chaque √©tape, on conserve la combinaison d'EDAs <b>la plus performante de l'√©tape pr√©c√©dente</b></li>
					</ul>
				</section>

				<section>
					<h3>√âtude sur les EDAs</h3>
					<div class="r-stack">
						<p class="fragment fade-out" data-fragment-index="2"><b>√âtape 1 :</b> EDAs Communes</p>
						<p class="fragment fade-in" data-fragment-index="2"><span class="fragment fade-out" data-fragment-index="6"><b>√âtape 2 :</b> EDAs G√©om√©triques</span></p>
						<p class="fragment" data-fragment-index="6"><b>√âtape 3 :</b> EDAs en d√©coupage</p>
					</div>
					<div class="r-stack">
						<img src="these/ssrl/eda_communes_results_0.png" height="450px" alt="eda">
						<img src="these/ssrl/eda_communes_results_1.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/ssrl/eda_communes_results.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/ssrl/eda_geo_results_0.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/ssrl/eda_geo_results_1.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/ssrl/eda_geo_results_2.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="4">
						<img src="these/ssrl/eda_geo_results.png" height="450px" alt="eda" class="fragment fade-in-then-out" data-fragment-index="5">
						<img src="these/ssrl/eda_drop_results.png" height="450px" alt="eda" class="fragment fade-in" data-fragment-index="6">
					</div>
					<div class="r-stack">
						<div class="fragment" data-fragment-index="1">
							<ul class="fragment fade-out" data-fragment-index="2">
								<li>Une EDA (<span style="color: red;">rouge</span>) &lsaquo; deux EDAs (<span style="color:green;">vert</span>) &lsaquo; Trois EDAs (<span style="color:blue;">bleu</span>)</li>
							</ul>
						</div>
						
						<div class="fragment" data-fragment-index="2">
							<ul class="fragment fade-out" data-fragment-index="6">
								<li>Dynamiques pour 3D-CNN et CSNN</li>
								<li>Statiques pour 2D-CNN</li>
							</ul>
						</div>

						<ul class="fragment fade-in" data-fragment-index="7">
							<li><code>EventCopyDrop</code> est syst√©matiquement ü•á ou ü•à</li>
						</ul>
					</div>
				</section>

				<section>
					<h3>√âtude sur les EDAs - R√©sum√©</h3>
					<ol>
						<li><b>EDAs communes :</b> au plus le mieux</li>
						<br>
						<li>Une EDA g√©om√©trique et une EDA en d√©coupage $\rightarrow$ ‚ûï performances</li>
						<br>
						<li>Int√©r√™t des relations <code>OneOf</code> <span class="ita">(<code>EventDrop</code>, ...)</span></li>
					</ol>
					<br>
					<br>
					<p class="fragment">$D = \{\texttt{Noise,Crop,PolFlip,StatDynGeo,}$ $\texttt{EventCopyDrop}\}$</p>
				</section>

				<section>
					<h3>√âvaluation des Performances</h3>
					<div class="r-stack">
						<ul class="fragment fade-out" data-fragment-index="0">
							<li>R√©sultats des protocoles <b>Semi-supervis√©</b> et <b>Transfert d'Apprentissage</b></li>
							<br>
							<li>Mise en perspective avec les <b>mod√®les supervis√©s</b></li>
							<br>
							<li>Pour un protocole donn√©, on rapporte :</li>
							<ol>
								<li>Le <b>meilleur mod√®le supervis√©</b> de l'√©tat de l'art</li>
								<li>Les <b>deux meilleurs r√©sultats</b> obtenus sur le SSRL √©v√©nementiel</li>
							</ol>
						</ul>
						<div class="r-stack fragment" data-fragment-index="0">
							<img src="these/ssrl/ssrl_benchmarks_0.png" alt="ssrl benchmarks" height="600px" style="margin: 0;">
							<img src="these/ssrl/ssrl_benchmarks_1.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
							<img src="these/ssrl/ssrl_benchmarks_2.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
							<img src="these/ssrl/ssrl_benchmarks_1.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
							<img src="these/ssrl/ssrl_benchmarks_3.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
							<img src="these/ssrl/ssrl_benchmarks_4.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
							<img src="these/ssrl/ssrl_benchmarks_5.png" alt="ssrl benchmarks" class="fragment" height="670px" style="margin:0;">
						</div>
					</div>
				</section>

				<section>
					<h3>Bilan des Contributions</h3>
					<br>
					<ul>
						<li class="fragment" data-fragment-index="0" style="list-style-type: '‚öôÔ∏è &nbsp;';"> <b>M√©thode de SSRL √©v√©nementielle</b></li>
						<ul class="fragment" data-fragment-index="0">
							<li>Performances comp√©titives voire surpassant les mod√®les supervis√©s</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="1" style="list-style-type: 'ü™Ñ &nbsp;';"> <b>√âtude sur les EDAs pour la SSRL</b></li>
						<ul class="fragment" data-fragment-index="1">
							<li>Propositions de nouvelles techniques</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2" style="list-style-type: '‚öñÔ∏è &nbsp;';"> <b>Protocoles d'√©valuation standardis√©s</b></li>
						<ul class="fragment" data-fragment-index="2">
							<li>Fondations pour la SSRL √©v√©nementielle</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Limitations</h3>
					<ul>
						<li><b>In√©galit√©s des encodeurs</b></li>
						<ul>
							<li>‚ùå &nbsp; $CSNN < 2D\text{ et }3D$</li>
						</ul>
						<br>
						<li>Protocoles d'√©valuation bas√©s sur la <b>classification uniquement</b></li>
						<ul>
							<li>‚ùå &nbsp; Information spatiale</li>
						</ul>
						<br>
						<li>Les caract√©ristiques sont extraites sur l'ensemble des √©v√©nements</li>
						<ul>
							<li>‚ùå &nbsp; Traitement de l'information spatio-temporel</li>
						</ul>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>

				<section>
					<h3 style="font-size: 1.0em;">√âtude des SNNs profonds par la Localisation d'Objet</h3>
					<p class="fragment" style="text-align: justify;">
						Notre √©tude fournit des <b style="color: green;">informations cl√©s sur des choix de conception</b> des SNNs profonds.
					</p>
					<br>
					<p class="fragment" style="text-align: justify;">
						Le SNN con√ßu montre l'<b style="color: green;">int√©r√™t</b> en termes de <b style="color: green;">consommation √©nerg√©tique</b> par rapport √† un ANN similaire.
					</p>
					<br>
					<p class="fragment" style="text-align: justify;">
						Les conclusions ant√©rieures sur les SNNs <b style="color: red;">ne sont pas v√©rifi√©es</b> pour l'apprentissage par SG $\Rightarrow$ Remise en cause.
					</p>
				</section>

				<section>
					<h3 style="font-size: 1.0em;">√âtude des SNNs profonds par la Localisation d'Objet</h3>
					<p><b>Travaux Futurs</b></p>
					<ul>
						<li><b>D√©ploiement et analyses sur mat√©riel neuromorphique</b></li>
						<ul>
							<li>Quelles sont les sp√©cificit√©s d'un SNN d√©ploy√© ?</li>
						</ul>
						<br>
						<li><b>√âtudes suppl√©mentaires</b></li>
						<ul>
							<li>Qualit√© de l'apprentissage, attaques adverses, etc.</li>
						</ul>
						<br>
						<li><b>Vers des t√¢ches plus complexes...</b></li>
						<ul>
							<li>d√©tection d'objets, segmentation panoptique, ...</li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>SSRL √©v√©nementiel</h3>
					<p class="fragment" style="text-align: justify;">
						Le SSRL √©v√©nementiel accomplit <b style="color: green;">avec succ√®s</b> la r√©duction du <b style="color: green;">besoin en annotations</b>.
					</p>
					<br>
					<p class="fragment" style="text-align: justify;">
						Cela ouvre des opportunit√©s d'<b style="color: green;">acc√©l√©rer</b> grandement la <b style="color: green;">diversification</b> de la vision √©v√©nementielle. 
					</p>
					<br>
					<p class="fragment" style="text-align: justify;">
						Possibilit√© de voir des BDDs √©v√©nementielles comportant <b style="color: green;">beaucoup de donn√©es</b> et <b style="color: green;">peu d'annotations</b>.
					</p>
				</section>

				<section>
					<h3>SSRL √âv√©nementiel</h3>
					<p><b>Travaux Futurs</b></p>
					<ul>
						<li><b>M√©thodes sp√©cialis√©es</b> pour un type d'encodeur</li>
						<br>
						<li>Proposer des <b>protocoles d'√©valuation</b> diversifi√©s <span class="ita">(d√©tection d'objets, ...)</span></li>
						<br>
						<li><b>Nouveaux contextes applicatifs</b></li>
						<br>
						<li><b>Mod√®les de fondation √©v√©nementiels</b> </li>
					</ul>
				</section>
			</section>

			<section>
				<h3>S√©ance de Questions</h3>
				<p style="text-align: left;"><b>Publications</b> &nbsp; 6Ô∏è‚É£</p>
				<ul>
					<li>Conf√©rences internationales √† comit√© de lecture &nbsp; 5Ô∏è‚É£</li>
					<li>Journal international √† comit√© de lecture &nbsp; 1Ô∏è‚É£</li>
				</ul>
				<br>
				<p style="text-align: left;"><b>Divers</b></p>
				<ul>
					<li>Encadrements de stages et projets Master &nbsp;  5Ô∏è‚É£</li>
					<li>Enseignement &nbsp;  1Ô∏è‚É£</li>
					<li>ü•á &nbsp; Doctoriales</li>
					<li>üì£ &nbsp; M√©diation scientifique</li>
				</ul>
			</section>

			<section>
				<h3>Contributions</h3>
				<ul>
					<li class="fragment shrink" data-fragment-index="0" style="text-align: justify; margin:0 20px 20px 0;"><small><span class="ita">"Deep spiking convolutional neural network for single object localization based on deep continuous local learning."</span> <b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></small></li>
					<li class="fragment shrink" data-fragment-index="0" style="text-align: justify; margin:0 20px 20px 0;"><small><span class="ita">"Spiking neural networks for frame-based and event-based single object localization."</span> <b>Neurocomputing 559 (2023): 126805.</b></small></li>
					<li class="fragment shrink" data-fragment-index="0" style="text-align: justify; margin:0 20px 20px 0;"><small><span class="ita">"Exploring Joint Embedding Architectures and Data Augmentations for Self-Supervised Representation Learning in Event-Based Vision."</span> <b>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023</b>.</small></li>
					<li class="fragment highlight-red" style="text-align: justify; margin:0 20px 20px 0;"><small><span class="ita">"Bina-rep event frames: A simple and effective representation for event-based cameras."</span> <b>2022 IEEE International Conference on Image Processing (ICIP)</b>.</small></li>
					<li class="fragment  highlight-blue" style="text-align: justify; margin:0 20px 20px 0;"><small><span class="ita">"Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras."</span> <b>2023 International Conference on Content-Based Multimedia Indexing (CBMI). ACM, 2023.</b>.</small></li>
					<li style="border-top: solid 2px; padding-top: 5px; text-align: justify; color: darkgrey;"><small><span class="ita">"Review on indoor RGB-D semantic segmentation with deep convolutional neural networks."</span> <b>2021 International Conference on Content-Based Multimedia Indexing (CBMI). IEEE, 2021.</b></small></li>
				</ul>
			</section>

			<section>
				<section>
					<h1>R√©f√©rences</h1>
				</section>
				
				<section>
					<!-- <h3>Introduction & √âtat de l'Art</h3> -->
					<ul style="list-style: none; text-align: justify;">
						<li><small><b>[Bokovoy2019]: </b>A. Bokovoy et al. "Real-time Vision-based Depth Reconstruction with NVidia Jetson"</small></li>
						<li><small><b>[Desislavov2023]: </b>R. Desislavov et al. "Trends in AI inference energy consumption: Beyond the performance-vs-parameter laws of deep learning"</small></li>
						<li><small><b>[Kzh2012]: </b>A. Kzh, et al. "Imagenet classification with deep convolutional neural networks"</small></li>
						<li><small><b>[He2016]: </b>K. He, et al. "Deep residual learning for image recognition"</small></li>
						<li><small><b>[Deng2009]: </b>J. Deng, et al. "Imagenet: A large-scale hierarchical image database"</small></li>
						<li><small><b>[Lapicque1907]: </b>LM Lapicque, "Recherches quantitatives sur l‚Äôexcitation electrique des nerfs"</small></li>
						<li><small><b>[Neftci2019]: </b>E. Neftci et al., "Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks"</small></li>
						<li><small><b>[Li2017]: </b>H. Li et al., "Cifar10-dvs: an event-stream dataset for object classification."</small></li>
						<li><small><b>[Kim2022]: </b>Y. Kim et al. "Beyond Classification: Directly Training Spiking Neural Networks for Semantic Segmentation"</small></li>
					</ul>
				</section>

				<section>
					<!-- <h3>R√©f√©rences (2)</h3> -->
					<ul style="list-style: none; text-align: justify;">
						<li><small><b>[Cordone2022]: </b>L. Cordone et al. "Object Detection with Spiking Neural Networks on Automotive Event Data"</small></li>
						<li><small><b>[Rancon2021]: </b>U. Ran√ßon et al. "StereoSpike: Depth Learning with a Spiking Neural Network"</small></li>
						<li><small><b>[Horowitz2014]: </b>M. Horowitz "Computing's energy problem (and what we can do about it)"</small></li>
						<li><small><b>[Bardes2022]: </b>A. Bardes et al. "VICReg: Variance-Invariance-Covariance Regularization For Self-Supervised Learning"</small></li>
						<li><small><b>[Zbontar2021]: </b>J. Zbontar et al. "Barlow Twins: Self-Supervised Learning via Redundancy Reduction"</small></li>
						<li><small><b>[Fang2021]: </b>W. Fang et al. "Deep residual learning in spiking neural networks"</small></li>
						<li><small><b>[Tran2017]: </b>D. Tran et al. "A Closer Look at Spatiotemporal Convolutions for Action Recognition"</small></li>
						<li><small><b>[Dehghani2023]: </b>M. Dehghani et al. "Scaling Vision Transformers to 22 Billion Parameters"</small></li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>√âtat de l'Art</h4>
				</section>

				<section>
					<h3>Consommation √ânerg√©tique</h3>
					<p>Estimation de l'√©nergie consomm√©e lors d'une inf√©rence des mod√®les de l'√©tat de l'art par
						ann√©e<small>[Desislavov2023]</small></p>
					<div class="r-stack">
						<!-- <img src="these/consommation_energie_0.png" alt="Consommation √©nerg√©tique">
						<img src="these/consommation_energie_1.png" alt="Consommation √©nerg√©tique" class="fragment"> -->
						<img src="these/consommation_energie_2.png" alt="Consommation √©nerg√©tique">
						<img src="these/consommation_energie_3.png" alt="Consommation √©nerg√©tique" class="fragment">
						<img src="these/consommation_energie_4.png" alt="Consommation √©nerg√©tique" class="fragment">
					</div>
				</section>

				<section>
					<h3>R√©seaux de Neurones Impulsionnels</h3>
					<p><b>Apprentissage par Subtitut du Gradient</b> <span class="ita">(SG)</span></p>
					<div class="r-stack">
						<img src="these/sota/if_eq.png" alt="eq" class="fragment fade-in-then-out">
						<img src="these/sota/if_recursive_0.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_2.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_3.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_4.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_recursive_5.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_rnn.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_rnn_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_1.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_2.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_3.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/if_forward_4.png" alt="recu" class="fragment fade-in-then-out" height="550px">
						<img src="these/sota/heaviside.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/heaviside_back.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/surrogate.png" alt="recu" class="fragment fade-in-then-out">
						<img src="these/sota/surrogate_back.png" alt="recu" class="fragment fade-in-then-out">
					</div>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Bina-Rep</h4>
				</section>

				<section>
					<h3>Bina-Rep</h3>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>Localisation</h4>
				</section>

				<section>
					<h3>Images Statiques - Latence</h3>
					<img src="these/localization/latence_full.png" alt="latence full" height="600px">
				</section>

				<section>
					<h3>Consommation √©nerg√©tique</h3>
					<div class="r-stack fragment fade-in" data-fragment-index="0">
						<img src="these/localization/conso_1.png" alt="conso" class="fragment" data-fragment-index="0">
						<img src="these/localization/conso_2.png" alt="conso" class="fragment" data-fragment-index="1">
						<img src="these/localization/conso_3.png" alt="conso" class="fragment" data-fragment-index="2">
						<img src="these/localization/conso.png" alt="conso" class="fragment" data-fragment-index="3">
						<img src="these/localization/conso_4.png" alt="conso" class="fragment" data-fragment-index="4">
						<img src="these/localization/conso_5.png" alt="conso" class="fragment" data-fragment-index="5">
					</div>
				</section>
			</section>

			<section>
				<section>
					<h1>Annexes</h1>
					<h4>SSRL √âv√©nementiel</h4>
				</section>

				<section>
					<h3>dIoU</h3>
				</section>

				<section>
					<h3>VICReg</h3>
					<img height="230px" src="these/vicreg_annexe.png" alt="vicreg annexe">
					<ol>
						<li><b>Invariance : </b>minimiser la distance entre les deux encastrements de la m√™me entr√©e</li>
						<li><b>Variance : </b>maintenir la variance de chaque variable d'un m√™me vecteur dans un lot au-dessus d'un seuil</li>
						<li><b>Covariance : </b>minimiser la covariance entre les valeurs d'un m√™me vecteur</li>
					</ol>
				</section>

				<section>
					<h3>Augmentations de Donn√©es √âtudi√©es</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>Exemple</b></p>
						<p style="border: solid 3px  blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="1"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>Augmentations Communes</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>Augmentations Communes</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="5"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10"><b>Augmentations en D√©coupage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11"><b>Augmentations en D√©coupage</b></p>

						<p style="border: solid 3px blue; margin:10px; color:blue;" class="fragment fade-in-then-out" data-fragment-index="12"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="14"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="15"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="16"><b>Augmentations G√©om√©triques</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="17"><b>Augmentations G√©om√©triques</b></p>
					</div>
					<div class="r-stack">
						<img src="these/eda/normal.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="0">
						<p class="fragment fade-in-then-out" data-fragment-index="1">üìñ &nbsp; Transformations couramment utilis√©es, ne partagent <b>pas de caract√©ristiques communes</b>.</p>
						<img src="these/eda/background_activity.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/eda/polarity_flip.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/eda/crop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="4">

						<p class="fragment fade-in-then-out" data-fragment-index="5">üìñ &nbsp; Transformations impliquant la <b>suppression d'√©v√©nements</b>.</p>
						<img src="these/eda/cutout.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/eda/drop_by_time.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/eda/random_drop.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="8">
						<img src="these/eda/event_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="9">
						<img src="these/eda/event_copy.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="10">
						<img src="these/eda/event_copy_drop.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="11">

						<p class="fragment fade-in-then-out" data-fragment-index="12">üìñ &nbsp; Transformations impliquant une <b>distorsion spatiale des √©v√©nements</b>.</p>
						<img src="these/eda/static_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="13">
						<img src="these/eda/static_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="14">
						<img src="these/eda/dynamic_translation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="15">
						<img src="these/eda/dynamic_rotation.gif" alt="normal" class="fragment fade-in-then-out" data-fragment-index="16">
						<img src="these/eda/stat_dyn_geo.png" height="400px" alt="normal" class="fragment fade-in-then-out" data-fragment-index="17">

					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2">Bruit d'activit√© de fond (<code>Noise</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="3">Inversion de polarit√© (<code>PolFlip</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">Recadrage (<code>Crop</code>)</p>
						<!-- decoupage-->
						<p class="fragment fade-in-then-out" data-fragment-index="5"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="6">D√©coupe par zone (<code>Cutout</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="7">D√©coupe par dur√©e</p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">D√©coupe al√©atoire</p>
						<p class="fragment fade-in-then-out" data-fragment-index="9"><code>EventDrop</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="10">üÜï &nbsp; <code>EventCopy</code></p>
						<p class="fragment fade-in-then-out" data-fragment-index="11">üÜï &nbsp; <code>EventCopyDrop</code></p>
						<!-- geo -->
						<p class="fragment fade-in-then-out" data-fragment-index="12"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="13">Translation statique (<code>StatTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="14">Rotation statique (<code>StatRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="15">üÜï &nbsp; Translation dynamique (<code>DynTran</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="16">üÜï &nbsp; Rotation dynamique (<code>DynRot</code>)</p>
						<p class="fragment fade-in-then-out" data-fragment-index="17">üÜï &nbsp; <code>StatDynGeo</code></p>
					</div>
				</section>

				<section>
					<h3>Distribution EDAs</h3>
					<img src="these/params_edas.png" alt="param edas" height="600px">
				</section>

				<section>
					<h3>√âtude sur les EDAs</h3>
					<p><b>R√©sultats</b></p>
					<div class="r-stack">
						<img alt="tab result edas" src="these/results_edas/tab_0.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_1.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_2.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_3.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_4.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_5.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_6.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_7.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_8.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_9.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_10.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_11.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_12.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_13.png">
						<img alt="tab result edas" class="fragment" src="these/results_edas/tab_14.png">
					</div>
				</section>

				<section>
					<h3>√âvaluation des Performances</h3>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="5"><b>√âvaluation Lin√©aire et Apprentissage Semi-supervis√©</b></p>

						<p class="fragment fade-in-then-out" data-fragment-index="6"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"><b>Transfert d'Apprentissage</b></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8"><b>Transfert d'Apprentissage</b></p>
					</div>
					<div class="r-stack">
						<img src="these/results_ssl/tab_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="0">
						<img src="these/results_ssl/tab_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="1">
						<img src="these/results_ssl/tab_2.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="2">
						<img src="these/results_ssl/tab_3.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="3">
						<img src="these/results_ssl/tab_4.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="4">
						<img src="these/results_ssl/tab_5.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="5">

						<img src="these/results_ssl/transfer_0.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="6">
						<img src="these/results_ssl/transfer_1.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="7">
						<img src="these/results_ssl/transfer.png" alt="results ssl" class="fragment fade-in-then-out" data-fragment-index="8">
					</div>
					<div class="r-stack">
						<p class="fragment fade-in-then-out" data-fragment-index="0"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="1"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="2"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="3"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="4">2D-/3D-CNNs $>$ CSNN</p>
						<p class="fragment fade-in-then-out" data-fragment-index="5">Int√©r√™t de la variante "√âtudiant-Professeur"</p>
						<p class="fragment fade-in-then-out" data-fragment-index="6"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="7"></p>
						<p class="fragment fade-in-then-out" data-fragment-index="8">‚úÖ &nbsp; transf√©rabilit√© des repr√©sentations apprises</p>
					</div>
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>ASL-DVS</b></p>
					<img height="500px" src="these/results_ssl/perspective_asl.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CARS</b></p>
					<img height="500px" src="these/results_ssl/perspective_ncars.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>N-CALTECH101</b></p>
					<img src="these/results_ssl/perspective_ncaltech101.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DVSGesture</b></p>
					<img src="these/results_ssl/perspective_dvsgesture.png" alt="ASL">
				</section>

				<section>
					<h3>Mise en Perspective - SSRL √©v√©nementiel</h3>
					<p><b>DailyAction-DVS</b></p>
					<img src="these/results_ssl/perspective_dailyactiondvs.png" alt="ASL">
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>Expliquer ce que c'est</p>
				</section>

				<section>
					<h3>Repr√©sentation - Uniformit√© et Tol√©rance</h3>
					<p>R√©sultat + interpretations</p>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>