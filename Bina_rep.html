<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Bina-Rep Event Frames: a Simple And Effective Representation For
		Event-based Cameras</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Titre -->
			<section>
				<h5 style="text-transform: capitalize;">Bina-Rep Event Frames: a Simple And Effective Representation For
					Event-based Cameras</h5>
				<br>
				<img src="img/Bina_rep/icip22.png" alt="ICIP22">
				<br>
				<small><b>Sami BARCHID</b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; José MENNESSON &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					Chaabane DJÉRABA</small>
				<img src="img/Bina_rep/logos_cbmi.png">
				<!-- <p><small id="js-current-date"></small></p>
				<script>
					document.getElementById('js-current-date').innerHTML = new Date().toLocaleDateString("en-US")
				</script> -->
			</section>

			<section>
				<section>
					<h1>Introduction</h1>
				</section>
				<section>
					<h3>Event Cameras</h3>
					<video src="img/Bina_rep/dvscamvisu.mp4" height="300px" muted autoplay></video>
					<p><small>Video from here: <a
								href="https://www.youtube.com/watch?v=LauQ6LWTkxM">https://www.youtube.com/watch?v=LauQ6LWTkxM</a></small>
					</p>
				</section>

				<section>
					<h3>Advantages</h3>
					<ul>
						<li class="fragment"><b>Sparser representation</b> (no redundancy)</li>
						<br>
						<li class="fragment"><b>Low latency</b> (~1 µs)</li>
						<br>
						<li class="fragment"><b>No motion blur</b></li>
						<br>
						<li class="fragment"><b>High Dynamic Range</b> (60dB vs 140 dB for standard cameras)</li>
						<br>
						<li class="fragment"><b>Low energy consumption</b></li>
					</ul>
				</section>

				<section>
					<h3>Event-based Computer Vision</h3>
					<p><b style="color: red">Conventional vision algorithms cannot be applied directly.</b></p>
					<ol>
						<li class="fragment"><b>Asynchronous events</b> <span style="font-style: italic">instead
								of</span> <b>frames</b></li>
						<br>
						<li class="fragment"><b>Binary changes</b> <span style="font-style: italic">instead of</span>
							<b>intensity values</b>
						</li>
					</ol>
				</section>

				<section data-transition="none">
					<h3>Event representation</h3>
					<img src="img/Bina_rep/event_representation_0.png" alt="Event representation">
					<p><b>Definition:</b> method that takes asynchronous events as input, and transforms them into an
						alternative representation (e.g. binary event frames).</p>
				</section>
				<section data-transition="none">
					<h3>Event representation</h3>
					<img src="img/Bina_rep/event_representation_1.png" alt="Event representation">
					<p><b>Definition:</b> method that takes <span style="color: red;">asynchronous events as
							input</span>, and transforms them into an
						alternative representation (e.g. binary event frames).</p>
				</section>

				<section data-transition="none">
					<h3>Event representation</h3>
					<img src="img/Bina_rep/event_representation.png" alt="Event representation">
					<p><b>Definition:</b> method that takes asynchronous events as input, and transforms them into an
						<span style="color: red;">alternative representation</span> (e.g. binary event frames).
					</p>
				</section>

				<section>
					<h3>Objective of this work</h3>
					<p>
						Propose a <b>new event representation</b> method to apply standard vision algorithms with event
						cameras (i.e. 2D frame-like representation).
					</p>
				</section>

				<section>
					<h3>Contributions</h3>
					<ol>
						<li class="fragment" data-fragment-index="1"><b>Bina-Rep</b>, a simple and efficient event
							representation to obtain a sequence of event frames that are:</li>
						<ul class="fragment" data-fragment-index="1">
							<li>sparse</li>
							<li>more expressive</li>
						</ul>
						<br>
						<li class="fragment" data-fragment-index="2"><b>A comparative study</b> on object recognition
							against other SOTA event representation methods that:</li>
						<ul class="fragment" data-fragment-index="2">
							<li>reports competitive results in terms of <b>accuracy</b> and <b>robustness</b> </li>
						</ul>
					</ol>
				</section>
			</section>

			<section>
				<section>
					<h1>Event Representation Methods</h1>
				</section>

				<section>
					<h3>Various Paradigms</h3>
					<ul>
						<li>Invididual events</li>
						<br>
						<li>Time Surfaces</li>
						<br>
						<li>Event Frames</li>
					</ul>
				</section>

				<section>
					<h3>Individual Events</h3>
					<video src="img/Bina_rep/snn_visu.mp4" height="280px" muted autoplay></video>
					<p><small>Video from: <a
								href="https://www.youtube.com/watch?v=oG0PTP3ogCA">https://www.youtube.com/watch?v=oG0PTP3ogCA</a></small>
					</p>
					<ul>
						<li>Asynchronous processing of events (e.g. Spiking Neural Networks)</li>
						<!-- <li>Little to no transformation</li> -->
						<li style="color: green;">Efficient and perfect integration with event cameras</li>
						<li style="color: red;">Performance limited</li>
					</ul>
				</section>

				<section>
					<h3>Time Surfaces</h3>
					<img src="img/Bina_rep/hats.png" alt="HATS">
					<p><small>Example computation of HATS, from paper [Sironi2018]</small></p>
					<ul>
						<li>Extract <b>temporal information</b> of an event stream and expose it as a 2D surface/image
						</li>
						<li>Easily integrated with conventional CV algorithms</li>
						<li style="color: green;">Robust to noisy events</li>
					</ul>
				</section>

				<section>
					<h3>Event Frames</h3>
					<img src="img/Bina_rep/event_frame.png" height="120px" alt="Binary event frames">
					<p><small>Example of binary event frame [Kogler2009]</small></p>
					<ul>
						<li><b>Accumulate</b> events into 2D frames to feed conventional algorithms</li>
						<li style="color: green;">Popular due to an intuitive representation of edge maps</li>
						<li class="fragment" data-fragment-index="1" style="color: red;">Absence of explicit temporal
							information</li>
						<ul class="fragment" data-fragment-index="1">
							<li style="color: green;"><b>Still achieves competitive results</b></li>
						</ul>
					</ul>
				</section>

				<section>
					<h3>Link with Bina-Rep</h3>
					<ul>
						<li>Follows the <b>Event Frame</b> strategy</li>
						<li><b>Capable of expressing temporal information</b> without intensive computation</li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Bina-Rep Event Frames</h1>
				</section>

				<section>
					<h3>Binary Event Frames</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/binary_event_frame_0.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/binary_event_frame_1.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/binary_event_frame_2.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/binary_event_frame_3.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/binary_event_frame_4.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/binary_event_frame_5.png" alt="fomrulation">
					</div>
				</section>

				<section>
					<h3>Bina-Rep Event Frames</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/bina_rep_frame.drawio_0.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_1.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_2.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_3.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_4.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_5.png" alt="fomrulation">
						<img class="fragment" src="img/Bina_rep/bina_rep_frame.drawio_6.png" alt="fomrulation">
					</div>
				</section>

				<section>
					<h3>Bina-Rep Frames Sequence</h3>
					<img src="img/Bina_rep/binarep_sequence.drawio.png" alt="seq binarep">
					<ul>
						<li><b style="color: green;">Sparser</b> : $T$ bina-rep frames of $N$-bit numbers $ = T \times
							N$ binary event frames</li>
					</ul>
				</section>

				<section>
					<h3>Difference with similar representations</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/link_binarep.drawio_0.png" alt="difference">
						<img class="fragment" src="img/Bina_rep/link_binarep.drawio_1.png" alt="difference">
						<img class="fragment" src="img/Bina_rep/link_binarep.drawio_2.png" alt="difference">
						<img class="fragment" src="img/Bina_rep/link_binarep.drawio.png" alt="difference">
					</div>
				</section>

				<section>
					<h3>Model for event-based recognition</h3>
					<div class="r-stack">
						<img height="350px" src="img/Bina_rep/model_0.png" alt="model CNN image">
						<img height="350px" class="fragment" src="img/Bina_rep/model_1.png" alt="model CNN image">
						<img height="350px" class="fragment" src="img/Bina_rep/model_2.png" alt="model CNN image">
						<img height="350px" class="fragment" src="img/Bina_rep/model.png" alt="model CNN image">
					</div>
				</section>
			</section>

			<section>
				<section>
					<h1>Experiments</h1>
				</section>

				<section>
					<h3>Datasets and metrics</h3>
					<img src="img/Bina_rep/table1.png" alt="Table 1">
					<ul>
						<li>Metric used: top-1 accuracy</li>
					</ul>
				</section>

				<section>
					<h3>Implementation Details</h3>
					<ul>
						<li>PyTorch 1.8 on one NVIDIA Tesla P100 GPU</li>
						<li class="fragment highlight-red">Frames Resolution: $224 \times 224$</li>
						<li class="fragment highlight-red">CNN used: <b>ResNet-18</b><small>[Kaiming2016]</small></li>
						<li>Trained during <b>60 epochs</b> using <b>Adam optimizer</b> with a <b>learning rate of
								$0.001$</b></li>
						<li class="fragment highlight-red">8-bit <code>uint</code> representation used for Bina-Rep (i.e. $N=8$)</li>
					</ul>
				</section>

				<section>
					<h3>Comparison with Event Representations (1)</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/table2.png" alt="Table 2">
						<img class="fragment" src="img/Bina_rep/table2_1.png" alt="Table 2">
					</div>
				</section>

				<section>
					<h3>Comparison with Event Representations (2)</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/table3.png" alt="Table 3">
						<img src="img/Bina_rep/table3_1.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_2.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_3.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_4.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_5.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_6.png" alt="table3" class="fragment">
						<img src="img/Bina_rep/table3_7.png" alt="table3" class="fragment">
					</div>
				</section>

				<section>
					<h3>Comparison with SOTA</h3>
					<div class="r-stack">
						<img src="img/Bina_rep/table4.png" alt="Table 4">
						<img src="img/Bina_rep/table4_1.png" class="fragment" alt="Table 4">
						<img src="img/Bina_rep/table4_2.png" class="fragment" alt="Table 4">
					</div>
				</section>

				<section>
					<h3>Robustness Analysis</h3>
					<h4>Corruptions</h4>
					<div class="r-stack">
						<img src="img/Bina_rep/example_corruptions_0.png" alt="Corruptions example">
						<img class="fragment" src="img/Bina_rep/example_corruptions_1.png" alt="Corruptions example">
						<img class="fragment" src="img/Bina_rep/example_corruptions.png" alt="Corruptions example">
					</div>
					<p><b>Dataset used</b>: N-Cars<small>[Sironi2018]</small></p>
				</section>

				<section>
					<h3>Robustness Analysis</h3>
					<h4>severity levels</h4>
					<p>For a specific corruption: performance are evaluated on increasing <b>severity levels</b> (From
						$1$ to $5$)</p>
					<ul>
						<li><b>Background Activity</b>: adds a percentage of noisy events</li>
						<li><b>Occlusion</b>: increases the occlusion area (percentage of original resolution)</li>
					</ul>
					<img src="img/Bina_rep/table5.png" alt="Table 5">
				</section>

				<section>
					<h3>Robustness Analysis</h3>
					<h4>Metric</h4>
					<p>
						<b>Relative Acurracy Drop</b> for a given severity level $i$:
					</p>
					<br>
					<p> $score = \frac{acc_0-acc_i}{acc_0} \times
						100$</p>
					<br>
					<ul>
						<li>$acc_0$ = the accuracy score on clean data</li>
						<li>$acc_i$ = the accuracy score on data corrupted by severity level $i$</li>
					</ul>
				</section>

				<section>
					<img src="img/Bina_rep/fig3.png" alt="Fig 3">
					<ul>
						<li class="fragment">In general, the same evolution is observed for all methods</li>
						<li class="fragment">Bina-Rep is on par with SOTA event representation methods</li>
						<li class="fragment">Bina-Rep becomes more robust with more frames ($T \gt 1$)</li>
					</ul>
				</section>
			</section>

			<section>
				<section>
					<h1>Conclusion</h1>
				</section>
				<section>
					<h3>Discussion</h3>
					<ol>
						<li class="fragment" data-fragment-index="1">Bina-Rep event frames express 3 information</li>
						<ul class="fragment">
							<li>The <b>presence/absence</b> of an event</li>
							<li>The <b>number of events</b> that occured</li>
							<li>The <b>order of these events</b> in the sequence</li>
						</ul>
						<br>
						<li class="fragment">Better or competitive performance against SOTA
						</li>
						<br>
						<li class="fragment">Competitive robustness scores against common corruptions of event cameras.
						</li>
					</ol>
				</section>

				<section>
					<h3>Try it yourself</h3>
					<p>Available in the <a href="https://github.com/neuromorphs/tonic">Tonic Library</a></p>
					<img height="100px" src="img/Bina_rep/tonic.png" alt="tonic logo">
					<br>
					<img class="fragment" src="img/Bina_rep/tobinarep.png" alt="code example">
				</section>
			</section>
			<section>
				<section>
					<p class="r-fit-text">Thank you!</p>
				</section>
				<section>
					<h3>References</h3>
					<ul>
						<li><small><b>[Kogler2009]: </b>Kogler, et al. "Bio-inspired stereo vision system with silicon
								retina imagers." International Conference on Computer Vision Systems. Springer, Berlin,
								Heidelberg, 2009</small></li>
						<br>
						<li><small><b>[Kaiming2016]: </b> He, Kaiming, et al. "Deep residual learning for image
								recognition." Proceedings of the IEEE conference on computer vision and pattern
								recognition. 2016.</small></li><br>
						<li><small><b>[Sironi2018]: </b>Sironi, et al. "HATS: Histograms of averaged time surfaces for
								robust event-based object classification." Proceedings of the IEEE Conference on
								Computer Vision and Pattern Recognition. 2018.</small></li><br>
						<li><small><b>[Maqueda2018]: </b>Maqueda, et al. "Event-based vision meets deep learning on
								steering prediction for self-driving cars." Proceedings of the IEEE conference on
								computer vision and pattern recognition. 2018.</small></li>
					</ul>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			slideNumber: 'c/t',
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
		});
	</script>
</body>

</html>